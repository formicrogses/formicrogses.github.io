// Auto-generated papers data file V3 with DOI information
// Generated from Papers folder images and DOI.xlsx
// Generation time: 2025-10-23T21:55:42.677995

const PAPERS_DATA = {
  "papers": [
    {
      "id": 1,
      "title": "Towards keyboard independent touch typing in VR",
      "year": "2005",
      "category": "hardware",
      "hardwareDevices": [
        "DataGloves",
        "Keyboard",
        "VRHeadset",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Pinch",
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "DigitalArt",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "OneHandUse",
        "TouchOptimized"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2005 - Towards keyboard independent touch typing in VR.png",
      "doi": "https://doi.org/10.1145/1101616.1101635",
      "authors": "Kuester Falko, Chen Michelle, Phair Mark E., Mehring Carsten",
      "journal": "VRST05: The ACM Symposium on Virtual Reality Software and Technology 2005"
    },
    {
      "id": 2,
      "title": "Demonstrating the feasibility of using forearm electromyography for muscle-computer interfaces",
      "year": "2008",
      "category": "hardware",
      "hardwareDevices": [
        "WearableSensor"
      ],
      "sensingTechnology": [
        "BioSensor",
        "EMG"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "Hold",
        "Pinch",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "InVehicleInteraction",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HandsFree",
        "HighAccuracy",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2008 - Demonstrating the feasibility of using forearm electromyography for muscle-computer interfaces.png",
      "doi": "https://doi.org/10.1145/1357054.1357138",
      "authors": "Saponas T. Scott, Tan Desney S., Morris Dan, Balakrishnan Ravin",
      "journal": "CHI '08: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 3,
      "title": "Hand gesture recognition and virtual game control based on 3D accelerometer and EMG sensors",
      "year": "2009",
      "category": "hardware",
      "hardwareDevices": [
        "WearableSensor"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "BioSensor",
        "EMG",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand"
      ],
      "applicationScenarios": [
        "Gaming",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "LowLatency",
        "PortableDesign"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2009 - Hand gesture recognition and virtual game control based on 3D accelerometer and EMG sensors.png",
      "doi": "https://doi.org/10.1145/1502650.1502708",
      "authors": "Zhang Xu, Chen Xiang, Wang Wen-hui, Yang Ji-hai, Lantz Vuokko, Wang Kong-qiao",
      "journal": "IUI09: 14th International Conference on Intelligent User Interfaces"
    },
    {
      "id": 4,
      "title": "A prototype of gesture-based interface",
      "year": "2011",
      "category": "hardware",
      "hardwareDevices": [
        "Smartphone",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "BioSensor",
        "EMG"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Flex",
        "SingleHand"
      ],
      "applicationScenarios": [
        "InVehicleInteraction",
        "MediaControl"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2011 - A prototype of gesture-based interface.png",
      "doi": "https://doi.org/10.1145/2037373.2037380",
      "authors": "Lu Zhiyuan, Chen Xiang, Zhao Zhangyan, Wang Kongqiao",
      "journal": "MobileHCI '11: 13th International Conference on Human Computer Interaction with Mobile Devices and Services"
    },
    {
      "id": 5,
      "title": "Design space for finger gestures with hand-held tablets",
      "year": "2012",
      "category": "gesture-design",
      "hardwareDevices": [
        "Tablet",
        "TouchScreen",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "CapacitiveSensor",
        "Gyroscope",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "DualHand",
        "Grasp",
        "MultiTouch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "MultimodalFeedback",
        "ProprioceptiveFeedback"
      ],
      "userExperienceDesign": [
        "FatFingerProblem",
        "OcclusionAvoidance",
        "SocialAcceptability",
        "TouchOptimized",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2012 - Design space for finger gestures with hand-held tablets.png",
      "doi": "https://doi.org/10.1145/2388676.2388748",
      "authors": "Wolf Katrin",
      "journal": "ICMI '12: INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION"
    },
    {
      "id": 6,
      "title": "Augmenting the input space of portable displays using add-on hall-sensor grid",
      "year": "2013",
      "category": "hardware",
      "hardwareDevices": [
        "Smartphone",
        "Tablet",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Magnetometer",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "DirectTouch",
        "NonContactBased",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Pinch",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "Gaming",
        "MediaControl",
        "Navigation",
        "TextInput"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "OcclusionAvoidance",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2013 - Augmenting the input space of portable displays using add-on hall-sensor grid.png",
      "doi": "https://doi.org/10.1145/2508468.2508470",
      "authors": "Liang Rong-Hao",
      "journal": "the adjunct publication of the 26th annual ACM symposium"
    },
    {
      "id": 7,
      "title": "EarPut augmenting ear-worn devices for ear-based interaction",
      "year": "2014",
      "category": "hardware",
      "hardwareDevices": [
        "OtherDevices",
        "Smartphone",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "DirectTouch",
        "EarBasedInteraction",
        "InAirGesture"
      ],
      "gestureTypes": [
        "MultiTouch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "Gaming",
        "MediaControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "HapticFeedback",
        "ProprioceptiveFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2014 - EarPut augmenting ear-worn devices for ear-based interaction.png",
      "doi": "https://doi.org/10.1145/2686612.2686655",
      "authors": "Lissermann Roman, Huber Jochen, Hadjakos Aristotelis, Nanayakkara Suranga, Mühlhäuser Max",
      "journal": "OzCHI '14: the Future of Design"
    },
    {
      "id": 8,
      "title": "Advancing muscle-computer interfaces with high-density electromyography",
      "year": "2015",
      "category": "hardware",
      "hardwareDevices": [
        "WearableSensor"
      ],
      "sensingTechnology": [
        "BioSensor",
        "EMG"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "NonContactBased"
      ],
      "gestureTypes": [
        "Flex",
        "Pinch",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "IoTControl",
        "MediaControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HandsFree",
        "HighAccuracy",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2015 - Advancing muscle-computer interfaces with high-density electromyography.png",
      "doi": "https://doi.org/10.1145/2702123.2702501",
      "authors": "Amma Christoph, Krings Thomas, Böer Jonas, Schultz Tanja",
      "journal": "CHI '15: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 9,
      "title": "eRing multiple finger gesture recognition with one ring using an electric field",
      "year": "2015",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "IoTControl",
        "OtherScenarios",
        "SmartHome"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "OcclusionAvoidance",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2015 - eRing multiple finger gesture recognition with one ring using an electric field.png",
      "doi": "https://doi.org/10.1145/2790044.2790047",
      "authors": "Wilhelm Mathias, Krakowczyk Daniel, Trollmann Frank, Albayrak Sahin",
      "journal": "iWOAR '15: 2nd international Workshop on Sensor-based Activity Recognition and Interaction"
    },
    {
      "id": 10,
      "title": "Finger-writing with smartwatch a case for finger and hand gesture recognition using smartwatch",
      "year": "2015",
      "category": "software",
      "hardwareDevices": [
        "SmartWatch",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "MotionAnalysis",
        "StaticGestureRecognition",
        "TrajectoryAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "IoTControl",
        "MediaControl",
        "SmartHome",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HandsFree",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2015 - Finger-writing with smartwatch a case for finger and hand gesture recognition using smartwatch.png",
      "doi": "https://doi.org/10.1145/2699343.2699350",
      "authors": "Xu Chao, Pathak Parth H., Mohapatra Prasant",
      "journal": "HotMobile '15: The 16th International Workshop on Mobile Computing Systems and Applications"
    },
    {
      "id": 11,
      "title": "Gunslinger subtle arms-down mid-air interaction",
      "year": "2015",
      "category": "gesture-design",
      "hardwareDevices": [
        "TouchScreen",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "DepthSensing",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "Hold",
        "Pinch",
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HandsFree",
        "LowLatency",
        "MidasTouchProblem",
        "OcclusionAvoidance",
        "OneHandUse",
        "TouchOptimized"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2015 - Gunslinger subtle arms-down mid-air interaction.png",
      "doi": "https://doi.org/10.1145/2807442.2807489",
      "authors": "Liu Mingyu, Nancel Mathieu, Vogel Daniel",
      "journal": "UIST '15: The 28th Annual ACM Symposium on User Interface Software and Technology"
    },
    {
      "id": 12,
      "title": "Microgesture detection for remote interaction with mobile devices",
      "year": "2016",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "Smartphone",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "DeviceContactGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "InVehicleInteraction",
        "IoTControl",
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EncumberedInteraction",
        "EyesFree",
        "HandsFree",
        "MidasTouchProblem",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2016 - Microgesture detection for remote interaction with mobile devices.png",
      "doi": "https://doi.org/10.1145/2957265.2961865",
      "authors": "Wolf Katrin, Mayer Sven, Meyer Stephan",
      "journal": "MobileHCI '16: 18th International Conference on Human-Computer Interaction with Mobile Devices and Services"
    },
    {
      "id": 13,
      "title": "Designing a willing-to-use-in-public hand gestural interaction technique for smart glasses",
      "year": "2016",
      "category": "gesture-design",
      "hardwareDevices": [
        "DataGloves",
        "HapticDevice",
        "SmartGlasses",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "IMU",
        "MotionSensor",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Flex",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "Navigation",
        "ObjectManipulation",
        "TextInput"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "MultimodalFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HandsFree",
        "OcclusionAvoidance",
        "PortableDesign",
        "SocialAcceptability",
        "TouchOptimized"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2016 - Designing a willing-to-use-in-public hand gestural interaction technique for smart glasses.png",
      "doi": "https://doi.org/10.1145/2858036.2858436",
      "authors": "Hsieh Yi-Ta, Jylhä Antti, Orso Valeria, Gamberini Luciano, Jacucci Giulio",
      "journal": "CHI'16: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 15,
      "title": "DeformWear deformation input on tiny wearable devices",
      "year": "2017",
      "category": "hardware",
      "hardwareDevices": [
        "ARGlasses",
        "HapticDevice",
        "SmartGlasses",
        "SmartRing",
        "SmartWatch",
        "VRHeadset",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "OpticalTracking",
        "OtherTechnology",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "MultiModalInteraction",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "Hold",
        "Pinch",
        "SingleHand",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming",
        "MediaControl",
        "Navigation",
        "ObjectManipulation",
        "SmartHome",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "ProprioceptiveFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SmallScreen",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2017 - DeformWear deformation input on tiny wearable devices.png",
      "doi": "https://doi.org/10.1145/3090093",
      "authors": "Weigel Martin, Steimle Jürgen",
      "journal": "Proc ACM Interact Mob Wearable Ubiquitous Technol"
    },
    {
      "id": 17,
      "title": "GestAKey touch interaction on individual keycaps",
      "year": "2018",
      "category": "hardware",
      "hardwareDevices": [
        "Keyboard",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "MultiTouch",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "TextInput"
      ],
      "feedbackOutput": [
        "HapticFeedback"
      ],
      "userExperienceDesign": [
        "LowLatency",
        "QWERTYLayout",
        "TouchOptimized",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2018 - GestAKey touch interaction on individual keycaps.png",
      "doi": "https://doi.org/10.1145/3173574.3174170",
      "authors": "Shi Yilei, Zhang Haimo, Rajapakse Hasitha, Perera Nuwan Tharaka, Vega Gálvez Tomás, Nanayakkara Suranga",
      "journal": "CHI '18: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 18,
      "title": "Gestures for smart rings empirical results, insights, and design implications",
      "year": "2018",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartRing",
        "Wearables"
      ],
      "sensingTechnology": [
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "IoTControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "HapticFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Gestures for smart rings empirical results, insights, and design implications.png",
      "doi": "https://doi.org/10.1145/3196709.3196741",
      "authors": "Gheran Bogdan-Florin, Vanderdonckt Jean, Vatavu Radu-Daniel",
      "journal": "DIS '18: Designing Interactive Systems Conference 2018"
    },
    {
      "id": 19,
      "title": "Thumb-in-motion evaluating thumb-to-ring microgestures for athletic activity",
      "year": "2018",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "SmartWatch",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "Healthcare",
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EncumberedInteraction",
        "LowLatency",
        "OneHandUse",
        "PortableDesign"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2018 - Thumb-in-motion evaluating thumb-to-ring microgestures for athletic activity.png",
      "doi": "https://doi.org/10.1145/3267782.3267796",
      "authors": "Boldu Roger, Dancu Alexandru, Matthies Denys J. C., Cascón Pablo Gallego, Ransir Shanaka, Nanayakkara Suranga",
      "journal": "SUI '18: Symposium on Spatial User Interaction"
    },
    {
      "id": 20,
      "title": "Touch+finger extending touch-based user interface capabilities with idle finger gestures in the air",
      "year": "2018",
      "category": "software",
      "hardwareDevices": [
        "SmartRing",
        "Tablet",
        "TouchScreen",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "Magnetometer"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Hold",
        "MultiTouch",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "DigitalArt",
        "Gaming",
        "MediaControl",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "SmallScreen",
        "TouchOptimized"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2018 - Touch+finger extending touch-based user interface capabilities with idle finger gestures in the air.png",
      "doi": "https://doi.org/10.1145/3242587.3242651",
      "authors": "Lim Hyunchul, Chung Jungmin, Oh Changhoon, Park SoHyun, Lee Joonhwan, Suh Bongwon",
      "journal": "UIST '18: The 31st Annual ACM Symposium on User Interface Software and Technology"
    },
    {
      "id": 21,
      "title": "FingerInput Capturing Expressive Single-Hand Thumb-to-Finger Microgestures",
      "year": "2018",
      "category": "software",
      "hardwareDevices": [
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "ComputerVision",
        "DepthSensing"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Flex",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "DigitalArt",
        "MediaControl"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "OneHandUse"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2018-FingerInput Capturing Expressive Single-Hand Thumb-to-Finger Microgestures.png",
      "doi": "https://doi.org/10.1145/3279778.3279799",
      "authors": "Soliman Mohamed, Mueller Franziska, Hegemann Lena, Roo Joan Sol, Theobalt Christian, Steimle Jürgen",
      "journal": "ISS '18: 2018 ACM International Conference on Interactive Surfaces and Spaces"
    },
    {
      "id": 22,
      "title": "AudioTouch minimally invasive sensing of micro-gestures via active bio-acoustic sensing",
      "year": "2019",
      "category": "hardware",
      "hardwareDevices": [
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "BioSensor",
        "PressureSensor",
        "UltrasonicSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "Hold",
        "Pinch",
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "SmartHome",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2019 - AudioTouch minimally invasive sensing of micro-gestures via active bio-acoustic sensing.png",
      "doi": "https://doi.org/10.1145/3338286.3340147",
      "authors": "Kubo Yuki, Koguchi Yuto, Shizuki Buntarou, Takahashi Shin, Hilliges Otmar",
      "journal": "MobileHCI '19: 21st International Conference on Human-Computer Interaction with Mobile Devices and Services"
    },
    {
      "id": 23,
      "title": "TipText eyes-free text entry on a fingertip keyboard",
      "year": "2019",
      "category": "software",
      "hardwareDevices": [
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "ComputerVision",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "QWERTYLayout",
        "SmallScreen",
        "SocialAcceptability"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2019 - TipText eyes-free text entry on a fingertip keyboard.png",
      "doi": "https://doi.org/10.1145/3332165.3347865",
      "authors": "Xu Zheer, Wong Pui Chung, Gong Jun, Wu Te-Yen, Nittala Aditya Shekhar, Bi Xiaojun, Steimle Jürgen, Fu Hongbo, Zhu Kening, Yang Xing-Dong",
      "journal": "UIST '19: The 32nd Annual ACM Symposium on User Interface Software and Technology"
    },
    {
      "id": 24,
      "title": "E-textile microinteractions augmenting twist with flick, slide and grasp gestures for soft electronics",
      "year": "2020",
      "category": "hardware",
      "hardwareDevices": [
        "Etextile",
        "OtherDevices",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "OtherTechnology",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Grasp",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "Gaming",
        "MediaControl",
        "OtherScenarios",
        "SmartHome"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "PortableDesign",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2020 - E-textile microinteractions augmenting twist with flick, slide and grasp gestures for soft electronics.png",
      "doi": "https://doi.org/10.1145/3313831.3376236",
      "authors": "Olwal Alex, Starner Thad, Mainini Gowa",
      "journal": "CHI '20: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 25,
      "title": "Exploring user defined gestures for ear-based interactions",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "SmartGlasses",
        "Wearables"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OtherTechnology",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "EarBasedInteraction",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "MediaControl",
        "Navigation",
        "OtherScenarios",
        "SmartHome"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "HapticFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "OneHandUse",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Exploring user defined gestures for ear-based interactions.png",
      "doi": "https://doi.org/10.1145/3427314",
      "authors": "Chen Yu-Chun, Liao Chia-Ying, Hsu Shuo-wen, Huang Da-Yuan, Chen Bing-Yu",
      "journal": "Proc ACM Hum Comput Interact"
    },
    {
      "id": 26,
      "title": "Fabriccio touchless gestural input on interactive fabrics",
      "year": "2020",
      "category": "hardware",
      "hardwareDevices": [
        "Etextile",
        "OtherDevices",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "RFSensing",
        "RadarSensing"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "IoTControl",
        "MediaControl",
        "OtherScenarios",
        "SmartHome"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "PortableDesign"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2020 - Fabriccio touchless gestural input on interactive fabrics.png",
      "doi": "https://doi.org/10.1145/3313831.3376681",
      "authors": "Wu Te-Yen, Qi Shutong, Chen Junchi, Shang MuJie, Gong Jun, Seyed Teddy, Yang Xing-Dong",
      "journal": "CHI '20: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 27,
      "title": "Finger gesture tracking for interactive applications a pilot study with sign languages",
      "year": "2020",
      "category": "software",
      "hardwareDevices": [
        "SmartRing",
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "Magnetometer",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "MotionAnalysis",
        "TrajectoryAnalysis"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "SignLanguageRelated",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "Education",
        "Healthcare",
        "Training"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "MultimodalFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "CommunicationAid",
        "EncumberedInteraction",
        "LowLatency",
        "PortableDesign",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Finger gesture tracking for interactive applications a pilot study with sign languages.png",
      "doi": "https://doi.org/10.1145/3414117",
      "authors": "Liu Yilin, Jiang Fengyang, Gowda Mahanth",
      "journal": "Proc ACM Interact Mob Wearable Ubiquitous Technol"
    },
    {
      "id": 28,
      "title": "How subtle can it get A trimodal study of ring-sized interfaces for one-handed drone control",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "SmartRing",
        "Smartphone",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "IMU",
        "MotionSensor",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Flex",
        "Hold",
        "SingleHand",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - How subtle can it get A trimodal study of ring-sized interfaces for one-handed drone control.png",
      "doi": "https://doi.org/10.1145/3397319",
      "authors": "Yau Yui-Pan, Lee Lik Hang, Li Zheng, Braud Tristan, Ho Yi-Hsuan, Hui Pan",
      "journal": "Proc ACM Interact Mob Wearable Ubiquitous Technol"
    },
    {
      "id": 29,
      "title": "Nailz sensing hand input with touch sensitive nails",
      "year": "2020",
      "category": "hardware",
      "hardwareDevices": [
        "SmartGlasses",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "IMU"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "MultiTouch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "OneHandUse",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2020 - Nailz sensing hand input with touch sensitive nails.png",
      "doi": "https://doi.org/10.1145/3313831.3376778",
      "authors": "Lee DoYoung, Lee SooHwan, Oakley Ian",
      "journal": "CHI '20: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 30,
      "title": "ThermalRing gesture and tag inputs enabled by a thermal imaging smart ring",
      "year": "2020",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "InAirGesture",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "IoTControl",
        "MediaControl",
        "Navigation",
        "SmartHome"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HighAccuracy",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2020 - ThermalRing gesture and tag inputs enabled by a thermal imaging smart ring.png",
      "doi": "https://doi.org/10.1145/3313831.3376323",
      "authors": "Zhang Tengxiang, Zeng Xin, Zhang Yinshuai, Sun Ke, Wang Yuntao, Chen Yiqiang",
      "journal": "CHI '20: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 32,
      "title": "ElectroRing subtle pinch and touch detection with a ring",
      "year": "2021",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "Pinch",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "DigitalArt",
        "MR",
        "MediaControl",
        "ObjectManipulation",
        "VR"
      ],
      "feedbackOutput": [
        "ProprioceptiveFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "PortableDesign"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2021 - ElectroRing subtle pinch and touch detection with a ring.png",
      "doi": "https://doi.org/10.1145/3411764.3445094",
      "authors": "Kienzle Wolf, Whitmire Eric, Rittaler Chris, Benko Hrvoje",
      "journal": "CHI '21: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 33,
      "title": "SoloFinger robust microgestures while grasping everyday objects",
      "year": "2021",
      "category": "gesture-design",
      "hardwareDevices": [
        "DataGloves",
        "OtherDevices"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "DeviceContactGesture",
        "DirectTouch"
      ],
      "gestureTypes": [
        "Flex",
        "Grasp",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "ObjectManipulation",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "EncumberedInteraction",
        "HighAccuracy"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2021 - SoloFinger robust microgestures while grasping everyday objects.png",
      "doi": "https://doi.org/10.1145/3411764.3445197",
      "authors": "Sharma Adwait, Hedderich Michael A., Bhardwaj Divyanshu, Fruchard Bruno, McIntosh Jess, Nittala Aditya Shekhar, Klakow Dietrich, Ashbrook Daniel, Steimle Jürgen",
      "journal": "CHI '21: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 34,
      "title": "ThumbTrak recognizing micro-finger poses using a ring with proximity sensing",
      "year": "2021",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "DeviceContactGesture",
        "DirectTouch"
      ],
      "gestureTypes": [
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming",
        "MediaControl",
        "Navigation",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2021 - ThumbTrak recognizing micro-finger poses using a ring with proximity sensing.png",
      "authors": "Sun Wei, Li Franklin Mingzhe, Huang Congshu, Lei Zhenyu, Steeper Benjamin, Tao Songyun, Tian Feng, Zhang Cheng",
      "journal": "Proceedings of the 23rd International Conference on Mobile Human-Computer Interaction"
    },
    {
      "id": 36,
      "title": "DualRing Enabling Subtle and Expressive Hand Interaction with Dual IMU Rings",
      "year": "2021",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "Magnetometer",
        "RFSensing"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "MotionAnalysis",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Grasp",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "IoTControl",
        "MediaControl",
        "ObjectManipulation",
        "SmartHome",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2021-DualRing Enabling Subtle and Expressive Hand Interaction with Dual IMU Rings.png",
      "doi": "https://doi.org/10.1145/3478114",
      "authors": "Liang Chen, Yu Chun, Qin Yue, Wang Yuntao, Shi Yuanchun",
      "journal": "Proc ACM Interact Mob Wearable Ubiquitous Technol"
    },
    {
      "id": 37,
      "title": "MicroPress detecting pressure and hover distance in thumb-to-finger interactions",
      "year": "2022",
      "category": "hardware",
      "hardwareDevices": [
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "DepthSensing",
        "Gyroscope",
        "IMU",
        "Magnetometer",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "DirectTouch",
        "NonContactBased"
      ],
      "gestureTypes": [
        "Hold",
        "Pinch",
        "SingleHand",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming",
        "MediaControl",
        "Navigation",
        "VR"
      ],
      "feedbackOutput": [
        "ProprioceptiveFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2022 - MicroPress detecting pressure and hover distance in thumb-to-finger interactions.png",
      "doi": "https://doi.org/10.1145/3565970.3567698",
      "authors": "Dobinson Rhett, Teyssier Marc, Steimle Jürgen, Fruchard Bruno",
      "journal": "SUI '22: Symposium on Spatial User Interaction"
    },
    {
      "id": 39,
      "title": "DRG-Keyboard Enabling Subtle Gesture Typing on the Fingertip with Dual IMU Rings",
      "year": "2023",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "Magnetometer"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "TrajectoryAnalysis"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "SmartHome",
        "TextInput"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "PortableDesign",
        "QWERTYLayout",
        "SmallScreen"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2023-DRG-Keyboard Enabling Subtle Gesture Typing on the Fingertip with Dual IMU Rings.png",
      "doi": "https://doi.org/10.1145/3569463",
      "authors": "Liang Chen, Hsia Chi, Yu Chun, Yan Yukang, Wang Yuntao, Shi Yuanchun",
      "journal": "Proc ACM Interact Mob Wearable Ubiquitous Technol"
    },
    {
      "id": 40,
      "title": "EFRing Enabling Thumb-to-Index-Finger Microgesture Interaction through Electric Field Sensing Using Single Smart Ring",
      "year": "2023",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "DigitalArt",
        "IoTControl",
        "MediaControl",
        "SmartHome",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2023-EFRing Enabling Thumb-to-Index-Finger Microgesture Interaction through Electric Field Sensing Using Single Smart Ring.png",
      "doi": "https://doi.org/10.1145/3569478",
      "authors": "Chen Taizhou, Li Tianpei, Yang Xingyu, Zhu Kening",
      "journal": "Proc ACM Interact Mob Wearable Ubiquitous Technol"
    },
    {
      "id": 41,
      "title": "SparseIMU Computational Design of Sparse IMU Layouts for Sensing Fine-grained Finger Microgestures",
      "year": "2023",
      "category": "hardware",
      "hardwareDevices": [
        "DataGloves",
        "SmartRing",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "Magnetometer",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "NonContactBased",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Flex",
        "Grasp",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "Gaming",
        "InVehicleInteraction",
        "IoTControl",
        "SmartHome",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EncumberedInteraction",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "PortableDesign"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2023-SparseIMU Computational Design of Sparse IMU Layouts for Sensing Fine-grained Finger Microgestures.png",
      "doi": "https://doi.org/10.1145/3569894",
      "authors": "Sharma Adwait, Salchow-Hömmen Christina, Mollyn Vimal Suresh, Nittala Aditya Shekhar, Hedderich Michael A., Koelle Marion, Seel Thomas, Steimle Jürgen",
      "journal": "ACM Trans Comput-Hum Interact"
    },
    {
      "id": 42,
      "title": "VibAware Context-Aware Tap and Swipe Gestures Using Bio-Acoustic Sensing",
      "year": "2023",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "SmartWatch",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "BioSensor",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction",
        "NonContactBased",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Grasp",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "IoTControl",
        "MediaControl",
        "SmartHome",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EncumberedInteraction",
        "EyesFree",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2023-VibAware Context-Aware Tap and Swipe Gestures Using Bio-Acoustic Sensing.png",
      "doi": "https://doi.org/10.1145/3607822.3614544",
      "authors": "Kim Jina, Kim Minyung, Lee Woo Suk, Yoon Sang Ho",
      "journal": "SUI '23: ACM Symposium on Spatial User Interaction"
    },
    {
      "id": 43,
      "title": "MAF exploring mobile acoustic field for hand-to-face gesture interactions",
      "year": "2024",
      "category": "hardware",
      "hardwareDevices": [
        "OtherDevices",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "OtherTechnology",
        "UltrasonicSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "HandToFaceGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Hold",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming",
        "Healthcare",
        "MediaControl",
        "SmartHome",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2024 - MAF exploring mobile acoustic field for hand-to-face gesture interactions.png",
      "doi": "https://doi.org/10.1145/3613904.3642437",
      "authors": "Yang Yongjie, Chen Tao, Huang Yujing, Guo Xiuzhen, Shangguan Longfei",
      "journal": "CHI '24: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 44,
      "title": "RadarHand a wrist-worn radar for on-skin touch-based proprioceptive gestures",
      "year": "2024",
      "category": "hardware",
      "hardwareDevices": [
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "RFSensing",
        "RadarSensing"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "Gaming",
        "InVehicleInteraction",
        "MediaControl",
        "Navigation",
        "SmartHome"
      ],
      "feedbackOutput": [
        "ProprioceptiveFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SmallScreen",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2024 - RadarHand a wrist-worn radar for on-skin touch-based proprioceptive gestures.png",
      "doi": "https://doi.org/10.1145/3617365",
      "authors": "Hajika Ryo, Gunasekaran Tamil Selvan, Haigh Chloe Dolma Si Ying, Pai Yun Suen, Hayashi Eiji, Lien Jaime, Lottridge Danielle, Billinghurst Mark",
      "journal": "ACM Trans Comput-Hum Interact"
    },
    {
      "id": 45,
      "title": "Ring-a-pose a ring for continuous hand pose tracking",
      "year": "2024",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "OtherTechnology",
        "UltrasonicSensor"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "AccessibilitySupport",
        "Gaming",
        "MediaControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2024 - Ring-a-pose a ring for continuous hand pose tracking.png",
      "doi": "https://doi.org/10.1145/3699741",
      "authors": "Yu Tianhong Catherine, Hu Guilin, Zhang Ruidong, Lim Hyunchul, Mahmud Saif, Lee Chi-Jung, Li Ke, Agarwal Devansh, Nie Shuyang, Oh Jinseok",
      "journal": "Proc ACM Interact Mob Wearable Ubiquitous Technol"
    },
    {
      "id": 46,
      "title": "Studying the simultaneous visual representation of microgestures",
      "year": "2024",
      "category": "software",
      "hardwareDevices": [
        "SmartWatch",
        "Smartphone",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "Hold",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HandsFree",
        "OneHandUse",
        "SmallScreen",
        "SocialAcceptability"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2024 - Studying the simultaneous visual representation of microgestures.png",
      "doi": "https://doi.org/10.1145/3676523",
      "authors": "Lambert Vincent, Goguey Alix, Malacria Sylvain, Nigay Laurence",
      "journal": "Proc ACM Hum Comput Interact"
    },
    {
      "id": 47,
      "title": "HCMG Human-Capacitance based Micro Gesture for VR AR",
      "year": "2024",
      "category": "hardware",
      "hardwareDevices": [
        "ARGlasses",
        "VRHeadset",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "BioSensor",
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture"
      ],
      "gestureTypes": [
        "Grasp",
        "Pinch",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "AccessibilitySupport",
        "Education",
        "Gaming",
        "Training",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2024-HCMG Human-Capacitance based Micro Gesture for VR AR.png",
      "doi": "https://doi.org/10.1145/3675094.3678386",
      "authors": "Lu Yu, Ding Dian, Wang Ran, Xue Guangtao",
      "journal": "UbiComp '24: The 2024 ACM International Joint Conference on Pervasive and Ubiquitous Computing"
    },
    {
      "id": 48,
      "title": "BudsID mobile-ready and expressive finger identification input for earbuds",
      "year": "2025",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "IMU",
        "Magnetometer"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "DirectTouch",
        "EarBasedInteraction"
      ],
      "gestureTypes": [
        "MultiTouch",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "InVehicleInteraction",
        "MediaControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2025 - BudsID mobile-ready and expressive finger identification input for earbuds.png",
      "doi": "https://doi.org/10.1145/3706598.3714133",
      "authors": "Kim Jiwan, Han Mingyu, Oakley Ian",
      "journal": "CHI 2025: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 49,
      "title": "Gesture and audio-haptic guidance techniques to direct conversations with intelligent voice interfaces",
      "year": "2025",
      "category": "software",
      "hardwareDevices": [
        "HapticDevice",
        "SmartGlasses",
        "SmartRing",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "IMU",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction",
        "VoiceGestureCombined"
      ],
      "gestureTypes": [
        "Hold",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "HapticFeedback",
        "MultimodalFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "LowLatency",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2025 - Gesture and audio-haptic guidance techniques to direct conversations with intelligent voice interfaces.png",
      "doi": "https://doi.org/10.1145/3706598.3714310",
      "authors": "Rajaram Shwetha, Surale Hemant Bhaskar, McConkey Codie, Rognon Carine, Mehta Hrim, Glueck Michael, Collins Christopher",
      "journal": "CHI 2025: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 50,
      "title": "LeakyFeeder In-air gesture control through leaky acoustic waves",
      "year": "2025",
      "category": "software",
      "hardwareDevices": [
        "OtherDevices",
        "Wearables"
      ],
      "sensingTechnology": [
        "OtherTechnology",
        "UltrasonicSensor"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "EarBasedInteraction",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "Hold",
        "Pinch",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl",
        "OtherScenarios",
        "SmartHome",
        "VR"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "PortableDesign"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2025 - LeakyFeeder In-air gesture control through leaky acoustic waves.png",
      "doi": "https://doi.org/10.1145/3715014.3722054",
      "authors": "Yang Yongjie, Chen Tao, An Zhenlin, Cao Shirui, Fan Xiaoran, Shangguan Longfei",
      "journal": "SenSys '25: 23rd ACM Conference on Embedded Networked Sensor Systems"
    },
    {
      "id": 51,
      "title": "DCSNN An Efficient and High-speed sEMG-based Transient-state Micro-gesture Recognition Method on Wearable Devices",
      "year": "2025",
      "category": "hardware",
      "hardwareDevices": [
        "OtherDevices",
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "BioSensor",
        "EMG",
        "IMU"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming",
        "IoTControl",
        "MediaControl",
        "Navigation",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "PortableDesign",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2025-DCSNN An Efficient and High-speed sEMG-based Transient-state Micro-gesture Recognition Method on Wearable Devices.png",
      "doi": "https://doi.org/10.1145/3729494",
      "authors": "Han Youfang, Zhao Wei, Gao Ge, Chen Xiangjin, Yin Jiliang, Wang Lin, Meng Xin, Yu Yang, Zhang Tengxiang",
      "journal": "Proc ACM Interact Mob Wearable Ubiquitous Technol"
    },
    {
      "id": 52,
      "title": "VibRing A Wearable Vibroacoustic Sensor for Single-Handed Gesture Recognition",
      "year": "2025",
      "category": "hardware",
      "hardwareDevices": [
        "OtherDevices",
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming",
        "IoTControl",
        "MediaControl",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "LowLatency",
        "PortableDesign",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2025-VibRing A Wearable Vibroacoustic Sensor for Single-Handed Gesture Recognition.png",
      "doi": "https://doi.org/10.1145/3733052",
      "authors": "Li Bu, Huang Xincheng, Xiao Robert",
      "journal": "Proc ACM Hum Comput Interact"
    },
    {
      "id": 53,
      "title": "Exploring mixed-scale gesture interaction",
      "year": "2017",
      "category": "gesture-design",
      "hardwareDevices": [
        "ARGlasses",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "OpticalTracking",
        "RadarSensing"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "Grasp",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Exploring mixed-scale gesture interaction.png",
      "doi": "https://doi.org/10.1145/3145690.3145740",
      "authors": "Ens Barrett, Quigley Aaron, Yeo Hui-Shyong, Irani Pourang, Piumsomboon Thammathip, Billinghurst Mark",
      "journal": "SA '17: SIGGRAPH Asia 2017"
    },
    {
      "id": 54,
      "title": "Depth aware finger tapping on virtual displays",
      "year": "2018",
      "category": "software",
      "hardwareDevices": [
        "ARGlasses",
        "Smartphone",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "DepthSensing",
        "UltrasonicSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "MultimodalFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "LowLatency"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2018 - Depth aware finger tapping on virtual displays.png",
      "doi": "https://doi.org/10.1145/3210240.3210315",
      "authors": "Sun Ke, Wang Wei, Liu Alex X., Dai Haipeng",
      "journal": "MobiSys '18: The 16th Annual International Conference on Mobile Systems, Applications, and Services"
    },
    {
      "id": 55,
      "title": "Experimental analysis of barehand mid-air mode-switching techniques in virtual reality",
      "year": "2019",
      "category": "gesture-design",
      "hardwareDevices": [
        "VRHeadset",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "OpticalTracking",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "Grasp",
        "Pinch",
        "SingleHand"
      ],
      "applicationScenarios": [
        "ObjectManipulation",
        "VR"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2019 - Experimental analysis of barehand mid-air mode-switching techniques in virtual reality.png",
      "doi": "https://doi.org/10.1145/3290605.3300426",
      "authors": "Surale Hemant Bhaskar, Matulic Fabrice, Vogel Daniel",
      "journal": "CHI '19: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 56,
      "title": "Characterizing in-air eyes-free typing movements in VR",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "MotionAnalysis",
        "TrajectoryAnalysis"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DualHand",
        "Flex",
        "Tap"
      ],
      "applicationScenarios": [
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "QWERTYLayout"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Characterizing in-air eyes-free typing movements in VR.png",
      "doi": "https://doi.org/10.1145/3385956.3418963",
      "authors": "Gil Hyunjae, Shin Yonghwan, Son Hyungki, Hwang Inwook, Oakley Ian, Kim Jin Ryong",
      "journal": "VRST '20: 26th ACM Symposium on Virtual Reality Software and Technology"
    },
    {
      "id": 57,
      "title": "User gesture elicitation of common smartphone tasks for hand proximate user interfaces",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "ARGlasses",
        "SmartGlasses",
        "Smartphone"
      ],
      "sensingTechnology": [
        "ComputerVision"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "DirectTouch",
        "InAirGesture"
      ],
      "gestureTypes": [
        "Flex",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "MR",
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "OneHandUse",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020-User gesture elicitation of common smartphone tasks for hand proximate user interfaces.png",
      "doi": "https://doi.org/10.1145/3396339.3396363",
      "authors": "Faleel Shariff A. M., Gammon Michael, Sakamoto Yumiko, Menon Carlo, Irani Pourang",
      "journal": "AH '20: 11th Augmented Human International Conference"
    },
    {
      "id": 58,
      "title": "AtaTouch robust finger pinch detection for a VR controller using RF return loss",
      "year": "2021",
      "category": "hardware",
      "hardwareDevices": [
        "VRHeadset",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "RFSensing"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture"
      ],
      "gestureTypes": [
        "Grasp",
        "Pinch",
        "SingleHand",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "Gaming",
        "ObjectManipulation",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "LowLatency",
        "OcclusionAvoidance",
        "OneHandUse"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2021 - AtaTouch robust finger pinch detection for a VR controller using RF return loss.png",
      "doi": "https://doi.org/10.1145/3411764.3445442",
      "authors": "Kim Daehwa, Park Keunwoo, Lee Geehyuk",
      "journal": "CHI '21: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 60,
      "title": "GraV grasp volume data for the design of one-handed XR interfaces",
      "year": "2024",
      "category": "software",
      "hardwareDevices": [
        "ARGlasses",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "ComputerVision"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Grasp",
        "SingleHand",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "ObjectManipulation",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "OneHandUse",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2024 - GraV grasp volume data for the design of one-handed XR interfaces.png",
      "doi": "https://doi.org/10.1145/3643834.3661567",
      "authors": "Aponte Alejandro, Caetano Arthur, Luo Yunhao, Sra Misha",
      "journal": "DIS '24: Designing Interactive Systems Conference"
    },
    {
      "id": 61,
      "title": "HapticPilot authoring in-situ hand posture-adaptive vibrotactile feedback for virtual reality",
      "year": "2024",
      "category": "software",
      "hardwareDevices": [
        "DataGloves",
        "HapticDevice",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand"
      ],
      "applicationScenarios": [
        "DigitalArt",
        "Gaming",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "LowLatency",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2024 - HapticPilot authoring in-situ hand posture-adaptive vibrotactile feedback for virtual reality.png",
      "doi": "https://doi.org/10.1145/3631453",
      "authors": "Sung Youjin, Kim Rachel, Song Kun Woo, Shao Yitian, Yoon Sang Ho",
      "journal": "Proc ACM Interact Mob Wearable Ubiquitous Technol"
    },
    {
      "id": 62,
      "title": "TriPad touch input in AR on ordinary surfaces with hand tracking only",
      "year": "2024",
      "category": "software",
      "hardwareDevices": [
        "ARGlasses",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "DepthSensing",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "InAirGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "MultiTouch",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "Navigation",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HandsFree",
        "LowLatency",
        "SocialAcceptability",
        "TouchOptimized"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2024 - TriPad touch input in AR on ordinary surfaces with hand tracking only.png",
      "doi": "https://doi.org/10.1145/3613904.3642323",
      "authors": "Dupré Camille, Appert Caroline, Rey Stéphanie, Saidi Houssem, Pietriga Emmanuel",
      "journal": "CHI '24: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 63,
      "title": "GraspUI Seamlessly Integrating Object-Centric Gestures within the Seven Phases of Grasping",
      "year": "2024",
      "category": "software",
      "hardwareDevices": [
        "ARGlasses",
        "SmartGlasses",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "InAirGesture",
        "MultiModalInteraction",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Grasp",
        "Hold",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl",
        "ObjectManipulation",
        "SmartHome"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2024-GraspUI Seamlessly Integrating Object-Centric Gestures within the Seven Phases of Grasping.png",
      "doi": "https://doi.org/10.1145/3643834.3661551",
      "authors": "Sharma Adwait, Ivanov Alexander, Lai Frances, Grossman Tovi, Santosa Stephanie",
      "journal": "DIS '24: Designing Interactive Systems Conference"
    },
    {
      "id": 64,
      "title": "Stick-To-XR Understanding Stick-Based User Interface Design for Extended Reality",
      "year": "2024",
      "category": "hardware",
      "hardwareDevices": [
        "HapticDevice",
        "OtherDevices",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OpticalTracking",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DualHand",
        "Grasp",
        "Hold",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AR",
        "Education",
        "Gaming",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "MultimodalFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "OneHandUse",
        "PortableDesign",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2024-Stick-To-XR Understanding Stick-Based User Interface Design for Extended Reality.png",
      "doi": "https://doi.org/10.1145/3643834.3661627",
      "authors": "Zhang Yaying, Shi Rongkai, Liang Hai-Ning",
      "journal": "DIS '24: Designing Interactive Systems Conference"
    },
    {
      "id": 65,
      "title": "STMG A Machine Learning Microgesture Recognition System for Supporting Thumb-Based VR AR Input",
      "year": "2024",
      "category": "software",
      "hardwareDevices": [
        "ARGlasses",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl",
        "Navigation",
        "ObjectManipulation",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2024-STMG A Machine Learning Microgesture Recognition System for Supporting Thumb-Based VR AR Input.png",
      "doi": "https://doi.org/10.1145/3613904.3642702",
      "authors": "Kin Kenrick, Wan Chengde, Koh Ken, Marin Andrei, Camgöz Necati Cihan, Zhang Yubo, Cai Yujun, Kovalev Fedor, Ben-Zacharia Moshe, Hoople Shannon, Nunes-Ueno Marcos, Sanchez-Rodriguez Mariel, Bhargava Ayush, Wang Robert, Sauser Eric, Ma Shugao",
      "journal": "CHI '24: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 66,
      "title": "Understanding Gesture and Microgesture Inputs for Augmented Reality Maps",
      "year": "2024",
      "category": "gesture-design",
      "hardwareDevices": [
        "ARGlasses",
        "SmartGlasses",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "CapacitiveSensor",
        "ComputerVision",
        "IMU",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "Navigation"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "ProprioceptiveFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "OneHandUse",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2024-Understanding Gesture and Microgesture Inputs for Augmented Reality Maps.png",
      "doi": "https://doi.org/10.1145/3643834.3661630",
      "authors": "Danyluk Kurtis, Klueber Simon, Nittala Aditya Shekhar, Willett Wesley",
      "journal": "DIS '24: Designing Interactive Systems Conference"
    },
    {
      "id": 67,
      "title": "T2IRay Design of Thumb-to-Index based Indirect Pointing for Continuous and Robust AR VR Input",
      "year": "2025",
      "category": "gesture-design",
      "hardwareDevices": [
        "ARGlasses",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "ObjectManipulation",
        "VR"
      ],
      "feedbackOutput": [
        "ProprioceptiveFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "OneHandUse",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2025-T2IRay Design of Thumb-to-Index based Indirect Pointing for Continuous and Robust AR VR Input.png",
      "doi": "https://doi.org/10.1145/3706598.3713442",
      "authors": "Kim Jina, Zhang Yang, Yoon Sang Ho",
      "journal": "CHI 2025: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 68,
      "title": "Key-press gestures recognition and interaction based on SEMG signals",
      "year": "2010",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "BioSensor",
        "EMG"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "Flex",
        "Hold",
        "SingleHand"
      ],
      "applicationScenarios": [
        "MediaControl",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EncumberedInteraction",
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2010 - Key-press gestures recognition and interaction based on SEMG signals.png",
      "doi": "https://doi.org/10.1145/1891903.1891950",
      "authors": "Cheng Juan, Chen Xiang, Lu Zhiyuan, Wang Kongqiao, Shen Minfen",
      "journal": "ICMI-MLMI '10: International Conference on Multimodal Interfaces / Workshop on Machine Learning for Multimodal Interfaces"
    },
    {
      "id": 69,
      "title": "A study of on-device gestures",
      "year": "2012",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone"
      ],
      "sensingTechnology": [
        "PressureSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "ContactBased",
        "DeviceContactGesture"
      ],
      "gestureTypes": [
        "Grasp",
        "SingleHand",
        "Swipe"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "ProprioceptiveFeedback"
      ],
      "userExperienceDesign": [
        "EncumberedInteraction",
        "OcclusionAvoidance",
        "OneHandUse"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2012 - A study of on-device gestures.png",
      "doi": "https://doi.org/10.1145/2371664.2371669",
      "authors": "Wolf Katrin, McGee-Lennon Marilyn, Brewster Stephen",
      "journal": "MobileHCI '12: 14th International Conference on Human Computer Interaction with Mobile Devices and Services"
    },
    {
      "id": 70,
      "title": "PinchPad performance of touch-based gestures while grasping devices",
      "year": "2012",
      "category": "gesture-design",
      "hardwareDevices": [
        "Tablet"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "ContactBased",
        "DeviceContactGesture",
        "DirectTouch"
      ],
      "gestureTypes": [
        "Grasp",
        "Pinch",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "ProprioceptiveFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "OcclusionAvoidance",
        "OneHandUse"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2012 - PinchPad performance of touch-based gestures while grasping devices.png",
      "doi": "https://doi.org/10.1145/2148131.2148155",
      "authors": "Wolf Katrin, Müller-Tomfelde Christian, Cheng Kelvin, Wechsung Ina",
      "journal": "TEI'12: Sixth International Conference on Tangible, Embedded, and Embodied Interaction"
    },
    {
      "id": 71,
      "title": "The fat thumb using the thumb's contact size for single-handed mobile interaction",
      "year": "2012",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "SingleHand",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "FatFingerProblem",
        "OneHandUse",
        "SmallScreen",
        "TouchOptimized"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2012 - The fat thumb using the thumb's contact size for single-handed mobile interaction.png",
      "doi": "https://doi.org/10.1145/2371574.2371582",
      "authors": "Boring Sebastian, Ledo David, Chen Xiang'Anthony', Marquardt Nicolai, Tang Anthony, Greenberg Saul",
      "journal": "Proceedings of the 14th international conference on Human-computer interaction with mobile devices and services"
    },
    {
      "id": 72,
      "title": "Exploring pinch and spread gestures on mobile devices",
      "year": "2013",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone",
        "Tablet"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "DirectTouch",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DualHand",
        "MultiTouch",
        "Pinch",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "SmallScreen",
        "TouchOptimized"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2013 - Exploring pinch and spread gestures on mobile devices.png",
      "doi": "https://doi.org/10.1145/2493190.2493221",
      "authors": "Tran Jessica J., Trewin Shari, Swart Calvin, John Bonnie E., Thomas John C.",
      "journal": "MobileHCI '13: 15th International Conference on Human-Computer Interaction with Mobile Devices and Services"
    },
    {
      "id": 74,
      "title": "Leap gestures for TV insights from an elicitation study",
      "year": "2014",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "Flex",
        "Hold",
        "SingleHand"
      ],
      "applicationScenarios": [
        "MediaControl"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "HandsFree",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2014 - Leap gestures for TV insights from an elicitation study.png",
      "doi": "https://doi.org/10.1145/2602299.2602316",
      "authors": "Vatavu Radu-Daniel, Zaiti Ionut-Alexandru",
      "journal": "TVX '14: ACM International Conference on Interactive Experiences for TV and Online Video"
    },
    {
      "id": 75,
      "title": "Tactile feedback for above-device gesture interfaces adding touch to touchless interactions",
      "year": "2014",
      "category": "software",
      "hardwareDevices": [
        "HapticDevice",
        "SmartRing",
        "SmartWatch",
        "Smartphone",
        "Wearables"
      ],
      "sensingTechnology": [
        "OpticalTracking",
        "UltrasonicSensor"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "SingleHand"
      ],
      "applicationScenarios": [
        "MediaControl"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "MultimodalFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "SmallScreen",
        "TouchOptimized"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2014 - Tactile feedback for above-device gesture interfaces adding touch to touchless interactions.png",
      "doi": "https://doi.org/10.1145/2663204.2663280",
      "authors": "Freeman Euan, Brewster Stephen, Lantz Vuokko",
      "journal": "Proceedings of the 16th international conference on multimodal interaction"
    },
    {
      "id": 76,
      "title": "Interaction proxemics combining physical spaces for seamless gesture interaction",
      "year": "2015",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "DepthSensing",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "DirectTouch",
        "InAirGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "Navigation",
        "ObjectManipulation",
        "TextInput"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2015 - Interaction proxemics combining physical spaces for seamless gesture interaction.png",
      "doi": "https://doi.org/10.1145/2757710.2757722",
      "authors": "Dingler Tilman, Funk Markus, Alt Florian",
      "journal": "PerDis '15: The International Symposium on Pervasive Displays"
    },
    {
      "id": 77,
      "title": "Exploring non-touchscreen gestures for smartwatches",
      "year": "2016",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartWatch",
        "Wearables"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "DeviceContactGesture",
        "InAirGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "ElicitationStudy",
        "FatFingerProblem",
        "OcclusionAvoidance",
        "SmallScreen",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2016 - Exploring non-touchscreen gestures for smartwatches.png",
      "doi": "https://doi.org/10.1145/2858036.2858385",
      "authors": "Arefin Shimon Shaikh Shawon, Lutton Courtney, Xu Zichun, Morrison-Smith Sarah, Boucher Christina, Ruiz Jaime",
      "journal": "CHI'16: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 78,
      "title": " Finger-aware shortcuts",
      "year": "2016",
      "category": "software",
      "hardwareDevices": [
        "Keyboard"
      ],
      "sensingTechnology": [
        "ComputerVision"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "DeviceContactGesture"
      ],
      "gestureTypes": [
        "DualHand",
        "Hold",
        "SingleHand"
      ],
      "applicationScenarios": [
        "TextInput"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "QWERTYLayout",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2016 - Finger-aware shortcuts.png",
      "doi": "https://doi.org/10.1145/2858036.2858355",
      "authors": "Zheng Jingjie, Vogel Daniel",
      "journal": "CHI'16: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 79,
      "title": "Interacting with soli exploring fine-grained dynamic gesture recognition in the radio-frequency spectrum",
      "year": "2016",
      "category": "hardware",
      "hardwareDevices": [
        "OtherDevices",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "RFSensing",
        "RadarSensing"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "ObjectManipulation",
        "SmartHome"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "OcclusionAvoidance",
        "PortableDesign"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2016 - Interacting with soli exploring fine-grained dynamic gesture recognition in the radio-frequency spectrum.png",
      "doi": "https://doi.org/10.1145/2984511.2984565",
      "authors": "Wang Saiwen, Song Jie, Lien Jaime, Poupyrev Ivan, Hilliges Otmar",
      "journal": "UIST '16: The 29th Annual ACM Symposium on User Interface Software and Technology"
    },
    {
      "id": 80,
      "title": "Investigating how the hand interacts with different mobile phones",
      "year": "2016",
      "category": "gesture-design",
      "hardwareDevices": [
        "Keyboard",
        "Smartphone",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "ComputerVision"
      ],
      "recognitionClassification": [
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "DirectTouch"
      ],
      "gestureTypes": [
        "DualHand",
        "Grasp",
        "Hold",
        "SingleHand"
      ],
      "applicationScenarios": [
        "MediaControl",
        "TextInput"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "OneHandUse",
        "TouchOptimized"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2016 - Investigating how the hand interacts with different mobile phones.png",
      "doi": "https://doi.org/10.1145/2957265.2961840",
      "authors": "Eardley Rachel, Gill Steve, Roudaut Anne, Thompson Stephen, Hare Joanna",
      "journal": "MobileHCI '16: 18th International Conference on Human-Computer Interaction with Mobile Devices and Services"
    },
    {
      "id": 81,
      "title": "WiFinger talk to your smart devices with finger-grained gesture",
      "year": "2016",
      "category": "software",
      "hardwareDevices": [
        "OtherDevices",
        "Smartphone"
      ],
      "sensingTechnology": [
        "RFSensing"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "SignLanguageRelated",
        "SingleHand"
      ],
      "applicationScenarios": [
        "SmartHome",
        "TextInput"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HandsFree",
        "HighAccuracy"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2016 - WiFinger talk to your smart devices with finger-grained gesture.png",
      "doi": "https://doi.org/10.1145/2971648.2971738",
      "authors": "Li Hong, Yang Wei, Wang Jianxin, Xu Yang, Huang Liusheng",
      "journal": "UbiComp '16: The 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing"
    },
    {
      "id": 82,
      "title": "Understanding grip shifts how form factors impact hand movements on mobile phones",
      "year": "2017",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "DualHand",
        "Hold",
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "Navigation",
        "TextInput"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "OneHandUse",
        "PortableDesign",
        "SmallScreen",
        "TouchOptimized"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Understanding grip shifts how form factors impact hand movements on mobile phones.png",
      "doi": "https://doi.org/10.1145/3025453.3025835",
      "authors": "Eardley Rachel, Roudaut Anne, Gill Steve, Thompson Stephen J.",
      "journal": "CHI '17: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 83,
      "title": "Characterizing finger pitch and roll orientation during atomic touch actions",
      "year": "2018",
      "category": "gesture-design",
      "hardwareDevices": [
        "Tablet",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "Magnetometer"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "DualHand",
        "Hold",
        "MultiTouch",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "TouchOptimized"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Characterizing finger pitch and roll orientation during atomic touch actions.png",
      "doi": "https://doi.org/10.1145/3173574.3174163",
      "authors": "Goguey Alix, Casiez Géry, Vogel Daniel, Gutwin Carl",
      "journal": "CHI '18: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 84,
      "title": "Fingers' range and comfortable area for one-handed smartphone interaction beyond the touchscreen",
      "year": "2018",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "FatFingerProblem",
        "OcclusionAvoidance",
        "OneHandUse",
        "PortableDesign",
        "TouchOptimized"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Fingers' range and comfortable area for one-handed smartphone interaction beyond the touchscreen.png",
      "doi": "https://doi.org/10.1145/3173574.3173605",
      "authors": "Le Huy Viet, Mayer Sven, Bader Patrick, Henze Niels",
      "journal": "CHI '18: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 85,
      "title": "InfiniTouch finger-aware interaction on fully touch sensitive smartphones",
      "year": "2018",
      "category": "hardware",
      "hardwareDevices": [
        "Smartphone",
        "TouchScreen",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "Flex",
        "Pinch",
        "SingleHand",
        "Swipe",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "MediaControl",
        "ObjectManipulation",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "FatFingerProblem",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2018 - InfiniTouch finger-aware interaction on fully touch sensitive smartphones.png",
      "doi": "https://doi.org/10.1145/3242587.3242605",
      "authors": "Le Huy Viet, Mayer Sven, Henze Niels",
      "journal": "UIST '18: The 31st Annual ACM Symposium on User Interface Software and Technology"
    },
    {
      "id": 86,
      "title": "Pen + mid-air gestures eliciting contextual gestures",
      "year": "2018",
      "category": "gesture-design",
      "hardwareDevices": [
        "Tablet",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased",
        "PenInput"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "Grasp",
        "Pinch",
        "Swipe"
      ],
      "applicationScenarios": [
        "DigitalArt",
        "Education",
        "MediaControl",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EncumberedInteraction",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Pen + mid-air gestures eliciting contextual gestures.png",
      "doi": "https://doi.org/10.1145/3242969.3242979",
      "authors": "Aslan Ilhan, Schmidt Tabea, Woehrle Jens, Vogel Lukas, André Elisabeth",
      "journal": "ICMI '18: International Conference on Multimodal Interaction"
    },
    {
      "id": 87,
      "title": "Unimanual Pen Touch Input Using Variations of Precision Grip Postures",
      "year": "2018",
      "category": "gesture-design",
      "hardwareDevices": [
        "Tablet",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction",
        "PenInput"
      ],
      "gestureTypes": [
        "Grasp",
        "MultiTouch",
        "SingleHand"
      ],
      "applicationScenarios": [
        "DigitalArt",
        "Education",
        "ObjectManipulation",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "HighAccuracy",
        "OneHandUse",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2018-Unimanual Pen Touch Input Using Variations of Precision Grip Postures.png",
      "doi": "https://doi.org/10.1145/3242587.3242652",
      "authors": "Cami Drini, Matulic Fabrice, Calland Richard G., Vogel Brian, Vogel Daniel",
      "journal": "UIST '18: The 31st Annual ACM Symposium on User Interface Software and Technology"
    },
    {
      "id": 88,
      "title": "Gaze-assisted typing for smart glasses",
      "year": "2019",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartGlasses",
        "VRHeadset",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "GazeBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "TextInput"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EyesFree",
        "LowLatency",
        "MidasTouchProblem",
        "OneHandUse",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2019 - Gaze-assisted typing for smart glasses.png",
      "doi": "https://doi.org/10.1145/3332165.3347883",
      "authors": "Ahn Sunggeun, Lee Geehyuk",
      "journal": "UIST '19: The 32nd Annual ACM Symposium on User Interface Software and Technology"
    },
    {
      "id": 89,
      "title": "Investigating unintended inputs for one-handed touch interaction beyond the touchscreen",
      "year": "2019",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "MotionAnalysis",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "ContactBased",
        "DeviceContactGesture"
      ],
      "gestureTypes": [
        "Grasp",
        "SingleHand"
      ],
      "applicationScenarios": [
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EncumberedInteraction",
        "FatFingerProblem",
        "OcclusionAvoidance",
        "OneHandUse",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2019 - Investigating unintended inputs for one-handed touch interaction beyond the touchscreen.png",
      "doi": "https://doi.org/10.1145/3338286.3340145",
      "authors": "Le Huy Viet, Mayer Sven, Steuerlein Benedict, Henze Niels",
      "journal": "MobileHCI '19: 21st International Conference on Human-Computer Interaction with Mobile Devices and Services"
    },
    {
      "id": 90,
      "title": "Expanding Side Touch Input on Mobile Phones",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "MediaControl",
        "Navigation",
        "TextInput"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "FatFingerProblem",
        "HighAccuracy",
        "OcclusionAvoidance",
        "OneHandUse",
        "PortableDesign"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Expanding side touch input on mobile phones finger reachability and two-dimensional taps and flicks using the index and.png",
      "doi": "https://doi.org/10.1145/3427334",
      "authors": "Yeh Yen-Ting, Roy Quentin, Irudayaraj Antony Albert Raj, Vogel Daniel",
      "journal": "Proc ACM Hum Comput Interact"
    },
    {
      "id": 91,
      "title": "MagTouch robust finger identification for a smartwatch using a magnet ring and a built-in magnetometer",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartRing",
        "SmartWatch",
        "Wearables"
      ],
      "sensingTechnology": [
        "IMU",
        "Magnetometer",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - MagTouch robust finger identification for a smartwatch using a magnet ring and a built-in magnetometer.png",
      "doi": "https://doi.org/10.1145/3313831.3376234",
      "authors": "Park Keunwoo, Kim Daehwa, Heo Seongkook, Lee Geehyuk",
      "journal": "CHI '20: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 92,
      "title": "PenSight enhanced interaction with a pen-top camera",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "Tablet"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "DepthSensing",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction",
        "NonContactBased",
        "PenInput",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DualHand",
        "Grasp"
      ],
      "applicationScenarios": [
        "DigitalArt",
        "Education",
        "Navigation",
        "ObjectManipulation",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EncumberedInteraction",
        "HighAccuracy",
        "LowLatency",
        "OcclusionAvoidance",
        "PortableDesign"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - PenSight enhanced interaction with a pen-top camera.png",
      "doi": "https://doi.org/10.1145/3313831.3376147",
      "authors": "Matulic Fabrice, Arakawa Riku, Vogel Brian, Vogel Daniel",
      "journal": "CHI '20: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 93,
      "title": "Shortcut gestures for mobile text editing on fully touch sensitive smartphones",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone",
        "TouchScreen",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "ContactBased",
        "DeviceContactGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Hold",
        "MultiTouch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "OtherScenarios",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "FatFingerProblem",
        "HighAccuracy",
        "OcclusionAvoidance",
        "OneHandUse",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Shortcut gestures for mobile text editing on fully touch sensitive smartphones.png",
      "doi": "https://doi.org/10.1145/3396233",
      "authors": "Le Huy Viet, Mayer Sven, Weiß Maximilian, Vogelsang Jonas, Weingärtner Henrike, Henze Niels",
      "journal": "ACM Trans Comput-Hum Interact"
    },
    {
      "id": 94,
      "title": "Eliciting tangible and gestural user interactions with and on a cooking pan",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Grasp",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "OtherScenarios",
        "SmartHome"
      ],
      "feedbackOutput": [
        "MultimodalFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EncumberedInteraction"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Eliciting tangible and gestural user interactions with and on a cooking pan.png",
      "doi": "https://doi.org/10.1145/3404983.3405516",
      "authors": "Beruscha Frank, Mueller Katharina, Sohnke Thorsten",
      "journal": "MuC'20: Mensch und Computer 2020"
    },
    {
      "id": 95,
      "title": "3D hand pose estimation on conventional capacitive touchscreens",
      "year": "2021",
      "category": "gesture-design",
      "hardwareDevices": [
        "Tablet",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DualHand",
        "Grasp",
        "MultiTouch",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AR",
        "DigitalArt",
        "Gaming",
        "ObjectManipulation",
        "Training",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "FatFingerProblem",
        "HighAccuracy",
        "LowLatency",
        "OcclusionAvoidance",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2021 - 3D hand pose estimation on conventional capacitive touchscreens.png",
      "doi": "https://doi.org/10.1145/3447526.3472045",
      "authors": "Choi Frederick, Mayer Sven, Harrison Chris",
      "journal": "MobileHCI '21: 23rd International Conference on Mobile Human-Computer Interaction"
    },
    {
      "id": 96,
      "title": "TouchPose hand pose prediction, depth estimation, and touch classification from capacitive images",
      "year": "2021",
      "category": "software",
      "hardwareDevices": [
        "Smartphone",
        "Tablet",
        "TouchScreen",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "ComputerVision",
        "DepthSensing",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Grasp",
        "MultiTouch",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AR",
        "DigitalArt",
        "ObjectManipulation",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "LowLatency",
        "OcclusionAvoidance",
        "TouchOptimized",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2021 - TouchPose hand pose prediction, depth estimation, and touch classification from capacitive images.png",
      "doi": "https://doi.org/10.1145/3472749.3474801",
      "authors": "Ahuja Karan, Streli Paul, Holz Christian",
      "journal": "UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology"
    },
    {
      "id": 97,
      "title": "Watching your phone's back gesture recognition by sensing acoustical structure-borne propagation",
      "year": "2021",
      "category": "software",
      "hardwareDevices": [
        "OtherDevices",
        "Smartphone",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OtherTechnology",
        "UltrasonicSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "DeviceContactGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "IoTControl",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "MultimodalFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "LowLatency",
        "OcclusionAvoidance",
        "PortableDesign",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2021 - Watching your phone's back gesture recognition by sensing acoustical structure-borne propagation.png",
      "doi": "https://doi.org/10.1145/3463522",
      "authors": "Wang Lei, Zhang Xiang, Jiang Yuanshuang, Zhang Yong, Xu Chenren, Gao Ruiyang, Zhang Daqing",
      "journal": "Proc ACM Interact Mob Wearable Ubiquitous Technol"
    },
    {
      "id": 98,
      "title": "A User-based Mid-air Hand Gesture Set for Spreadsheets",
      "year": "2021",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "Pinch",
        "SingleHand",
        "Swipe"
      ],
      "applicationScenarios": [
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2021-A User-based Mid-air Hand Gesture Set for Spreadsheets.png",
      "doi": "https://doi.org/10.1145/3429360.3468193",
      "authors": "Takayama Yuta, Ichikawa Yuu, Shizuki Buntarou, Kawaguchi Ikkaku, Takahashi Shin",
      "journal": "CHI '21: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 99,
      "title": "Leveraging the properties of mmWave signals for 3D finger motion tracking for interactive IoT applications",
      "year": "2022",
      "category": "software",
      "hardwareDevices": [
        "OtherDevices",
        "Smartphone",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "RFSensing",
        "RadarSensing"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "ContinuousRecognition",
        "FingerTracking",
        "HandTracking"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "Flex",
        "SignLanguageRelated",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AR",
        "AccessibilitySupport",
        "Healthcare",
        "IoTControl",
        "SmartHome",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2022 - Leveraging the properties of mmWave signals for 3D finger motion tracking for interactive IoT applications.png",
      "doi": "https://doi.org/10.1145/3570613",
      "authors": "Liu Yilin, Zhang Shijia, Gowda Mahanth, Nelakuditi Srihari",
      "journal": "Proc ACM Meas Anal Comput Syst"
    },
    {
      "id": 100,
      "title": "IndexPen Two Finger Text Input with Millimeter Wave Radar",
      "year": "2022",
      "category": "software",
      "hardwareDevices": [
        "OtherDevices",
        "Smartphone",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "RFSensing",
        "RadarSensing"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "AccessibilitySupport",
        "IoTControl",
        "SmartHome",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2022-IndexPen Two Finger Text Input with Millimeter Wave Radar.png",
      "doi": "https://doi.org/10.1145/3534619",
      "authors": "Yu Du, Yongquan Hu, Ke He, Yongkang Xing, Yubing Wang, Zhaojie Huang, Chun Yu, Yukang Yan, Yuanchun Shi",
      "journal": "IMWUT Proc. ACM Interact. Mob. Wearable Ubiquitous Technol."
    },
    {
      "id": 101,
      "title": "SoloFinger Robust Microgestures while Grasping Everyday Objects",
      "year": "2021",
      "category": "gesture-design",
      "hardwareDevices": [
        "DataGloves",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Flex",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "ObjectManipulation",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2021 - SoloFinger robust microgestures while grasping everyday objects.png",
      "doi": "https://doi.org/10.1145/3411764.3445197",
      "authors": "Sharma Adwait, Hedderich Michael A., Bhardwaj Divyanshu, Fruchard Bruno, McIntosh Jess, Nittala Aditya Shekhar, Klakow Dietrich, Ashbrook Daniel, Steimle Jürgen",
      "journal": "CHI '21: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 102,
      "title": "ARO Exploring the Design of Smart-Ring Interactions for Encumbered Hands",
      "year": "2021",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "CapacitiveSensor",
        "Gyroscope",
        "IMU"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "InAirGesture"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Grasp",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "ElicitationStudy",
        "EncumberedInteraction",
        "HandsFree",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2021-ARO Exploring the Design of Smart-Ring Interactions for Encumbered Hands.png",
      "doi": "https://doi.org/10.1145/3447526.3472037",
      "authors": "Bardot Sandra, Rawat Surya, Nguyen Duy Thai, Rempel Sawyer, Zheng Huizhe, Rey Bradley, Li Jun, Fan Kevin, Huang Da-Yuan, Li Wei, Irani Pourang",
      "journal": "MobileHCI '21: 23rd International Conference on Mobile Human-Computer Interaction"
    },
    {
      "id": 103,
      "title": "Enabling voice-accompanying hand-to-face gesture recognition with cross-device sensing",
      "year": "2023",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartRing",
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "UltrasonicSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "EarBasedInteraction",
        "MultiModalInteraction",
        "VoiceGestureCombined"
      ],
      "gestureTypes": [
        "SingleHand"
      ],
      "applicationScenarios": [
        "AR",
        "IoTControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "HandsFree",
        "LowLatency",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2023 - Enabling voice-accompanying hand-to-face gesture recognition with cross-device sensing.png",
      "doi": "https://doi.org/10.1145/3544548.3581008",
      "authors": "Li Zisu, Liang Chen, Wang Yuntao, Qin Yue, Yu Chun, Yan Yukang, Fan Mingming, Shi Yuanchun",
      "journal": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 104,
      "title": "iFAD Gestures Understanding Users’ Gesture Input Performance with Index-Finger Augmentation Devices",
      "year": "2023",
      "category": "software",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "DeviceContactGesture",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "SmartHome",
        "TextInput"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HandsFree",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2023-iFAD Gestures Understanding Users’ Gesture Input Performance with Index-Finger Augmentation Devices.png",
      "doi": "https://doi.org/10.1145/3544548.3580928",
      "authors": "Vatavu Radu-Daniel",
      "journal": "CHI '23: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 105,
      "title": "Persistent assistant seamless everyday AI interactions via intent grounding and multimodal feedback",
      "year": "2025",
      "category": "software",
      "hardwareDevices": [
        "ARGlasses",
        "HapticDevice",
        "SmartGlasses",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "GazeBased",
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased",
        "VoiceGestureCombined"
      ],
      "gestureTypes": [
        "Pinch",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AR",
        "Navigation",
        "SmartHome"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "HapticFeedback",
        "MultimodalFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "OneHandUse",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2025 - Persistent assistant seamless everyday AI interactions via intent grounding and multimodal feedback.png",
      "doi": "https://doi.org/10.1145/3706598.3714317",
      "authors": "Cho Hyunsung, Fashimpaur Jacqui, Sendhilnathan Naveen, Browder Jonathan, Lindlbauer David, Jonker Tanya R., Todi Kashyap",
      "journal": "CHI 2025: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 106,
      "title": "Grasp Interaction with Tablets",
      "year": "2011",
      "category": "software",
      "hardwareDevices": [
        "Tablet",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "CapacitiveSensor",
        "Gyroscope",
        "IMU",
        "Magnetometer"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DualHand",
        "Grasp",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "FatFingerProblem",
        "MidasTouchProblem",
        "OcclusionAvoidance",
        "OneHandUse",
        "SmallScreen",
        "TouchOptimized"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2011-Grasp Interaction with Tablets.png",
      "authors": "Wolf Katrin",
      "journal": "Springer International Publishing"
    },
    {
      "id": 107,
      "title": "Opportunistic synergy a classifier fusion engine for micro-gesture recognition",
      "year": "2013",
      "category": "software",
      "hardwareDevices": [
        "DrivingSimulator",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "BioSensor",
        "EMG",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "MultiModalInteraction",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Grasp",
        "Hold",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "InVehicleInteraction"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2013 - Opportunistic synergy a classifier fusion engine for micro-gesture recognition.png",
      "doi": "https://doi.org/10.1145/2516540.2516563",
      "authors": "Angelini Leonardo, Carrino Francesco, Carrino Stefano, Caon Maurizio, Lalanne Denis, Khaled Omar Abou, Mugellini Elena",
      "journal": "AutomotiveUI '13: Automotive User Interfaces and Interactive Vehicular Applications"
    },
    {
      "id": 109,
      "title": "The performance and preference of different fingers and chords for pointing, dragging, and object transformation",
      "year": "2016",
      "category": "gesture-design",
      "hardwareDevices": [
        "Tablet",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "Hold",
        "MultiTouch",
        "Pinch",
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "LowLatency",
        "TouchOptimized",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2016 - The performance and preference of different fingers and chords for pointing, dragging, and object transformation.png",
      "doi": "https://doi.org/10.1145/2858036.2858194",
      "authors": "Goguey Alix, Nancel Mathieu, Casiez Géry, Vogel Daniel",
      "journal": "CHI'16: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 110,
      "title": "BikeGesture user elicitation and performance of micro hand gesture as input for cycling",
      "year": "2017",
      "category": "hardware",
      "hardwareDevices": [
        "DataGloves",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "BioSensor",
        "IMU",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "Flex",
        "Grasp",
        "Pinch",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "AthleticActivity",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2017 - BikeGesture user elicitation and performance of micro hand gesture as input for cycling.png",
      "doi": "https://doi.org/10.1145/3027063.3053075",
      "authors": "Tan Yanke, Yoon Sang Ho, Ramani Karthik",
      "journal": "CHI '17: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 112,
      "title": "M[eye]cro eye-gaze+microgestures for multitasking and interruptions",
      "year": "2021",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "OpticalTracking",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "GazeBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "Pinch",
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "InVehicleInteraction",
        "ObjectManipulation",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "MultimodalFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "LowLatency",
        "MidasTouchProblem",
        "OneHandUse"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2021 - M[eye]cro eye-gaze+microgestures for multitasking and interruptions.png",
      "doi": "https://doi.org/10.1145/3461732",
      "authors": "Wambecke Jérémy, Goguey Alix, Nigay Laurence, Dargent Lauren, Hauret Daniel, Lafon Stéphanie, De Visme Jean-Samuel Louis",
      "journal": "Proc ACM Hum Comput Interact"
    },
    {
      "id": 115,
      "title": "AnyButton unpowered, modeless and highly available mobile input using unmodified clothing buttons",
      "year": "2014",
      "category": "hardware",
      "hardwareDevices": [
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "GestureRecognition",
        "HandTracking",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "HapticFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HandsFree",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2014 - AnyButton unpowered, modeless and highly available mobile input using unmodified clothing buttons.png",
      "doi": "https://doi.org/10.1145/2582051.2582075",
      "authors": "Chan Liwei, Weng Chien-Ting, Liang Rong-Hao, Chen Bing-Yu",
      "journal": "AH '14: 5th Augmented Human International Conference"
    },
    {
      "id": 116,
      "title": "Towards the establishment of a framework for intuitive multi-touch interaction design",
      "year": "2012",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone",
        "Tablet",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "HandTracking",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "MultiTouch",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "Navigation",
        "ObjectManipulation",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "HapticFeedback",
        "MultimodalFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "FatFingerProblem",
        "HighAccuracy",
        "OcclusionAvoidance",
        "TouchOptimized",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2012 - Towards the establishment of a framework for intuitive multi-touch interaction design.png",
      "doi": "https://doi.org/10.1145/2254556.2254571",
      "authors": "Ingram Amy, Wang Xiaoyu, Ribarsky William",
      "journal": "AVI'12: International Working Conference on Advanced Visual Interfaces"
    },
    {
      "id": 117,
      "title": "Grasping microgestures eliciting single-hand microgestures for handheld objects",
      "year": "2019",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "Smartphone"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "Magnetometer",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "DeviceContactGesture",
        "DirectTouch"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Grasp",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "IoTControl",
        "ObjectManipulation",
        "OtherScenarios",
        "SmartHome"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "ElicitationStudy",
        "EncumberedInteraction",
        "OneHandUse"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2019 - Grasping microgestures eliciting single-hand microgestures for handheld objects.png",
      "doi": "https://doi.org/10.1145/3290605.3300632",
      "authors": "Sharma Adwait, Roo Joan Sol, Steimle Jürgen",
      "journal": "CHI '19: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 118,
      "title": "Rhythmic micro-gestures discreet interaction on-the-go",
      "year": "2017",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Flex",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "MultimodalFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "MidasTouchProblem",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Rhythmic micro-gestures discreet interaction on-the-go.png",
      "doi": "https://doi.org/10.1145/3136755.3136815",
      "authors": "Freeman Euan, Griffiths Gareth, Brewster Stephen A.",
      "journal": "ICMI '17: International Conference on Multimodal Interaction"
    },
    {
      "id": 119,
      "title": "Studying the visual representation of microgestures",
      "year": "2023",
      "category": "gesture-design",
      "hardwareDevices": [
        "ARGlasses",
        "OtherDevices"
      ],
      "sensingTechnology": [
        "Magnetometer",
        "OtherTechnology"
      ],
      "recognitionClassification": [],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "Flex",
        "Hold",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "Education"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "ElicitationStudy",
        "OneHandUse"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2023 - Studying the visual representation of microgestures.png",
      "doi": "https://doi.org/10.1145/3604272",
      "authors": "Lambert Vincent, Chaffangeon Caillet Adrien, Goguey Alix, Malacria Sylvain, Nigay Laurence",
      "journal": "Proc ACM Hum Comput Interact"
    },
    {
      "id": 120,
      "title": "µGlyph a microgesture notation",
      "year": "2023",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices"
      ],
      "sensingTechnology": [
        "OtherTechnology"
      ],
      "recognitionClassification": [],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "NonContactBased"
      ],
      "gestureTypes": [
        "Flex",
        "Hold",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "Education"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "OneHandUse"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2023 - µGlyph a microgesture notation.png",
      "doi": "https://doi.org/10.1145/3544548.3580693",
      "authors": "Chaffangeon Caillet Adrien, Goguey Alix, Nigay Laurence",
      "journal": "CHI '23: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 121,
      "title": "User elicitation on single-hand microgestures",
      "year": "2016",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "ObjectManipulation",
        "TextInput"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EyesFree",
        "OneHandUse",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2016 - User elicitation on single-hand microgestures.png",
      "doi": "https://doi.org/10.1145/2858036.2858589",
      "authors": "Chan Edwin, Seyed Teddy, Stuerzlinger Wolfgang, Yang Xing-Dong, Maurer Frank",
      "journal": "CHI'16: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 122,
      "title": "Would you do that understanding social acceptance of gestural interfaces",
      "year": "2010",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "Smartphone"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "OtherScenarios",
        "SmartHome"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2010 - Would you do that understanding social acceptance of gestural interfaces.png",
      "doi": "https://doi.org/10.1145/1851600.1851647",
      "authors": "Montero Calkin S., Alexander Jason, Marshall Mark T., Subramanian Sriram",
      "journal": "MobileHCI '10: 12th International Conference on Human Computer Interaction with Mobile Devices and Services"
    },
    {
      "id": 123,
      "title": "Hands as a controller user preferences for hand specific on-skin gestures",
      "year": "2017",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "ComputerVision",
        "IMU",
        "RadarSensing",
        "UltrasonicSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "DualHand",
        "Pinch",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "InVehicleInteraction",
        "IoTControl",
        "MediaControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Hands as a controller user preferences for hand specific on-skin gestures.png",
      "doi": "https://doi.org/10.1145/3064663.3064766",
      "authors": "Bostan Idil, Buruk Oğuz Turan, Canat Mert, Tezcan Mustafa Ozan, Yurdakul Celalettin, Göksun Tilbe, Özcan Oğuzhan",
      "journal": "DIS '17: Designing Interactive Systems Conference 2017"
    },
    {
      "id": 124,
      "title": "Designing More Private and Socially Acceptable Hand-to-Face Gestures for Heads-Up Computing",
      "year": "2024",
      "category": "gesture-design",
      "hardwareDevices": [
        "ARGlasses",
        "SmartGlasses",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "OtherScenarios",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "ProprioceptiveFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2024-Designing More Private and Socially Acceptable Hand-to-Face Gestures for Heads-Up Computing.png",
      "doi": "https://doi.org/10.1145/3675094.3678994",
      "authors": "Gao Xing, Sun Minghui, Zhao Kaixing",
      "journal": "UbiComp '24: The 2024 ACM International Joint Conference on Pervasive and Ubiquitous Computing"
    },
    {
      "id": 125,
      "title": "Blind people and mobile touch-based text-entry acknowledging the need for different flavors",
      "year": "2011",
      "category": "software",
      "hardwareDevices": [
        "Smartphone",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "PressureSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "MultiTouch",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "TextInput"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "MultimodalFeedback"
      ],
      "userExperienceDesign": [
        "FatFingerProblem",
        "QWERTYLayout",
        "TouchOptimized",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2011 - Blind people and mobile touch-based text-entry acknowledging the need for different flavors.png",
      "authors": "Oliveira João, Guerreiro Tiago, Nicolau Hugo, Jorge Joaquim, Gonçalves Daniel",
      "journal": "The proceedings of the 13th international ACM SIGACCESS conference on Computers and accessibility"
    },
    {
      "id": 126,
      "title": "Interaction gestures for a wearable device defined by visually impaired children",
      "year": "2016",
      "category": "gesture-design",
      "hardwareDevices": [
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "Hold",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "Healthcare",
        "Training"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "MultimodalFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EyesFree",
        "OneHandUse",
        "PortableDesign",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2016 - Interaction gestures for a wearable device defined by visually impaired children.png",
      "doi": "https://doi.org/10.1145/2971485.2996752",
      "authors": "Magnusson Charlotte, Caltenco Héctor, Finocchietti Sara, Gori Monica, Cocchi Elena, Porquis Lope Ben, Baud-Bovy Gabriel",
      "journal": "NordiCHI '16: 9th Nordic Conference on Human-Computer Interaction"
    },
    {
      "id": 127,
      "title": "Investigating microinteractions for people with visual impairments and the potential role of on-body interaction",
      "year": "2017",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartWatch",
        "Smartphone",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "IMU",
        "MotionSensor",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "MediaControl",
        "Navigation",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Investigating microinteractions for people with visual impairments and the potential role of on-body interaction.png",
      "doi": "https://doi.org/10.1145/3132525.3132536",
      "authors": "Oh Uran, Stearns Lee, Pradhan Alisha, Froehlich Jon E., Findlater Leah",
      "journal": "ASSETS '17: The 19th International ACM SIGACCESS Conference on Computers and Accessibility"
    },
    {
      "id": 128,
      "title": "Static fingerspelling recognition based on boundary tracing algorithm and chain code",
      "year": "2018",
      "category": "software",
      "hardwareDevices": [
        "OtherDevices"
      ],
      "sensingTechnology": [
        "ComputerVision"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "NonContactBased"
      ],
      "gestureTypes": [
        "SignLanguageRelated",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AccessibilitySupport"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2018 - Static fingerspelling recognition based on boundary tracing algorithm and chain code.png",
      "doi": "https://doi.org/10.1145/3206185.3206195",
      "authors": "Dawod Ahmad Yahya, Nordin Md Jan, Abdullah Junaidi",
      "journal": "ISMSI '18: 2018 2nd International Conference on Intelligent Systems, Metaheuristics & Swarm Intelligence"
    },
    {
      "id": 129,
      "title": "Keep the phone in your pocket enabling smartphone operation with an IMU ring for visually impaired people",
      "year": "2020",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "Smartphone",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport"
      ],
      "feedbackOutput": [
        "AudioFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2020 - Keep the phone in your pocket enabling smartphone operation with an IMU ring for visually impaired people.png",
      "doi": "https://doi.org/10.1145/3397308",
      "authors": "Liu Guanhong, Gu Yizheng, Yin Yiwen, Yu Chun, Wang Yuntao, Mi Haipeng, Shi Yuanchun",
      "journal": "Proc ACM Interact Mob Wearable Ubiquitous Technol"
    },
    {
      "id": 130,
      "title": "Performance evaluation of pattern recognition networks using electromyography signal and time-domain features for the classification of hand gestures",
      "year": "2020",
      "category": "software",
      "hardwareDevices": [
        "WearableSensor"
      ],
      "sensingTechnology": [
        "BioSensor",
        "EMG"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased"
      ],
      "gestureTypes": [
        "Flex",
        "Grasp",
        "SingleHand",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "Healthcare"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "CommunicationAid",
        "HighAccuracy"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2020 - Performance evaluation of pattern recognition networks using electromyography signal and time-domain features for the cl.png",
      "doi": "https://doi.org/10.1177/0954411920912119",
      "authors": "Vasanthi S. Mary, Jayasree T.",
      "journal": "Proc Inst Mech Eng H: J Eng Med"
    },
    {
      "id": 131,
      "title": "Keep in touch combining touch interaction with thumb-to-finger µGestures for people with visual impairment",
      "year": "2022",
      "category": "software",
      "hardwareDevices": [
        "Tablet",
        "TouchScreen",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "Education",
        "Navigation"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "MultimodalFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "CommunicationAid",
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "OneHandUse",
        "TouchOptimized"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2022 - Keep in touch combining touch interaction with thumb-to-finger µGestures for people with visual impairment.png",
      "doi": "https://doi.org/10.1145/3536221.3556589",
      "authors": "Faisandaz Gauthier Robert Jean, Goguey Alix, Jouffrais Christophe, Nigay Laurence",
      "journal": "ICMI '22: International Conference on Multimodal Interaction"
    },
    {
      "id": 132,
      "title": "µGeT multimodal eyes-free text selection technique combining touch interaction and microgestures",
      "year": "2023",
      "category": "software",
      "hardwareDevices": [
        "Tablet",
        "TouchScreen",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "ComputerVision"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "Hold",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "TextInput"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "OneHandUse",
        "TouchOptimized"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2023 - µGeT multimodal eyes-free text selection technique combining touch interaction and microgestures.png",
      "doi": "https://doi.org/10.1145/3577190.3614131",
      "authors": "Faisandaz Gauthier Robert Jean, Goguey Alix, Jouffrais Christophe, Nigay Laurence",
      "journal": "ICMI '23: International Conference on Multimodal Interaction"
    },
    {
      "id": 133,
      "title": "Designing upper-body gesture interaction with and for people with spinal muscular atrophy in VR",
      "year": "2024",
      "category": "gesture-design",
      "hardwareDevices": [
        "VRHeadset",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "ComputerVision"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "GazeBased",
        "InAirGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "VR"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HandsFree",
        "OneHandUse",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2024 - Designing upper-body gesture interaction with and for people with spinal muscular atrophy in VR.png",
      "doi": "https://doi.org/10.1145/3613904.364288",
      "authors": "Tian Jingze, Wang Yingna, Yu Keye, Xu Liyi, Xie Junan, Li Franklin Mingzhe, Niu Yafeng, Fan Mingming",
      "journal": "Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 134,
      "title": "Finger gesture tracking for interactive applications a pilot study with sign languages",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartRing",
        "SmartWatch",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "SignLanguageRelated",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "Education"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "LowLatency",
        "PortableDesign",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Finger gesture tracking for interactive applications a pilot study with sign languages.png",
      "doi": "https://doi.org/10.1145/3414117",
      "authors": "Liu Yilin, Jiang Fengyang, Gowda Mahanth",
      "journal": "Proc ACM Interact Mob Wearable Ubiquitous Technol"
    },
    {
      "id": 135,
      "title": "A non-linear model of shape  and motion for tracking finger spelt American sign language",
      "year": "2002",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "HandTracking",
        "MotionAnalysis",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "SignLanguageRelated",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "Education"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2002-A non-linear model of shape  and motion for tracking finger spelt American sign language.png",
      "doi": "https://doi.org/10.1016/S0262-8856(02)00049-5",
      "authors": "Bowden Richard, Sarhadi Mansoor",
      "journal": "Image Vision Comput"
    },
    {
      "id": 140,
      "title": "WristFlex- low-power gesture input with wrist-worn pressure sensors",
      "year": "2014",
      "category": "hardware",
      "hardwareDevices": [
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "Pinch",
        "SingleHand",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AthleticActivity",
        "IoTControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2014 - WristFlex- low-power gesture input with wrist-worn pressure sensors.png",
      "doi": "https://doi.org/10.1145/2642918.2647396",
      "authors": "Dementyev Artem, Paradiso Joseph A.",
      "journal": "UIST '14: The 27th Annual ACM Symposium on User Interface Software and Technology"
    },
    {
      "id": 141,
      "title": "CyclopsRing- Enabling Whole-Hand and  Context-Aware Interactions Through a Fisheye Ring",
      "year": "2015",
      "category": "hardware",
      "hardwareDevices": [
        "OtherDevices",
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming",
        "IoTControl",
        "SmartHome",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HandsFree",
        "OneHandUse",
        "PortableDesign",
        "QWERTYLayout"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2015 - CyclopsRing- Enabling Whole-Hand and  Context-Aware Interactions Through a Fisheye Ring.png",
      "doi": "https://doi.org/10.1145/2807442.2807450",
      "authors": "Chan Liwei, Chen Yi-Ling, Hsieh Chi-Hao, Liang Rong-Hao, Chen Bing-Yu",
      "journal": "UIST '15: The 28th Annual ACM Symposium on User Interface Software and Technology"
    },
    {
      "id": 142,
      "title": "Combining Ring Input with Hand  Tracking for Precise, Natural Interaction with Spatial Analytic Interfaces",
      "year": "2016",
      "category": "software",
      "hardwareDevices": [
        "ARGlasses",
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "ComputerVision",
        "DepthSensing",
        "IMU",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "ContinuousRecognition",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Grasp",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "Navigation",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "PortableDesign"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2016 - Combining Ring Input with Hand  Tracking for Precise, Natural Interaction with Spatial Analytic Interfaces..png",
      "doi": "https://doi.org/10.1145/2983310.2985757",
      "authors": "Ens Barrett, Byagowi Ahmad, Han Teng, Hincapié-Ramos Juan David, Irani Pourang",
      "journal": "SUI '16: Symposium on Spatial User Interaction"
    },
    {
      "id": 143,
      "title": "DigitSpace Designing Thumb-to-Fingers Touch Interfaces for One-Handed and Eyes-Free Interactions",
      "year": "2016",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "OpticalTracking",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "TextInput"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EyesFree",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2016 - DigitSpace Designing Thumb-to-Fingers Touch Interfaces for One-Handed and Eyes-Free Interactions.png",
      "doi": "https://doi.org/10.1145/2858036.2858483",
      "authors": "Huang Da-Yuan, Chan Liwei, Yang Shuo, Wang Fan, Liang Rong-Hao, Yang De-Nian, Hung Yi-Ping, Chen Bing-Yu",
      "journal": "CHI'16: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 144,
      "title": "ThumbRing- private interactions using one-handed thumb motion input on  finger segments",
      "year": "2016",
      "category": "hardware",
      "hardwareDevices": [
        "ARGlasses",
        "SmartGlasses",
        "SmartRing",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "Magnetometer",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "GestureRecognition",
        "MotionAnalysis",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2016 - ThumbRing- private interactions using one-handed thumb motion input on  finger segments.png",
      "doi": "https://doi.org/10.1145/2957265.2961859",
      "authors": "Tsai Hsin-Ruey, Wu Cheng-Yuan, Huang Lee-Ting, Hung Yi-Ping",
      "journal": "MobileHCI '16: 18th International Conference on Human-Computer Interaction with Mobile Devices and Services"
    },
    {
      "id": 145,
      "title": "Interacting with Soli- Exploring Fine-Grained Dynamic  Gesture Recognition in the Radio-Frequency Spectrum",
      "year": "2016",
      "category": "software",
      "hardwareDevices": [
        "OtherDevices",
        "Wearables"
      ],
      "sensingTechnology": [
        "RFSensing",
        "RadarSensing"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "IoTControl",
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "OcclusionAvoidance"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2016-Interacting with Soli- Exploring Fine-Grained Dynamic  Gesture Recognition in the Radio-Frequency Spectrum.png",
      "doi": "https://doi.org/10.1145/2984511.2984565",
      "authors": "Wang Saiwen, Song Jie, Lien Jaime, Poupyrev Ivan, Hilliges Otmar",
      "journal": "UIST '16: The 29th Annual ACM Symposium on User Interface Software and Technology"
    },
    {
      "id": 146,
      "title": "Soli- Ubiquitous Gesture Sensing with Millimeter Wave Radar",
      "year": "2016",
      "category": "hardware",
      "hardwareDevices": [
        "OtherDevices",
        "SmartWatch",
        "VRHeadset",
        "Wearables"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "RFSensing",
        "RadarSensing"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "Gaming",
        "IoTControl",
        "MediaControl",
        "Navigation",
        "SmartHome",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "OcclusionAvoidance",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2016-Soli- Ubiquitous Gesture Sensing with Millimeter Wave Radar..png",
      "doi": "https://doi.org/10.1145/2897824.2925953",
      "authors": "Lien Jaime, Gillian Nicholas, Karagozler M. Emre, Amihood Patrick, Schwesig Carsten, Olson Erik, Raja Hakim, Poupyrev Ivan",
      "journal": "ACM Trans Graphics"
    },
    {
      "id": 147,
      "title": "TouchRing- Subtle and  Always-Available Input Using a Multi-Touch Ring",
      "year": "2016",
      "category": "hardware",
      "hardwareDevices": [
        "SmartGlasses",
        "SmartRing",
        "TouchScreen",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "MultiTouch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability",
        "TouchOptimized"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2016-TouchRing- Subtle and  Always-Available Input Using a Multi-Touch Ring.png",
      "doi": "https://doi.org/10.1145/2957265.2961860",
      "authors": "Tsai Hsin-Ruey, Hsiu Min-Chieh, Hsiao Jui-Chun, Huang Lee-Ting, Chen Mike, Hung Yi-Ping",
      "journal": "MobileHCI '16: 18th International Conference on Human-Computer Interaction with Mobile Devices and Services"
    },
    {
      "id": 148,
      "title": "DigiTouch- Reconfigurable Thumb-to-Finger Input and Text Entry on Head-mounted Displays",
      "year": "2017",
      "category": "hardware",
      "hardwareDevices": [
        "ARGlasses",
        "DataGloves",
        "VRHeadset",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture"
      ],
      "gestureTypes": [
        "Hold",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "ProprioceptiveFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "OcclusionAvoidance",
        "PortableDesign",
        "QWERTYLayout",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2017 - DigiTouch- Reconfigurable Thumb-to-Finger Input and Text Entry on Head-mounted Displays.png",
      "doi": "https://doi.org/10.1145/3130978",
      "authors": "Whitmire Eric, Jain Mohit, Jain Divye, Nelson Greg, Karkar Ravi, Patel Shwetak, Goel Mayank",
      "journal": "Proc ACM Interact Mob Wearable Ubiquitous Technol"
    },
    {
      "id": 149,
      "title": "FingerSound- Recognizing unistroke thumb gestures using a ring",
      "year": "2017",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Gyroscope",
        "MotionSensor",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl",
        "SmartHome",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "HapticFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "MidasTouchProblem",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2017 - FingerSound- Recognizing unistroke thumb gestures using a ring..png",
      "doi": "https://doi.org/10.1145/3130985",
      "authors": "Zhang Cheng, Waghmare Anandghan, Kundra Pranav, Pu Yiming, Gilliland Scott, Ploetz Thomas, Starner Thad E., Inan Omer T., Abowd Gregory D.",
      "journal": "Proc ACM Interact Mob Wearable Ubiquitous Technol"
    },
    {
      "id": 152,
      "title": "Fingert9- Leveraging  thumb-to-finger interaction for same-side-hand text entry on smartwatches",
      "year": "2018",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartWatch",
        "TouchScreen",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "Hold",
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "TextInput"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EyesFree",
        "OcclusionAvoidance",
        "OneHandUse",
        "SmallScreen",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Fingert9- Leveraging  thumb-to-finger interaction for same-side-hand text entry on smartwatches.png",
      "doi": "https://doi.org/10.1145/3173574.3173752",
      "authors": "Wong Pui Chung, Zhu Kening, Fu Hongbo",
      "journal": "CHI '18: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 153,
      "title": "ThumbText- Text Entry for Wearable Devices Using a Miniature Ring",
      "year": "2018",
      "category": "hardware",
      "hardwareDevices": [
        "SmartGlasses",
        "SmartRing",
        "SmartWatch",
        "TouchScreen",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Hold",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "TextInput"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "OcclusionAvoidance",
        "OneHandUse",
        "PortableDesign",
        "SmallScreen",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2018 - ThumbText- Text Entry for Wearable Devices Using a Miniature Ring.png",
      "authors": "Kim Junhyeok, Delamare William, Irani Pourang",
      "journal": "Graphics Interface"
    },
    {
      "id": 154,
      "title": "Tip-tap- battery-free discrete 2D fingertip input",
      "year": "2019",
      "category": "hardware",
      "hardwareDevices": [
        "DataGloves",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "RFSensing"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "Healthcare",
        "IndustryApplication",
        "MediaControl"
      ],
      "feedbackOutput": [
        "HapticFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HandsFree",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2019- Tip-tap- battery-free discrete 2D fingertip input..png",
      "doi": "https://doi.org/10.1145/3332165.3347907",
      "authors": "Katsuragawa Keiko, Wang Ju, Shan Ziyang, Ouyang Ningshan, Abari Omid, Vogel Daniel",
      "journal": "UIST '19: The 32nd Annual ACM Symposium on User Interface Software and Technology"
    },
    {
      "id": 155,
      "title": "The missing interface- Micro-gestures on augmented objects",
      "year": "2019",
      "category": "gesture-design",
      "hardwareDevices": [
        "ARGlasses",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "RFSensing",
        "RadarSensing"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe"
      ],
      "applicationScenarios": [
        "AR",
        "IndustryApplication",
        "Training"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "OcclusionAvoidance",
        "OneHandUse",
        "PortableDesign"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2019-The missing interface- Micro-gestures on augmented objects.png",
      "doi": "https://doi.org/10.1145/3290607.3312986",
      "authors": "Čopič Pucihar Klen, Sandor Christian, Kljun Matjaž, Huerst Wolfgang, Plopski Alexander, Taketomi Takafumi, Kato Hirokazu, Leiva Luis A.",
      "journal": "CHI '19: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 156,
      "title": "QwertyRing- Text Entry on Physical Surfaces  Using a Ring",
      "year": "2020",
      "category": "hardware",
      "hardwareDevices": [
        "ARGlasses",
        "SmartRing",
        "VRHeadset",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture"
      ],
      "gestureTypes": [
        "Hold",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "SmartHome",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "OneHandUse",
        "PortableDesign",
        "QWERTYLayout",
        "TouchOptimized",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2020 - . QwertyRing- Text Entry on Physical Surfaces  Using a Ring..png",
      "doi": "https://doi.org/10.1145/3432204",
      "authors": "Gu Yizheng, Yu Chun, Li Zhipeng, Li Zhaoheng, Wei Xiaoying, Shi Yuanchun",
      "journal": "Proc ACM Interact Mob Wearable Ubiquitous Technol"
    },
    {
      "id": 157,
      "title": "BiTipText- Bimanual Eyes-Free Text Entry on a Fingertip Keyboard ",
      "year": "2020",
      "category": "hardware",
      "hardwareDevices": [
        "SmartGlasses",
        "SmartWatch",
        "TouchScreen",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "DualHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "PortableDesign",
        "QWERTYLayout",
        "TouchOptimized",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2020-BiTipText- Bimanual Eyes-Free Text Entry on a Fingertip Keyboard.png",
      "doi": "https://doi.org/10.1145/3313831.3376306",
      "authors": "Xu Zheer, Chen Weihao, Zhao Dongyang, Luo Jiehui, Wu Te-Yen, Gong Jun, Yin Sicheng, Zhai Jialun, Yang Xing-Dong",
      "journal": "CHI '20: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 158,
      "title": "EarBuddy- Enabling On-Face Interaction via Wireless Earbuds",
      "year": "2020",
      "category": "software",
      "hardwareDevices": [
        "Smartphone",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "BioSensor",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "EarBasedInteraction"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "MediaControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2020-EarBuddy- Enabling On-Face Interaction via Wireless Earbuds.png",
      "doi": "https://doi.org/10.1145/3313831.3376836",
      "authors": "Xu Xuhai, Shi Haitian, Yi Xin, Liu WenJia, Yan Yukang, Shi Yuanchun, Mariakakis Alex, Mankoff Jennifer, Dey Anind K.",
      "journal": "CHI '20: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 159,
      "title": "Ready, Steady, Touch! Sensing  Physical Contact with a Finger-Mounted IMU",
      "year": "2020",
      "category": "hardware",
      "hardwareDevices": [
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "Magnetometer"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "ContactBased",
        "DeviceContactGesture",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl",
        "Navigation",
        "SmartHome",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "PortableDesign",
        "SocialAcceptability",
        "TouchOptimized"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2020-Ready, Steady, Touch! Sensing  Physical Contact with a Finger-Mounted IMU.png",
      "doi": "https://doi.org/10.1145/3397309",
      "authors": "Shi Yilei, Zhang Haimo, Zhao Kaixing, Cao Jiashuo, Sun Mengmeng, Nanayakkara Suranga",
      "journal": "Proc ACM Interact Mob Wearable Ubiquitous Technol"
    },
    {
      "id": 162,
      "title": "Design of 3D Microgestures for Commands in Virtual Reality or Augmented Reality",
      "year": "2023",
      "category": "gesture-design",
      "hardwareDevices": [
        "ARGlasses",
        "TouchScreen",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Grasp",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming",
        "MediaControl",
        "Navigation",
        "ObjectManipulation",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2023- Design of 3D Microgestures for Commands in Virtual Reality or Augmented Reality.png",
      "doi": "https://doi.org/10.3390/app11146375",
      "authors": "Li Guangchuan, Rempel David, Liu Yue, Song Weitao, Adamson Carisa Harris",
      "journal": "Appl Sci"
    },
    {
      "id": 164,
      "title": "Abracadabra Wireless, High-Precision, and Unpowered Finger Input for Very Small Mobile Devices",
      "year": "2009",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "SmartWatch",
        "Wearables"
      ],
      "sensingTechnology": [
        "Magnetometer",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Flex",
        "Hold",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "PortableDesign",
        "SmallScreen"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2009-Abracadabra Wireless, High-Precision, and Unpowered Finger Input for Very Small Mobile Devices.png",
      "doi": "https://doi.org/10.1145/1622176.1622199",
      "authors": "Harrison Chris, Hudson Scott E.",
      "journal": "UIST '09: The 22nd Annual ACM Symposium on User Interface Software and Technology"
    },
    {
      "id": 165,
      "title": "Digits Freehand 3D Interactions Anywhere Using a Wrist-Worn Gloveless Sensor",
      "year": "2012",
      "category": "hardware",
      "hardwareDevices": [
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "IMU",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "ContinuousRecognition",
        "FingerTracking",
        "HandTracking"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "Flex",
        "Grasp",
        "Pinch",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming",
        "MR",
        "ObjectManipulation",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "PortableDesign"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2012-Digits Freehand 3D Interactions Anywhere Using a Wrist-Worn Gloveless Sensor.png",
      "doi": "https://doi.org/10.1145/2380116.2380139",
      "authors": "Kim David, Hilliges Otmar, Izadi Shahram, Butler Alex D., Chen Jiawen, Oikonomidis Iason, Olivier Patrick",
      "journal": "UIST '12: The 25th Annual ACM Symposium on User Interface Software and Technology"
    },
    {
      "id": 166,
      "title": "TIMMi Finger-worn Textile Input Device with Multimodal Sensing in Mobile Interaction",
      "year": "2015",
      "category": "hardware",
      "hardwareDevices": [
        "Etextile",
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "OtherTechnology",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "Flex",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2015-TIMMi Finger-worn Textile Input Device with Multimodal Sensing in Mobile Interaction.png",
      "doi": "https://doi.org/10.1145/2677199.2680560",
      "authors": "Yoon Sang Ho, Huo Ke, Nguyen Vinh P., Ramani Karthik",
      "journal": "TEI '15: Ninth International Conference on Tangible, Embedded, and Embodied Interaction"
    },
    {
      "id": 167,
      "title": "User-Defined Game Input for Smart Glasses in Public Space",
      "year": "2015",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartGlasses"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "ElicitationStudy",
        "EyesFree",
        "HandsFree",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2015-User-Defined Game Input for Smart Glasses in Public Space.png",
      "doi": "https://doi.org/10.1145/2702123.2702214",
      "authors": "Tung Ying-Chao, Hsu Chun-Yen, Wang Han-Yu, Chyou Silvia, Lin Jhe-Wei, Wu Pei-Jung, Valstar Andries, Chen Mike Y.",
      "journal": "CHI '15: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 168,
      "title": "zSense Enabling Shallow Depth Gesture Recognition for Greater Input Expressivity on Smart Wearables",
      "year": "2015",
      "category": "hardware",
      "hardwareDevices": [
        "SmartGlasses",
        "SmartRing",
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "DepthSensing",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "PortableDesign",
        "SmallScreen"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2015-zSense Enabling Shallow Depth Gesture Recognition for Greater Input Expressivity on Smart Wearables.png",
      "doi": "https://doi.org/10.1145/2702123.2702371",
      "authors": "Withana Anusha, Peiris Roshan, Samarasekara Nipuna, Nanayakkara Suranga",
      "journal": "CHI '15: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 171,
      "title": "A Usability User Study Concerning Free-Hand Microgesture and Wrist-Worn Sensors",
      "year": "2014",
      "category": "software",
      "hardwareDevices": [
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "DepthSensing",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "NonContactBased"
      ],
      "gestureTypes": [
        "DualHand",
        "Flex",
        "Pinch",
        "SingleHand"
      ],
      "applicationScenarios": [
        "IndustryApplication",
        "MediaControl",
        "Navigation",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "OneHandUse",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2014-A Usability User Study Concerning Free-Hand Microgesture and Wrist-Worn Sensors.png",
      "doi": "https://doi.org/10.1109/BSN.2014.32",
      "authors": "Way David, Paradiso Joseph",
      "journal": "2014 11th International Conference on Wearable and Implantable Body Sensor Networks (BSN)"
    },
    {
      "id": 172,
      "title": "A Taxonomy of Microinteractions Defining Microgestures based on Ergonomic and Scenario-dependent Requirements",
      "year": "2011",
      "category": "gesture-design",
      "hardwareDevices": [
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "DepthSensing",
        "EMG",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "Grasp",
        "Pinch",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "InVehicleInteraction",
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "MultimodalFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EncumberedInteraction",
        "EyesFree",
        "OneHandUse"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2011-A Taxonomy of Microinteractions Defining Microgestures based on Ergonomic and Scenario-dependent Requirements.png",
      "authors": "Wolf Katrin, Naumann Anja, Rohs Michael, Müller Jörg",
      "journal": "Springer Berlin Heidelberg"
    },
    {
      "id": 173,
      "title": "DigiTap- an eyes-free VR:AR symbolic input device.",
      "year": "2014",
      "category": "hardware",
      "image": "Papers/HARDWARE/Hardware预览图/2014 - DigiTap- an eyes-free VR:AR symbolic input device..png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": [],
      "doi": "https://doi.org/10.1145/2671015.2671029",
      "authors": "Prätorius Manuel, Valkov Dimitar, Burgbacher Ulrich, Hinrichs Klaus",
      "journal": "VRST '14: The 20th ACM Symposium on Virtual Reality Software and Technology"
    },
    {
      "id": 174,
      "title": "LightRing- Always-Available 2D Input on Any Surface.",
      "year": "2014",
      "category": "hardware",
      "image": "Papers/HARDWARE/Hardware预览图/2014 - LightRing- Always-Available 2D Input on Any Surface..png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": [],
      "doi": "https://doi.org/10.1145/2642918.2647376",
      "authors": "Kienzle Wolf, Hinckley Ken",
      "journal": "UIST '14: The 27th Annual ACM Symposium on User Interface Software and Technology"
    },
    {
      "id": 175,
      "title": "OptiRing Low-Resolution Optical Sensing for Subtle Thumb-to-Index Input",
      "year": "2023",
      "category": "hardware",
      "image": "Papers/HARDWARE/Hardware预览图/2023 -  OptiRing Low-Resolution Optical Sensing for Subtle Thumb-to-Index Input.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": [],
      "doi": "https://doi.org/10.1145/3607822.3614538",
      "authors": "Waghmare Anandghan, Boldu Roger, Whitmire Eric, Kienzle Wolf",
      "journal": "SUI '23: ACM Symposium on Spatial User Interaction"
    },
    {
      "id": 176,
      "title": "PinchWatch  A Wearable Device for One-Handed Microinteractions",
      "year": "2010",
      "category": "hardware",
      "image": "Papers/HARDWARE/Hardware预览图/2010-PinchWatch  A Wearable Device for One-Handed Microinteractions.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": [],
      "authors": "Loclair Christian, Gustafson Sean, Baudisch Patrick",
      "journal": "Proc MobileHCI"
    },
    {
      "id": 177,
      "title": "iSkin Flexible, Stretchable and Visually Customizable On-Body Touch Sensors for Mobile Computing",
      "year": "2015",
      "category": "hardware",
      "image": "Papers/HARDWARE/Hardware预览图/2015-iSkin Flexible, Stretchable and Visually Customizable On-Body Touch Sensors for Mobile Computing.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": [],
      "doi": "https://doi.org/10.1145/2702123.2702391",
      "authors": "Weigel Martin, Lu Tong, Bailly Gilles, Oulasvirta Antti, Majidi Carmel, Steimle Jürgen",
      "journal": "CHI '15: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 178,
      "title": "Pyro thumb-tip gesture recognition using pyroelectric infrared sensing",
      "year": "2017",
      "category": "hardware",
      "image": "Papers/HARDWARE/Hardware预览图/2017 - Pyro thumb-tip gesture recognition using pyroelectric infrared sensing.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": [],
      "doi": "https://doi.org/10.1145/3126594.3126615",
      "authors": "Gong Jun, Zhang Yang, Zhou Xia, Yang Xing-Dong",
      "journal": "UIST '17: The 30th Annual ACM Symposium on User Interface Software and Technology"
    },
    {
      "id": 179,
      "title": "FingerPad-  private and subtle interaction using fingertips",
      "year": "2013",
      "category": "hardware",
      "image": "Papers/HARDWARE/Hardware预览图/2013 - FingerPad-  private and subtle interaction using fingertips.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": [],
      "doi": "https://doi.org/10.1145/2501988.2502016",
      "authors": "Chan Liwei, Liang Rong-Hao, Tsai Ming-Chang, Cheng Kai-Yin, Su Chao-Huai, Chen Mike Y., Cheng Wen-Huang, Chen Bing-Yu",
      "journal": "UIST'13: The 26th Annual ACM Symposium on User Interface Software and Technology"
    },
    {
      "id": 180,
      "title": "Skinmarks Enabling interactions on body landmarks using conformal skin electronics",
      "year": "2017",
      "category": "hardware",
      "image": "Papers/HARDWARE/Hardware预览图/2017-Skinmarks Enabling interactions on body landmarks using conformal skin electronics.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": [],
      "doi": "https://doi.org/10.1145/3025453.3025704",
      "authors": "Weigel Martin, Nittala Aditya Shekhar, Olwal Alex, Steimle Jürgen",
      "journal": "CHI '17: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 181,
      "title": "Press-n-paste copy-and-paste operations with pressure-sensitive caret navigation for miniaturized surface in mobile aug",
      "year": "2021",
      "category": "software",
      "image": "Papers/SOFTWARE/Software预览图/2021 - Press-n-paste copy-and-paste operations with pressure-sensitive caret navigation for miniaturized surface in mobile aug.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": [],
      "doi": "https://doi.org/10.1145/3457146",
      "authors": "Lee Lik Hang, Zhu Yiming, Yau Yui-Pan, Hui Pan, Pirttikangas Susanna",
      "journal": "Proc ACM Hum Comput Interact"
    },
    {
      "id": 182,
      "title": "Vulture- A Mid-Air Word-Gesture Keyboard",
      "year": "2014",
      "category": "software",
      "image": "Papers/SOFTWARE/Software预览图/2014 - Vulture- A Mid-Air Word-Gesture Keyboard.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": [],
      "doi": "https://doi.org/10.1145/2556288.2556964",
      "authors": "Markussen Anders, Jakobsen Mikkel Rønne, Hornbæk Kasper",
      "journal": "CHI '14: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 183,
      "title": "The intuitive grasp interface design and evaluation of micro-gestures on the steering wheel for driving scenario",
      "year": "2020",
      "category": "gesture-design",
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - The intuitive grasp interface design and evaluation of micro-gestures on the steering wheel for driving scenario.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": [],
      "doi": "https://doi.org/10.1007/s10209-019-00647-0",
      "authors": "Xiao Yiqi, He Renke",
      "journal": "Univers Access Inf Soc"
    },
    {
      "id": 184,
      "title": "Transferable Microgestures Across Hand Posture and Location Constraints- Leveraging the Middle, Ring, and Pinky Fingers",
      "year": "2023",
      "category": "gesture-design",
      "image": "Papers/GestureDesign/GestureDesign预览图/2023 - Transferable Microgestures Across Hand Posture and Location Constraints- Leveraging the Middle, Ring, and Pinky Fingers.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": [],
      "doi": "https://doi.org/10.1145/3586183.3606713",
      "authors": "Joshi Nikhita, Abtahi Parastoo, Sodhi Raj, Bartov Nitzan, Rushing Jackson, Collins Christopher, Vogel Daniel, Glueck Michael",
      "journal": "UIST '23: The 36th Annual ACM Symposium on User Interface Software and Technology"
    },
    {
      "id": 185,
      "title": "Segtouch",
      "year": "2017",
      "category": "gesture-design",
      "image": "Papers/GestureDesign/GestureDesign预览图/2017-Segtouch.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": [],
      "doi": "https://doi.org/10.1145/3027063.3053109",
      "authors": "Tsai Hsin-Ruey, Wu Te-Yen, Huang Da-Yuan, Hsiu Min-Chieh, Hsiao Jui-Chun, Hung Yi-Ping, Chen Mike Y., Chen Bing-Yu",
      "journal": "CHI '17: CHI Conference on Human Factors in Computing Systems"
    },
    {
      "id": 186,
      "title": "Arpège learning multitouch chord gestures vocabularies",
      "year": "2013",
      "category": "gesture-design",
      "image": "Papers/GestureDesign/GestureDesign预览图/2013 - Arpège learning multitouch chord gestures vocabularies.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": [],
      "doi": "https://doi.org/10.1145/2512349.2512795",
      "authors": "Ghomi Emilien, Huot Stéphane, Bau Olivier, Beaudouin-Lafon Michel, Mackay Wendy E.",
      "journal": "ITS '13: The ACM International Conference on Interactive Tabletops and Surfaces"
    },
    {
      "id": 187,
      "title": "PalmType Using Palms as Keyboards for Smart Glasses",
      "year": "2015",
      "category": "gesture-design",
      "image": "Papers/GestureDesign/GestureDesign预览图/2015-PalmType Using Palms as Keyboards for Smart Glasses.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": [],
      "doi": "https://doi.org/10.1145/2785830.2785886",
      "authors": "Wang Cheng-Yao, Chu Wei-Chen, Chiu Po-Tsung, Hsiu Min-Chieh, Chiang Yih-Harn, Chen Mike Y.",
      "journal": "MobileHCI '15: 17th International Conference on Human-Computer Interaction with Mobile Devices and Services"
    }
  ],
  "categories": {
    "hardware": [
      {
        "id": 1,
        "title": "Towards keyboard independent touch typing in VR",
        "year": "2005",
        "category": "hardware",
        "hardwareDevices": [
          "DataGloves",
          "Keyboard",
          "VRHeadset",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Pinch",
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "DigitalArt",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "OneHandUse",
          "TouchOptimized"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2005 - Towards keyboard independent touch typing in VR.png"
      },
      {
        "id": 2,
        "title": "Demonstrating the feasibility of using forearm electromyography for muscle-computer interfaces",
        "year": "2008",
        "category": "hardware",
        "hardwareDevices": [
          "WearableSensor"
        ],
        "sensingTechnology": [
          "BioSensor",
          "EMG"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "Hold",
          "Pinch",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "InVehicleInteraction",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HandsFree",
          "HighAccuracy",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2008 - Demonstrating the feasibility of using forearm electromyography for muscle-computer interfaces.png"
      },
      {
        "id": 3,
        "title": "Hand gesture recognition and virtual game control based on 3D accelerometer and EMG sensors",
        "year": "2009",
        "category": "hardware",
        "hardwareDevices": [
          "WearableSensor"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "BioSensor",
          "EMG",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand"
        ],
        "applicationScenarios": [
          "Gaming",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "LowLatency",
          "PortableDesign"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2009 - Hand gesture recognition and virtual game control based on 3D accelerometer and EMG sensors.png"
      },
      {
        "id": 4,
        "title": "A prototype of gesture-based interface",
        "year": "2011",
        "category": "hardware",
        "hardwareDevices": [
          "Smartphone",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "BioSensor",
          "EMG"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Flex",
          "SingleHand"
        ],
        "applicationScenarios": [
          "InVehicleInteraction",
          "MediaControl"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2011 - A prototype of gesture-based interface.png"
      },
      {
        "id": 6,
        "title": "Augmenting the input space of portable displays using add-on hall-sensor grid",
        "year": "2013",
        "category": "hardware",
        "hardwareDevices": [
          "Smartphone",
          "Tablet",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Magnetometer",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "DirectTouch",
          "NonContactBased",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Pinch",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "Gaming",
          "MediaControl",
          "Navigation",
          "TextInput"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "OcclusionAvoidance",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2013 - Augmenting the input space of portable displays using add-on hall-sensor grid.png"
      },
      {
        "id": 7,
        "title": "EarPut augmenting ear-worn devices for ear-based interaction",
        "year": "2014",
        "category": "hardware",
        "hardwareDevices": [
          "OtherDevices",
          "Smartphone",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "DirectTouch",
          "EarBasedInteraction",
          "InAirGesture"
        ],
        "gestureTypes": [
          "MultiTouch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "Gaming",
          "MediaControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "HapticFeedback",
          "ProprioceptiveFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2014 - EarPut augmenting ear-worn devices for ear-based interaction.png"
      },
      {
        "id": 8,
        "title": "Advancing muscle-computer interfaces with high-density electromyography",
        "year": "2015",
        "category": "hardware",
        "hardwareDevices": [
          "WearableSensor"
        ],
        "sensingTechnology": [
          "BioSensor",
          "EMG"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "NonContactBased"
        ],
        "gestureTypes": [
          "Flex",
          "Pinch",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "IoTControl",
          "MediaControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HandsFree",
          "HighAccuracy",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2015 - Advancing muscle-computer interfaces with high-density electromyography.png"
      },
      {
        "id": 9,
        "title": "eRing multiple finger gesture recognition with one ring using an electric field",
        "year": "2015",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "IoTControl",
          "OtherScenarios",
          "SmartHome"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "OcclusionAvoidance",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2015 - eRing multiple finger gesture recognition with one ring using an electric field.png"
      },
      {
        "id": 12,
        "title": "Microgesture detection for remote interaction with mobile devices",
        "year": "2016",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "Smartphone",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "DeviceContactGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "InVehicleInteraction",
          "IoTControl",
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EncumberedInteraction",
          "EyesFree",
          "HandsFree",
          "MidasTouchProblem",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2016 - Microgesture detection for remote interaction with mobile devices.png"
      },
      {
        "id": 15,
        "title": "DeformWear deformation input on tiny wearable devices",
        "year": "2017",
        "category": "hardware",
        "hardwareDevices": [
          "ARGlasses",
          "HapticDevice",
          "SmartGlasses",
          "SmartRing",
          "SmartWatch",
          "VRHeadset",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "OpticalTracking",
          "OtherTechnology",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "MultiModalInteraction",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "Hold",
          "Pinch",
          "SingleHand",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming",
          "MediaControl",
          "Navigation",
          "ObjectManipulation",
          "SmartHome",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "ProprioceptiveFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SmallScreen",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2017 - DeformWear deformation input on tiny wearable devices.png"
      },
      {
        "id": 17,
        "title": "GestAKey touch interaction on individual keycaps",
        "year": "2018",
        "category": "hardware",
        "hardwareDevices": [
          "Keyboard",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "MultiTouch",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "TextInput"
        ],
        "feedbackOutput": [
          "HapticFeedback"
        ],
        "userExperienceDesign": [
          "LowLatency",
          "QWERTYLayout",
          "TouchOptimized",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2018 - GestAKey touch interaction on individual keycaps.png"
      },
      {
        "id": 19,
        "title": "Thumb-in-motion evaluating thumb-to-ring microgestures for athletic activity",
        "year": "2018",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "SmartWatch",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "Healthcare",
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EncumberedInteraction",
          "LowLatency",
          "OneHandUse",
          "PortableDesign"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2018 - Thumb-in-motion evaluating thumb-to-ring microgestures for athletic activity.png"
      },
      {
        "id": 22,
        "title": "AudioTouch minimally invasive sensing of micro-gestures via active bio-acoustic sensing",
        "year": "2019",
        "category": "hardware",
        "hardwareDevices": [
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "BioSensor",
          "PressureSensor",
          "UltrasonicSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "Hold",
          "Pinch",
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "SmartHome",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2019 - AudioTouch minimally invasive sensing of micro-gestures via active bio-acoustic sensing.png"
      },
      {
        "id": 24,
        "title": "E-textile microinteractions augmenting twist with flick, slide and grasp gestures for soft electronics",
        "year": "2020",
        "category": "hardware",
        "hardwareDevices": [
          "Etextile",
          "OtherDevices",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "OtherTechnology",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Grasp",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "Gaming",
          "MediaControl",
          "OtherScenarios",
          "SmartHome"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "PortableDesign",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2020 - E-textile microinteractions augmenting twist with flick, slide and grasp gestures for soft electronics.png"
      },
      {
        "id": 26,
        "title": "Fabriccio touchless gestural input on interactive fabrics",
        "year": "2020",
        "category": "hardware",
        "hardwareDevices": [
          "Etextile",
          "OtherDevices",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "RFSensing",
          "RadarSensing"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "IoTControl",
          "MediaControl",
          "OtherScenarios",
          "SmartHome"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "PortableDesign"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2020 - Fabriccio touchless gestural input on interactive fabrics.png"
      },
      {
        "id": 29,
        "title": "Nailz sensing hand input with touch sensitive nails",
        "year": "2020",
        "category": "hardware",
        "hardwareDevices": [
          "SmartGlasses",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "IMU"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "MultiTouch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "OneHandUse",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2020 - Nailz sensing hand input with touch sensitive nails.png"
      },
      {
        "id": 30,
        "title": "ThermalRing gesture and tag inputs enabled by a thermal imaging smart ring",
        "year": "2020",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "InAirGesture",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "IoTControl",
          "MediaControl",
          "Navigation",
          "SmartHome"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HighAccuracy",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2020 - ThermalRing gesture and tag inputs enabled by a thermal imaging smart ring.png"
      },
      {
        "id": 32,
        "title": "ElectroRing subtle pinch and touch detection with a ring",
        "year": "2021",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "Pinch",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "DigitalArt",
          "MR",
          "MediaControl",
          "ObjectManipulation",
          "VR"
        ],
        "feedbackOutput": [
          "ProprioceptiveFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "PortableDesign"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2021 - ElectroRing subtle pinch and touch detection with a ring.png"
      },
      {
        "id": 34,
        "title": "ThumbTrak recognizing micro-finger poses using a ring with proximity sensing",
        "year": "2021",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "DeviceContactGesture",
          "DirectTouch"
        ],
        "gestureTypes": [
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming",
          "MediaControl",
          "Navigation",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2021 - ThumbTrak recognizing micro-finger poses using a ring with proximity sensing.png"
      },
      {
        "id": 36,
        "title": "DualRing Enabling Subtle and Expressive Hand Interaction with Dual IMU Rings",
        "year": "2021",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "Magnetometer",
          "RFSensing"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "MotionAnalysis",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Grasp",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "IoTControl",
          "MediaControl",
          "ObjectManipulation",
          "SmartHome",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2021-DualRing Enabling Subtle and Expressive Hand Interaction with Dual IMU Rings.png"
      },
      {
        "id": 37,
        "title": "MicroPress detecting pressure and hover distance in thumb-to-finger interactions",
        "year": "2022",
        "category": "hardware",
        "hardwareDevices": [
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "DepthSensing",
          "Gyroscope",
          "IMU",
          "Magnetometer",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "DirectTouch",
          "NonContactBased"
        ],
        "gestureTypes": [
          "Hold",
          "Pinch",
          "SingleHand",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming",
          "MediaControl",
          "Navigation",
          "VR"
        ],
        "feedbackOutput": [
          "ProprioceptiveFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2022 - MicroPress detecting pressure and hover distance in thumb-to-finger interactions.png"
      },
      {
        "id": 39,
        "title": "DRG-Keyboard Enabling Subtle Gesture Typing on the Fingertip with Dual IMU Rings",
        "year": "2023",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "Magnetometer"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "TrajectoryAnalysis"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "SmartHome",
          "TextInput"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "PortableDesign",
          "QWERTYLayout",
          "SmallScreen"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2023-DRG-Keyboard Enabling Subtle Gesture Typing on the Fingertip with Dual IMU Rings.png"
      },
      {
        "id": 40,
        "title": "EFRing Enabling Thumb-to-Index-Finger Microgesture Interaction through Electric Field Sensing Using Single Smart Ring",
        "year": "2023",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "DigitalArt",
          "IoTControl",
          "MediaControl",
          "SmartHome",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2023-EFRing Enabling Thumb-to-Index-Finger Microgesture Interaction through Electric Field Sensing Using Single Smart Ring.png"
      },
      {
        "id": 41,
        "title": "SparseIMU Computational Design of Sparse IMU Layouts for Sensing Fine-grained Finger Microgestures",
        "year": "2023",
        "category": "hardware",
        "hardwareDevices": [
          "DataGloves",
          "SmartRing",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "Magnetometer",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "NonContactBased",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Flex",
          "Grasp",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "Gaming",
          "InVehicleInteraction",
          "IoTControl",
          "SmartHome",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EncumberedInteraction",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "PortableDesign"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2023-SparseIMU Computational Design of Sparse IMU Layouts for Sensing Fine-grained Finger Microgestures.png"
      },
      {
        "id": 42,
        "title": "VibAware Context-Aware Tap and Swipe Gestures Using Bio-Acoustic Sensing",
        "year": "2023",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "SmartWatch",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "BioSensor",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction",
          "NonContactBased",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Grasp",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "IoTControl",
          "MediaControl",
          "SmartHome",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EncumberedInteraction",
          "EyesFree",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2023-VibAware Context-Aware Tap and Swipe Gestures Using Bio-Acoustic Sensing.png"
      },
      {
        "id": 43,
        "title": "MAF exploring mobile acoustic field for hand-to-face gesture interactions",
        "year": "2024",
        "category": "hardware",
        "hardwareDevices": [
          "OtherDevices",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "OtherTechnology",
          "UltrasonicSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "HandToFaceGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Hold",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming",
          "Healthcare",
          "MediaControl",
          "SmartHome",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2024 - MAF exploring mobile acoustic field for hand-to-face gesture interactions.png"
      },
      {
        "id": 44,
        "title": "RadarHand a wrist-worn radar for on-skin touch-based proprioceptive gestures",
        "year": "2024",
        "category": "hardware",
        "hardwareDevices": [
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "RFSensing",
          "RadarSensing"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "Gaming",
          "InVehicleInteraction",
          "MediaControl",
          "Navigation",
          "SmartHome"
        ],
        "feedbackOutput": [
          "ProprioceptiveFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SmallScreen",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2024 - RadarHand a wrist-worn radar for on-skin touch-based proprioceptive gestures.png"
      },
      {
        "id": 45,
        "title": "Ring-a-pose a ring for continuous hand pose tracking",
        "year": "2024",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "OtherTechnology",
          "UltrasonicSensor"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "AccessibilitySupport",
          "Gaming",
          "MediaControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2024 - Ring-a-pose a ring for continuous hand pose tracking.png"
      },
      {
        "id": 47,
        "title": "HCMG Human-Capacitance based Micro Gesture for VR AR",
        "year": "2024",
        "category": "hardware",
        "hardwareDevices": [
          "ARGlasses",
          "VRHeadset",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "BioSensor",
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture"
        ],
        "gestureTypes": [
          "Grasp",
          "Pinch",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "AccessibilitySupport",
          "Education",
          "Gaming",
          "Training",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2024-HCMG Human-Capacitance based Micro Gesture for VR AR.png"
      },
      {
        "id": 48,
        "title": "BudsID mobile-ready and expressive finger identification input for earbuds",
        "year": "2025",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "IMU",
          "Magnetometer"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "DirectTouch",
          "EarBasedInteraction"
        ],
        "gestureTypes": [
          "MultiTouch",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "InVehicleInteraction",
          "MediaControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2025 - BudsID mobile-ready and expressive finger identification input for earbuds.png"
      },
      {
        "id": 51,
        "title": "DCSNN An Efficient and High-speed sEMG-based Transient-state Micro-gesture Recognition Method on Wearable Devices",
        "year": "2025",
        "category": "hardware",
        "hardwareDevices": [
          "OtherDevices",
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "BioSensor",
          "EMG",
          "IMU"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming",
          "IoTControl",
          "MediaControl",
          "Navigation",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "PortableDesign",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2025-DCSNN An Efficient and High-speed sEMG-based Transient-state Micro-gesture Recognition Method on Wearable Devices.png"
      },
      {
        "id": 52,
        "title": "VibRing A Wearable Vibroacoustic Sensor for Single-Handed Gesture Recognition",
        "year": "2025",
        "category": "hardware",
        "hardwareDevices": [
          "OtherDevices",
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming",
          "IoTControl",
          "MediaControl",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "LowLatency",
          "PortableDesign",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2025-VibRing A Wearable Vibroacoustic Sensor for Single-Handed Gesture Recognition.png"
      },
      {
        "id": 58,
        "title": "AtaTouch robust finger pinch detection for a VR controller using RF return loss",
        "year": "2021",
        "category": "hardware",
        "hardwareDevices": [
          "VRHeadset",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "RFSensing"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture"
        ],
        "gestureTypes": [
          "Grasp",
          "Pinch",
          "SingleHand",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "Gaming",
          "ObjectManipulation",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "LowLatency",
          "OcclusionAvoidance",
          "OneHandUse"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2021 - AtaTouch robust finger pinch detection for a VR controller using RF return loss.png"
      },
      {
        "id": 64,
        "title": "Stick-To-XR Understanding Stick-Based User Interface Design for Extended Reality",
        "year": "2024",
        "category": "hardware",
        "hardwareDevices": [
          "HapticDevice",
          "OtherDevices",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OpticalTracking",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DualHand",
          "Grasp",
          "Hold",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AR",
          "Education",
          "Gaming",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "MultimodalFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "OneHandUse",
          "PortableDesign",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2024-Stick-To-XR Understanding Stick-Based User Interface Design for Extended Reality.png"
      },
      {
        "id": 79,
        "title": "Interacting with soli exploring fine-grained dynamic gesture recognition in the radio-frequency spectrum",
        "year": "2016",
        "category": "hardware",
        "hardwareDevices": [
          "OtherDevices",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "RFSensing",
          "RadarSensing"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "ObjectManipulation",
          "SmartHome"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "OcclusionAvoidance",
          "PortableDesign"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2016 - Interacting with soli exploring fine-grained dynamic gesture recognition in the radio-frequency spectrum.png"
      },
      {
        "id": 85,
        "title": "InfiniTouch finger-aware interaction on fully touch sensitive smartphones",
        "year": "2018",
        "category": "hardware",
        "hardwareDevices": [
          "Smartphone",
          "TouchScreen",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "Flex",
          "Pinch",
          "SingleHand",
          "Swipe",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "MediaControl",
          "ObjectManipulation",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "FatFingerProblem",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2018 - InfiniTouch finger-aware interaction on fully touch sensitive smartphones.png"
      },
      {
        "id": 102,
        "title": "ARO Exploring the Design of Smart-Ring Interactions for Encumbered Hands",
        "year": "2021",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "CapacitiveSensor",
          "Gyroscope",
          "IMU"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "InAirGesture"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Grasp",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "ElicitationStudy",
          "EncumberedInteraction",
          "HandsFree",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2021-ARO Exploring the Design of Smart-Ring Interactions for Encumbered Hands.png"
      },
      {
        "id": 110,
        "title": "BikeGesture user elicitation and performance of micro hand gesture as input for cycling",
        "year": "2017",
        "category": "hardware",
        "hardwareDevices": [
          "DataGloves",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "BioSensor",
          "IMU",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "Flex",
          "Grasp",
          "Pinch",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "AthleticActivity",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2017 - BikeGesture user elicitation and performance of micro hand gesture as input for cycling.png"
      },
      {
        "id": 115,
        "title": "AnyButton unpowered, modeless and highly available mobile input using unmodified clothing buttons",
        "year": "2014",
        "category": "hardware",
        "hardwareDevices": [
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "GestureRecognition",
          "HandTracking",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "HapticFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HandsFree",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2014 - AnyButton unpowered, modeless and highly available mobile input using unmodified clothing buttons.png"
      },
      {
        "id": 129,
        "title": "Keep the phone in your pocket enabling smartphone operation with an IMU ring for visually impaired people",
        "year": "2020",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "Smartphone",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport"
        ],
        "feedbackOutput": [
          "AudioFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2020 - Keep the phone in your pocket enabling smartphone operation with an IMU ring for visually impaired people.png"
      },
      {
        "id": 140,
        "title": "WristFlex- low-power gesture input with wrist-worn pressure sensors",
        "year": "2014",
        "category": "hardware",
        "hardwareDevices": [
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "Pinch",
          "SingleHand",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AthleticActivity",
          "IoTControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2014 - WristFlex- low-power gesture input with wrist-worn pressure sensors.png"
      },
      {
        "id": 141,
        "title": "CyclopsRing- Enabling Whole-Hand and  Context-Aware Interactions Through a Fisheye Ring",
        "year": "2015",
        "category": "hardware",
        "hardwareDevices": [
          "OtherDevices",
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming",
          "IoTControl",
          "SmartHome",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HandsFree",
          "OneHandUse",
          "PortableDesign",
          "QWERTYLayout"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2015 - CyclopsRing- Enabling Whole-Hand and  Context-Aware Interactions Through a Fisheye Ring.png"
      },
      {
        "id": 144,
        "title": "ThumbRing- private interactions using one-handed thumb motion input on  finger segments",
        "year": "2016",
        "category": "hardware",
        "hardwareDevices": [
          "ARGlasses",
          "SmartGlasses",
          "SmartRing",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "Magnetometer",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "GestureRecognition",
          "MotionAnalysis",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2016 - ThumbRing- private interactions using one-handed thumb motion input on  finger segments.png"
      },
      {
        "id": 146,
        "title": "Soli- Ubiquitous Gesture Sensing with Millimeter Wave Radar",
        "year": "2016",
        "category": "hardware",
        "hardwareDevices": [
          "OtherDevices",
          "SmartWatch",
          "VRHeadset",
          "Wearables"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "RFSensing",
          "RadarSensing"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "Gaming",
          "IoTControl",
          "MediaControl",
          "Navigation",
          "SmartHome",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "OcclusionAvoidance",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2016-Soli- Ubiquitous Gesture Sensing with Millimeter Wave Radar..png"
      },
      {
        "id": 147,
        "title": "TouchRing- Subtle and  Always-Available Input Using a Multi-Touch Ring",
        "year": "2016",
        "category": "hardware",
        "hardwareDevices": [
          "SmartGlasses",
          "SmartRing",
          "TouchScreen",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "MultiTouch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability",
          "TouchOptimized"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2016-TouchRing- Subtle and  Always-Available Input Using a Multi-Touch Ring.png"
      },
      {
        "id": 148,
        "title": "DigiTouch- Reconfigurable Thumb-to-Finger Input and Text Entry on Head-mounted Displays",
        "year": "2017",
        "category": "hardware",
        "hardwareDevices": [
          "ARGlasses",
          "DataGloves",
          "VRHeadset",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture"
        ],
        "gestureTypes": [
          "Hold",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "ProprioceptiveFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "OcclusionAvoidance",
          "PortableDesign",
          "QWERTYLayout",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2017 - DigiTouch- Reconfigurable Thumb-to-Finger Input and Text Entry on Head-mounted Displays.png"
      },
      {
        "id": 149,
        "title": "FingerSound- Recognizing unistroke thumb gestures using a ring",
        "year": "2017",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Gyroscope",
          "MotionSensor",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl",
          "SmartHome",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "HapticFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "MidasTouchProblem",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2017 - FingerSound- Recognizing unistroke thumb gestures using a ring..png"
      },
      {
        "id": 153,
        "title": "ThumbText- Text Entry for Wearable Devices Using a Miniature Ring",
        "year": "2018",
        "category": "hardware",
        "hardwareDevices": [
          "SmartGlasses",
          "SmartRing",
          "SmartWatch",
          "TouchScreen",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Hold",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "TextInput"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "OcclusionAvoidance",
          "OneHandUse",
          "PortableDesign",
          "SmallScreen",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2018 - ThumbText- Text Entry for Wearable Devices Using a Miniature Ring.png"
      },
      {
        "id": 154,
        "title": "Tip-tap- battery-free discrete 2D fingertip input",
        "year": "2019",
        "category": "hardware",
        "hardwareDevices": [
          "DataGloves",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "RFSensing"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "Healthcare",
          "IndustryApplication",
          "MediaControl"
        ],
        "feedbackOutput": [
          "HapticFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HandsFree",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2019- Tip-tap- battery-free discrete 2D fingertip input..png"
      },
      {
        "id": 156,
        "title": "QwertyRing- Text Entry on Physical Surfaces  Using a Ring",
        "year": "2020",
        "category": "hardware",
        "hardwareDevices": [
          "ARGlasses",
          "SmartRing",
          "VRHeadset",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture"
        ],
        "gestureTypes": [
          "Hold",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "SmartHome",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "OneHandUse",
          "PortableDesign",
          "QWERTYLayout",
          "TouchOptimized",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2020 - . QwertyRing- Text Entry on Physical Surfaces  Using a Ring..png"
      },
      {
        "id": 157,
        "title": "BiTipText- Bimanual Eyes-Free Text Entry on a Fingertip Keyboard ",
        "year": "2020",
        "category": "hardware",
        "hardwareDevices": [
          "SmartGlasses",
          "SmartWatch",
          "TouchScreen",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "DualHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "PortableDesign",
          "QWERTYLayout",
          "TouchOptimized",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2020-BiTipText- Bimanual Eyes-Free Text Entry on a Fingertip Keyboard.png"
      },
      {
        "id": 159,
        "title": "Ready, Steady, Touch! Sensing  Physical Contact with a Finger-Mounted IMU",
        "year": "2020",
        "category": "hardware",
        "hardwareDevices": [
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "Magnetometer"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "ContactBased",
          "DeviceContactGesture",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl",
          "Navigation",
          "SmartHome",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "PortableDesign",
          "SocialAcceptability",
          "TouchOptimized"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2020-Ready, Steady, Touch! Sensing  Physical Contact with a Finger-Mounted IMU.png"
      },
      {
        "id": 164,
        "title": "Abracadabra Wireless, High-Precision, and Unpowered Finger Input for Very Small Mobile Devices",
        "year": "2009",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "SmartWatch",
          "Wearables"
        ],
        "sensingTechnology": [
          "Magnetometer",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Flex",
          "Hold",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "PortableDesign",
          "SmallScreen"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2009-Abracadabra Wireless, High-Precision, and Unpowered Finger Input for Very Small Mobile Devices.png"
      },
      {
        "id": 165,
        "title": "Digits Freehand 3D Interactions Anywhere Using a Wrist-Worn Gloveless Sensor",
        "year": "2012",
        "category": "hardware",
        "hardwareDevices": [
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "IMU",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "ContinuousRecognition",
          "FingerTracking",
          "HandTracking"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "Flex",
          "Grasp",
          "Pinch",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming",
          "MR",
          "ObjectManipulation",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "PortableDesign"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2012-Digits Freehand 3D Interactions Anywhere Using a Wrist-Worn Gloveless Sensor.png"
      },
      {
        "id": 166,
        "title": "TIMMi Finger-worn Textile Input Device with Multimodal Sensing in Mobile Interaction",
        "year": "2015",
        "category": "hardware",
        "hardwareDevices": [
          "Etextile",
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "OtherTechnology",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "Flex",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2015-TIMMi Finger-worn Textile Input Device with Multimodal Sensing in Mobile Interaction.png"
      },
      {
        "id": 168,
        "title": "zSense Enabling Shallow Depth Gesture Recognition for Greater Input Expressivity on Smart Wearables",
        "year": "2015",
        "category": "hardware",
        "hardwareDevices": [
          "SmartGlasses",
          "SmartRing",
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "DepthSensing",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "PortableDesign",
          "SmallScreen"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2015-zSense Enabling Shallow Depth Gesture Recognition for Greater Input Expressivity on Smart Wearables.png"
      },
      {
        "id": 173,
        "title": "DigiTap- an eyes-free VR:AR symbolic input device.",
        "year": "2014",
        "category": "hardware",
        "image": "Papers/HARDWARE/Hardware预览图/2014 - DigiTap- an eyes-free VR:AR symbolic input device..png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 174,
        "title": "LightRing- Always-Available 2D Input on Any Surface.",
        "year": "2014",
        "category": "hardware",
        "image": "Papers/HARDWARE/Hardware预览图/2014 - LightRing- Always-Available 2D Input on Any Surface..png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 175,
        "title": "OptiRing Low-Resolution Optical Sensing for Subtle Thumb-to-Index Input",
        "year": "2023",
        "category": "hardware",
        "image": "Papers/HARDWARE/Hardware预览图/2023 -  OptiRing Low-Resolution Optical Sensing for Subtle Thumb-to-Index Input.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 176,
        "title": "PinchWatch  A Wearable Device for One-Handed Microinteractions",
        "year": "2010",
        "category": "hardware",
        "image": "Papers/HARDWARE/Hardware预览图/2010-PinchWatch  A Wearable Device for One-Handed Microinteractions.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 177,
        "title": "iSkin Flexible, Stretchable and Visually Customizable On-Body Touch Sensors for Mobile Computing",
        "year": "2015",
        "category": "hardware",
        "image": "Papers/HARDWARE/Hardware预览图/2015-iSkin Flexible, Stretchable and Visually Customizable On-Body Touch Sensors for Mobile Computing.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 178,
        "title": "Pyro thumb-tip gesture recognition using pyroelectric infrared sensing",
        "year": "2017",
        "category": "hardware",
        "image": "Papers/HARDWARE/Hardware预览图/2017 - Pyro thumb-tip gesture recognition using pyroelectric infrared sensing.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 179,
        "title": "FingerPad-  private and subtle interaction using fingertips",
        "year": "2013",
        "category": "hardware",
        "image": "Papers/HARDWARE/Hardware预览图/2013 - FingerPad-  private and subtle interaction using fingertips.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 180,
        "title": "Skinmarks Enabling interactions on body landmarks using conformal skin electronics",
        "year": "2017",
        "category": "hardware",
        "image": "Papers/HARDWARE/Hardware预览图/2017-Skinmarks Enabling interactions on body landmarks using conformal skin electronics.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      }
    ],
    "software": [
      {
        "id": 10,
        "title": "Finger-writing with smartwatch a case for finger and hand gesture recognition using smartwatch",
        "year": "2015",
        "category": "software",
        "hardwareDevices": [
          "SmartWatch",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "MotionAnalysis",
          "StaticGestureRecognition",
          "TrajectoryAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "IoTControl",
          "MediaControl",
          "SmartHome",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HandsFree",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2015 - Finger-writing with smartwatch a case for finger and hand gesture recognition using smartwatch.png"
      },
      {
        "id": 20,
        "title": "Touch+finger extending touch-based user interface capabilities with idle finger gestures in the air",
        "year": "2018",
        "category": "software",
        "hardwareDevices": [
          "SmartRing",
          "Tablet",
          "TouchScreen",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "Magnetometer"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Hold",
          "MultiTouch",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "DigitalArt",
          "Gaming",
          "MediaControl",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "SmallScreen",
          "TouchOptimized"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2018 - Touch+finger extending touch-based user interface capabilities with idle finger gestures in the air.png"
      },
      {
        "id": 21,
        "title": "FingerInput Capturing Expressive Single-Hand Thumb-to-Finger Microgestures",
        "year": "2018",
        "category": "software",
        "hardwareDevices": [
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "ComputerVision",
          "DepthSensing"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Flex",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "DigitalArt",
          "MediaControl"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "OneHandUse"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2018-FingerInput Capturing Expressive Single-Hand Thumb-to-Finger Microgestures.png"
      },
      {
        "id": 23,
        "title": "TipText eyes-free text entry on a fingertip keyboard",
        "year": "2019",
        "category": "software",
        "hardwareDevices": [
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "ComputerVision",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "QWERTYLayout",
          "SmallScreen",
          "SocialAcceptability"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2019 - TipText eyes-free text entry on a fingertip keyboard.png"
      },
      {
        "id": 27,
        "title": "Finger gesture tracking for interactive applications a pilot study with sign languages",
        "year": "2020",
        "category": "software",
        "hardwareDevices": [
          "SmartRing",
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "Magnetometer",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "MotionAnalysis",
          "TrajectoryAnalysis"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "SignLanguageRelated",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "Education",
          "Healthcare",
          "Training"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "MultimodalFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "CommunicationAid",
          "EncumberedInteraction",
          "LowLatency",
          "PortableDesign",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Finger gesture tracking for interactive applications a pilot study with sign languages.png"
      },
      {
        "id": 46,
        "title": "Studying the simultaneous visual representation of microgestures",
        "year": "2024",
        "category": "software",
        "hardwareDevices": [
          "SmartWatch",
          "Smartphone",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "Hold",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HandsFree",
          "OneHandUse",
          "SmallScreen",
          "SocialAcceptability"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2024 - Studying the simultaneous visual representation of microgestures.png"
      },
      {
        "id": 49,
        "title": "Gesture and audio-haptic guidance techniques to direct conversations with intelligent voice interfaces",
        "year": "2025",
        "category": "software",
        "hardwareDevices": [
          "HapticDevice",
          "SmartGlasses",
          "SmartRing",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "IMU",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction",
          "VoiceGestureCombined"
        ],
        "gestureTypes": [
          "Hold",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "HapticFeedback",
          "MultimodalFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "LowLatency",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2025 - Gesture and audio-haptic guidance techniques to direct conversations with intelligent voice interfaces.png"
      },
      {
        "id": 50,
        "title": "LeakyFeeder In-air gesture control through leaky acoustic waves",
        "year": "2025",
        "category": "software",
        "hardwareDevices": [
          "OtherDevices",
          "Wearables"
        ],
        "sensingTechnology": [
          "OtherTechnology",
          "UltrasonicSensor"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "EarBasedInteraction",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "Hold",
          "Pinch",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl",
          "OtherScenarios",
          "SmartHome",
          "VR"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "PortableDesign"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2025 - LeakyFeeder In-air gesture control through leaky acoustic waves.png"
      },
      {
        "id": 54,
        "title": "Depth aware finger tapping on virtual displays",
        "year": "2018",
        "category": "software",
        "hardwareDevices": [
          "ARGlasses",
          "Smartphone",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "DepthSensing",
          "UltrasonicSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "MultimodalFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "LowLatency"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2018 - Depth aware finger tapping on virtual displays.png"
      },
      {
        "id": 60,
        "title": "GraV grasp volume data for the design of one-handed XR interfaces",
        "year": "2024",
        "category": "software",
        "hardwareDevices": [
          "ARGlasses",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "ComputerVision"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Grasp",
          "SingleHand",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "ObjectManipulation",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "OneHandUse",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2024 - GraV grasp volume data for the design of one-handed XR interfaces.png"
      },
      {
        "id": 61,
        "title": "HapticPilot authoring in-situ hand posture-adaptive vibrotactile feedback for virtual reality",
        "year": "2024",
        "category": "software",
        "hardwareDevices": [
          "DataGloves",
          "HapticDevice",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand"
        ],
        "applicationScenarios": [
          "DigitalArt",
          "Gaming",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "LowLatency",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2024 - HapticPilot authoring in-situ hand posture-adaptive vibrotactile feedback for virtual reality.png"
      },
      {
        "id": 62,
        "title": "TriPad touch input in AR on ordinary surfaces with hand tracking only",
        "year": "2024",
        "category": "software",
        "hardwareDevices": [
          "ARGlasses",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "DepthSensing",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "InAirGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "MultiTouch",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "Navigation",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HandsFree",
          "LowLatency",
          "SocialAcceptability",
          "TouchOptimized"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2024 - TriPad touch input in AR on ordinary surfaces with hand tracking only.png"
      },
      {
        "id": 63,
        "title": "GraspUI Seamlessly Integrating Object-Centric Gestures within the Seven Phases of Grasping",
        "year": "2024",
        "category": "software",
        "hardwareDevices": [
          "ARGlasses",
          "SmartGlasses",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "InAirGesture",
          "MultiModalInteraction",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Grasp",
          "Hold",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl",
          "ObjectManipulation",
          "SmartHome"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2024-GraspUI Seamlessly Integrating Object-Centric Gestures within the Seven Phases of Grasping.png"
      },
      {
        "id": 65,
        "title": "STMG A Machine Learning Microgesture Recognition System for Supporting Thumb-Based VR AR Input",
        "year": "2024",
        "category": "software",
        "hardwareDevices": [
          "ARGlasses",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl",
          "Navigation",
          "ObjectManipulation",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2024-STMG A Machine Learning Microgesture Recognition System for Supporting Thumb-Based VR AR Input.png"
      },
      {
        "id": 75,
        "title": "Tactile feedback for above-device gesture interfaces adding touch to touchless interactions",
        "year": "2014",
        "category": "software",
        "hardwareDevices": [
          "HapticDevice",
          "SmartRing",
          "SmartWatch",
          "Smartphone",
          "Wearables"
        ],
        "sensingTechnology": [
          "OpticalTracking",
          "UltrasonicSensor"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "SingleHand"
        ],
        "applicationScenarios": [
          "MediaControl"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "MultimodalFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "SmallScreen",
          "TouchOptimized"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2014 - Tactile feedback for above-device gesture interfaces adding touch to touchless interactions.png"
      },
      {
        "id": 78,
        "title": " Finger-aware shortcuts",
        "year": "2016",
        "category": "software",
        "hardwareDevices": [
          "Keyboard"
        ],
        "sensingTechnology": [
          "ComputerVision"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "DeviceContactGesture"
        ],
        "gestureTypes": [
          "DualHand",
          "Hold",
          "SingleHand"
        ],
        "applicationScenarios": [
          "TextInput"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "QWERTYLayout",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2016 - Finger-aware shortcuts.png"
      },
      {
        "id": 81,
        "title": "WiFinger talk to your smart devices with finger-grained gesture",
        "year": "2016",
        "category": "software",
        "hardwareDevices": [
          "OtherDevices",
          "Smartphone"
        ],
        "sensingTechnology": [
          "RFSensing"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "SignLanguageRelated",
          "SingleHand"
        ],
        "applicationScenarios": [
          "SmartHome",
          "TextInput"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HandsFree",
          "HighAccuracy"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2016 - WiFinger talk to your smart devices with finger-grained gesture.png"
      },
      {
        "id": 96,
        "title": "TouchPose hand pose prediction, depth estimation, and touch classification from capacitive images",
        "year": "2021",
        "category": "software",
        "hardwareDevices": [
          "Smartphone",
          "Tablet",
          "TouchScreen",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "ComputerVision",
          "DepthSensing",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Grasp",
          "MultiTouch",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AR",
          "DigitalArt",
          "ObjectManipulation",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "LowLatency",
          "OcclusionAvoidance",
          "TouchOptimized",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2021 - TouchPose hand pose prediction, depth estimation, and touch classification from capacitive images.png"
      },
      {
        "id": 97,
        "title": "Watching your phone's back gesture recognition by sensing acoustical structure-borne propagation",
        "year": "2021",
        "category": "software",
        "hardwareDevices": [
          "OtherDevices",
          "Smartphone",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OtherTechnology",
          "UltrasonicSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "DeviceContactGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "IoTControl",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "MultimodalFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "LowLatency",
          "OcclusionAvoidance",
          "PortableDesign",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2021 - Watching your phone's back gesture recognition by sensing acoustical structure-borne propagation.png"
      },
      {
        "id": 99,
        "title": "Leveraging the properties of mmWave signals for 3D finger motion tracking for interactive IoT applications",
        "year": "2022",
        "category": "software",
        "hardwareDevices": [
          "OtherDevices",
          "Smartphone",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "RFSensing",
          "RadarSensing"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "ContinuousRecognition",
          "FingerTracking",
          "HandTracking"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "Flex",
          "SignLanguageRelated",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AR",
          "AccessibilitySupport",
          "Healthcare",
          "IoTControl",
          "SmartHome",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2022 - Leveraging the properties of mmWave signals for 3D finger motion tracking for interactive IoT applications.png"
      },
      {
        "id": 100,
        "title": "IndexPen Two Finger Text Input with Millimeter Wave Radar",
        "year": "2022",
        "category": "software",
        "hardwareDevices": [
          "OtherDevices",
          "Smartphone",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "RFSensing",
          "RadarSensing"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "AccessibilitySupport",
          "IoTControl",
          "SmartHome",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2022-IndexPen Two Finger Text Input with Millimeter Wave Radar.png"
      },
      {
        "id": 104,
        "title": "iFAD Gestures Understanding Users’ Gesture Input Performance with Index-Finger Augmentation Devices",
        "year": "2023",
        "category": "software",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "DeviceContactGesture",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "SmartHome",
          "TextInput"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HandsFree",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2023-iFAD Gestures Understanding Users’ Gesture Input Performance with Index-Finger Augmentation Devices.png"
      },
      {
        "id": 105,
        "title": "Persistent assistant seamless everyday AI interactions via intent grounding and multimodal feedback",
        "year": "2025",
        "category": "software",
        "hardwareDevices": [
          "ARGlasses",
          "HapticDevice",
          "SmartGlasses",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "GazeBased",
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased",
          "VoiceGestureCombined"
        ],
        "gestureTypes": [
          "Pinch",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AR",
          "Navigation",
          "SmartHome"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "HapticFeedback",
          "MultimodalFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "OneHandUse",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2025 - Persistent assistant seamless everyday AI interactions via intent grounding and multimodal feedback.png"
      },
      {
        "id": 106,
        "title": "Grasp Interaction with Tablets",
        "year": "2011",
        "category": "software",
        "hardwareDevices": [
          "Tablet",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "CapacitiveSensor",
          "Gyroscope",
          "IMU",
          "Magnetometer"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DualHand",
          "Grasp",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "FatFingerProblem",
          "MidasTouchProblem",
          "OcclusionAvoidance",
          "OneHandUse",
          "SmallScreen",
          "TouchOptimized"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2011-Grasp Interaction with Tablets.png"
      },
      {
        "id": 107,
        "title": "Opportunistic synergy a classifier fusion engine for micro-gesture recognition",
        "year": "2013",
        "category": "software",
        "hardwareDevices": [
          "DrivingSimulator",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "BioSensor",
          "EMG",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "MultiModalInteraction",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Grasp",
          "Hold",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "InVehicleInteraction"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2013 - Opportunistic synergy a classifier fusion engine for micro-gesture recognition.png"
      },
      {
        "id": 125,
        "title": "Blind people and mobile touch-based text-entry acknowledging the need for different flavors",
        "year": "2011",
        "category": "software",
        "hardwareDevices": [
          "Smartphone",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "PressureSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "MultiTouch",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "TextInput"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "MultimodalFeedback"
        ],
        "userExperienceDesign": [
          "FatFingerProblem",
          "QWERTYLayout",
          "TouchOptimized",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2011 - Blind people and mobile touch-based text-entry acknowledging the need for different flavors.png"
      },
      {
        "id": 128,
        "title": "Static fingerspelling recognition based on boundary tracing algorithm and chain code",
        "year": "2018",
        "category": "software",
        "hardwareDevices": [
          "OtherDevices"
        ],
        "sensingTechnology": [
          "ComputerVision"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "NonContactBased"
        ],
        "gestureTypes": [
          "SignLanguageRelated",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AccessibilitySupport"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2018 - Static fingerspelling recognition based on boundary tracing algorithm and chain code.png"
      },
      {
        "id": 130,
        "title": "Performance evaluation of pattern recognition networks using electromyography signal and time-domain features for the classification of hand gestures",
        "year": "2020",
        "category": "software",
        "hardwareDevices": [
          "WearableSensor"
        ],
        "sensingTechnology": [
          "BioSensor",
          "EMG"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased"
        ],
        "gestureTypes": [
          "Flex",
          "Grasp",
          "SingleHand",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "Healthcare"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "CommunicationAid",
          "HighAccuracy"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2020 - Performance evaluation of pattern recognition networks using electromyography signal and time-domain features for the cl.png"
      },
      {
        "id": 131,
        "title": "Keep in touch combining touch interaction with thumb-to-finger µGestures for people with visual impairment",
        "year": "2022",
        "category": "software",
        "hardwareDevices": [
          "Tablet",
          "TouchScreen",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "Education",
          "Navigation"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "MultimodalFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "CommunicationAid",
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "OneHandUse",
          "TouchOptimized"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2022 - Keep in touch combining touch interaction with thumb-to-finger µGestures for people with visual impairment.png"
      },
      {
        "id": 132,
        "title": "µGeT multimodal eyes-free text selection technique combining touch interaction and microgestures",
        "year": "2023",
        "category": "software",
        "hardwareDevices": [
          "Tablet",
          "TouchScreen",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "ComputerVision"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "Hold",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "TextInput"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "OneHandUse",
          "TouchOptimized"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2023 - µGeT multimodal eyes-free text selection technique combining touch interaction and microgestures.png"
      },
      {
        "id": 142,
        "title": "Combining Ring Input with Hand  Tracking for Precise, Natural Interaction with Spatial Analytic Interfaces",
        "year": "2016",
        "category": "software",
        "hardwareDevices": [
          "ARGlasses",
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "ComputerVision",
          "DepthSensing",
          "IMU",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "ContinuousRecognition",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Grasp",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "Navigation",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "PortableDesign"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2016 - Combining Ring Input with Hand  Tracking for Precise, Natural Interaction with Spatial Analytic Interfaces..png"
      },
      {
        "id": 145,
        "title": "Interacting with Soli- Exploring Fine-Grained Dynamic  Gesture Recognition in the Radio-Frequency Spectrum",
        "year": "2016",
        "category": "software",
        "hardwareDevices": [
          "OtherDevices",
          "Wearables"
        ],
        "sensingTechnology": [
          "RFSensing",
          "RadarSensing"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "IoTControl",
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "OcclusionAvoidance"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2016-Interacting with Soli- Exploring Fine-Grained Dynamic  Gesture Recognition in the Radio-Frequency Spectrum.png"
      },
      {
        "id": 158,
        "title": "EarBuddy- Enabling On-Face Interaction via Wireless Earbuds",
        "year": "2020",
        "category": "software",
        "hardwareDevices": [
          "Smartphone",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "BioSensor",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "EarBasedInteraction"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "MediaControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2020-EarBuddy- Enabling On-Face Interaction via Wireless Earbuds.png"
      },
      {
        "id": 171,
        "title": "A Usability User Study Concerning Free-Hand Microgesture and Wrist-Worn Sensors",
        "year": "2014",
        "category": "software",
        "hardwareDevices": [
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "DepthSensing",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "NonContactBased"
        ],
        "gestureTypes": [
          "DualHand",
          "Flex",
          "Pinch",
          "SingleHand"
        ],
        "applicationScenarios": [
          "IndustryApplication",
          "MediaControl",
          "Navigation",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "OneHandUse",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2014-A Usability User Study Concerning Free-Hand Microgesture and Wrist-Worn Sensors.png"
      },
      {
        "id": 181,
        "title": "Press-n-paste copy-and-paste operations with pressure-sensitive caret navigation for miniaturized surface in mobile aug",
        "year": "2021",
        "category": "software",
        "image": "Papers/SOFTWARE/Software预览图/2021 - Press-n-paste copy-and-paste operations with pressure-sensitive caret navigation for miniaturized surface in mobile aug.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 182,
        "title": "Vulture- A Mid-Air Word-Gesture Keyboard",
        "year": "2014",
        "category": "software",
        "image": "Papers/SOFTWARE/Software预览图/2014 - Vulture- A Mid-Air Word-Gesture Keyboard.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      }
    ],
    "gesture-design": [
      {
        "id": 5,
        "title": "Design space for finger gestures with hand-held tablets",
        "year": "2012",
        "category": "gesture-design",
        "hardwareDevices": [
          "Tablet",
          "TouchScreen",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "CapacitiveSensor",
          "Gyroscope",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "DualHand",
          "Grasp",
          "MultiTouch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "MultimodalFeedback",
          "ProprioceptiveFeedback"
        ],
        "userExperienceDesign": [
          "FatFingerProblem",
          "OcclusionAvoidance",
          "SocialAcceptability",
          "TouchOptimized",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2012 - Design space for finger gestures with hand-held tablets.png"
      },
      {
        "id": 11,
        "title": "Gunslinger subtle arms-down mid-air interaction",
        "year": "2015",
        "category": "gesture-design",
        "hardwareDevices": [
          "TouchScreen",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "DepthSensing",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "Hold",
          "Pinch",
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HandsFree",
          "LowLatency",
          "MidasTouchProblem",
          "OcclusionAvoidance",
          "OneHandUse",
          "TouchOptimized"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2015 - Gunslinger subtle arms-down mid-air interaction.png"
      },
      {
        "id": 13,
        "title": "Designing a willing-to-use-in-public hand gestural interaction technique for smart glasses",
        "year": "2016",
        "category": "gesture-design",
        "hardwareDevices": [
          "DataGloves",
          "HapticDevice",
          "SmartGlasses",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "IMU",
          "MotionSensor",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Flex",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "Navigation",
          "ObjectManipulation",
          "TextInput"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "MultimodalFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HandsFree",
          "OcclusionAvoidance",
          "PortableDesign",
          "SocialAcceptability",
          "TouchOptimized"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2016 - Designing a willing-to-use-in-public hand gestural interaction technique for smart glasses.png"
      },
      {
        "id": 18,
        "title": "Gestures for smart rings empirical results, insights, and design implications",
        "year": "2018",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartRing",
          "Wearables"
        ],
        "sensingTechnology": [
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "IoTControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "HapticFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Gestures for smart rings empirical results, insights, and design implications.png"
      },
      {
        "id": 25,
        "title": "Exploring user defined gestures for ear-based interactions",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "SmartGlasses",
          "Wearables"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OtherTechnology",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "EarBasedInteraction",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "MediaControl",
          "Navigation",
          "OtherScenarios",
          "SmartHome"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "HapticFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "OneHandUse",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Exploring user defined gestures for ear-based interactions.png"
      },
      {
        "id": 28,
        "title": "How subtle can it get A trimodal study of ring-sized interfaces for one-handed drone control",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "SmartRing",
          "Smartphone",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "IMU",
          "MotionSensor",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Flex",
          "Hold",
          "SingleHand",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - How subtle can it get A trimodal study of ring-sized interfaces for one-handed drone control.png"
      },
      {
        "id": 33,
        "title": "SoloFinger robust microgestures while grasping everyday objects",
        "year": "2021",
        "category": "gesture-design",
        "hardwareDevices": [
          "DataGloves",
          "OtherDevices"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "DeviceContactGesture",
          "DirectTouch"
        ],
        "gestureTypes": [
          "Flex",
          "Grasp",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "ObjectManipulation",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "EncumberedInteraction",
          "HighAccuracy"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2021 - SoloFinger robust microgestures while grasping everyday objects.png"
      },
      {
        "id": 53,
        "title": "Exploring mixed-scale gesture interaction",
        "year": "2017",
        "category": "gesture-design",
        "hardwareDevices": [
          "ARGlasses",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "OpticalTracking",
          "RadarSensing"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "Grasp",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Exploring mixed-scale gesture interaction.png"
      },
      {
        "id": 55,
        "title": "Experimental analysis of barehand mid-air mode-switching techniques in virtual reality",
        "year": "2019",
        "category": "gesture-design",
        "hardwareDevices": [
          "VRHeadset",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "OpticalTracking",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "Grasp",
          "Pinch",
          "SingleHand"
        ],
        "applicationScenarios": [
          "ObjectManipulation",
          "VR"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2019 - Experimental analysis of barehand mid-air mode-switching techniques in virtual reality.png"
      },
      {
        "id": 56,
        "title": "Characterizing in-air eyes-free typing movements in VR",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "MotionAnalysis",
          "TrajectoryAnalysis"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DualHand",
          "Flex",
          "Tap"
        ],
        "applicationScenarios": [
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "QWERTYLayout"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Characterizing in-air eyes-free typing movements in VR.png"
      },
      {
        "id": 57,
        "title": "User gesture elicitation of common smartphone tasks for hand proximate user interfaces",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "ARGlasses",
          "SmartGlasses",
          "Smartphone"
        ],
        "sensingTechnology": [
          "ComputerVision"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "DirectTouch",
          "InAirGesture"
        ],
        "gestureTypes": [
          "Flex",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "MR",
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "OneHandUse",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020-User gesture elicitation of common smartphone tasks for hand proximate user interfaces.png"
      },
      {
        "id": 66,
        "title": "Understanding Gesture and Microgesture Inputs for Augmented Reality Maps",
        "year": "2024",
        "category": "gesture-design",
        "hardwareDevices": [
          "ARGlasses",
          "SmartGlasses",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "CapacitiveSensor",
          "ComputerVision",
          "IMU",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "Navigation"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "ProprioceptiveFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "OneHandUse",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2024-Understanding Gesture and Microgesture Inputs for Augmented Reality Maps.png"
      },
      {
        "id": 67,
        "title": "T2IRay Design of Thumb-to-Index based Indirect Pointing for Continuous and Robust AR VR Input",
        "year": "2025",
        "category": "gesture-design",
        "hardwareDevices": [
          "ARGlasses",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "ObjectManipulation",
          "VR"
        ],
        "feedbackOutput": [
          "ProprioceptiveFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "OneHandUse",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2025-T2IRay Design of Thumb-to-Index based Indirect Pointing for Continuous and Robust AR VR Input.png"
      },
      {
        "id": 68,
        "title": "Key-press gestures recognition and interaction based on SEMG signals",
        "year": "2010",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "BioSensor",
          "EMG"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "Flex",
          "Hold",
          "SingleHand"
        ],
        "applicationScenarios": [
          "MediaControl",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EncumberedInteraction",
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2010 - Key-press gestures recognition and interaction based on SEMG signals.png"
      },
      {
        "id": 69,
        "title": "A study of on-device gestures",
        "year": "2012",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone"
        ],
        "sensingTechnology": [
          "PressureSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "ContactBased",
          "DeviceContactGesture"
        ],
        "gestureTypes": [
          "Grasp",
          "SingleHand",
          "Swipe"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "ProprioceptiveFeedback"
        ],
        "userExperienceDesign": [
          "EncumberedInteraction",
          "OcclusionAvoidance",
          "OneHandUse"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2012 - A study of on-device gestures.png"
      },
      {
        "id": 70,
        "title": "PinchPad performance of touch-based gestures while grasping devices",
        "year": "2012",
        "category": "gesture-design",
        "hardwareDevices": [
          "Tablet"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "ContactBased",
          "DeviceContactGesture",
          "DirectTouch"
        ],
        "gestureTypes": [
          "Grasp",
          "Pinch",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "ProprioceptiveFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "OcclusionAvoidance",
          "OneHandUse"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2012 - PinchPad performance of touch-based gestures while grasping devices.png"
      },
      {
        "id": 71,
        "title": "The fat thumb using the thumb's contact size for single-handed mobile interaction",
        "year": "2012",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "SingleHand",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "FatFingerProblem",
          "OneHandUse",
          "SmallScreen",
          "TouchOptimized"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2012 - The fat thumb using the thumb's contact size for single-handed mobile interaction.png"
      },
      {
        "id": 72,
        "title": "Exploring pinch and spread gestures on mobile devices",
        "year": "2013",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone",
          "Tablet"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "DirectTouch",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DualHand",
          "MultiTouch",
          "Pinch",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "SmallScreen",
          "TouchOptimized"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2013 - Exploring pinch and spread gestures on mobile devices.png"
      },
      {
        "id": 74,
        "title": "Leap gestures for TV insights from an elicitation study",
        "year": "2014",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "Flex",
          "Hold",
          "SingleHand"
        ],
        "applicationScenarios": [
          "MediaControl"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "HandsFree",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2014 - Leap gestures for TV insights from an elicitation study.png"
      },
      {
        "id": 76,
        "title": "Interaction proxemics combining physical spaces for seamless gesture interaction",
        "year": "2015",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "DepthSensing",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "DirectTouch",
          "InAirGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "Navigation",
          "ObjectManipulation",
          "TextInput"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2015 - Interaction proxemics combining physical spaces for seamless gesture interaction.png"
      },
      {
        "id": 77,
        "title": "Exploring non-touchscreen gestures for smartwatches",
        "year": "2016",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartWatch",
          "Wearables"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "DeviceContactGesture",
          "InAirGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "ElicitationStudy",
          "FatFingerProblem",
          "OcclusionAvoidance",
          "SmallScreen",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2016 - Exploring non-touchscreen gestures for smartwatches.png"
      },
      {
        "id": 80,
        "title": "Investigating how the hand interacts with different mobile phones",
        "year": "2016",
        "category": "gesture-design",
        "hardwareDevices": [
          "Keyboard",
          "Smartphone",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "ComputerVision"
        ],
        "recognitionClassification": [
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "DirectTouch"
        ],
        "gestureTypes": [
          "DualHand",
          "Grasp",
          "Hold",
          "SingleHand"
        ],
        "applicationScenarios": [
          "MediaControl",
          "TextInput"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "OneHandUse",
          "TouchOptimized"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2016 - Investigating how the hand interacts with different mobile phones.png"
      },
      {
        "id": 82,
        "title": "Understanding grip shifts how form factors impact hand movements on mobile phones",
        "year": "2017",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "DualHand",
          "Hold",
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "Navigation",
          "TextInput"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "OneHandUse",
          "PortableDesign",
          "SmallScreen",
          "TouchOptimized"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Understanding grip shifts how form factors impact hand movements on mobile phones.png"
      },
      {
        "id": 83,
        "title": "Characterizing finger pitch and roll orientation during atomic touch actions",
        "year": "2018",
        "category": "gesture-design",
        "hardwareDevices": [
          "Tablet",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "Magnetometer"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "DualHand",
          "Hold",
          "MultiTouch",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "TouchOptimized"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Characterizing finger pitch and roll orientation during atomic touch actions.png"
      },
      {
        "id": 84,
        "title": "Fingers' range and comfortable area for one-handed smartphone interaction beyond the touchscreen",
        "year": "2018",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "FatFingerProblem",
          "OcclusionAvoidance",
          "OneHandUse",
          "PortableDesign",
          "TouchOptimized"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Fingers' range and comfortable area for one-handed smartphone interaction beyond the touchscreen.png"
      },
      {
        "id": 86,
        "title": "Pen + mid-air gestures eliciting contextual gestures",
        "year": "2018",
        "category": "gesture-design",
        "hardwareDevices": [
          "Tablet",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased",
          "PenInput"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "Grasp",
          "Pinch",
          "Swipe"
        ],
        "applicationScenarios": [
          "DigitalArt",
          "Education",
          "MediaControl",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EncumberedInteraction",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Pen + mid-air gestures eliciting contextual gestures.png"
      },
      {
        "id": 87,
        "title": "Unimanual Pen Touch Input Using Variations of Precision Grip Postures",
        "year": "2018",
        "category": "gesture-design",
        "hardwareDevices": [
          "Tablet",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction",
          "PenInput"
        ],
        "gestureTypes": [
          "Grasp",
          "MultiTouch",
          "SingleHand"
        ],
        "applicationScenarios": [
          "DigitalArt",
          "Education",
          "ObjectManipulation",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "HighAccuracy",
          "OneHandUse",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2018-Unimanual Pen Touch Input Using Variations of Precision Grip Postures.png"
      },
      {
        "id": 88,
        "title": "Gaze-assisted typing for smart glasses",
        "year": "2019",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartGlasses",
          "VRHeadset",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "GazeBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "TextInput"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EyesFree",
          "LowLatency",
          "MidasTouchProblem",
          "OneHandUse",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2019 - Gaze-assisted typing for smart glasses.png"
      },
      {
        "id": 89,
        "title": "Investigating unintended inputs for one-handed touch interaction beyond the touchscreen",
        "year": "2019",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "MotionAnalysis",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "ContactBased",
          "DeviceContactGesture"
        ],
        "gestureTypes": [
          "Grasp",
          "SingleHand"
        ],
        "applicationScenarios": [
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EncumberedInteraction",
          "FatFingerProblem",
          "OcclusionAvoidance",
          "OneHandUse",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2019 - Investigating unintended inputs for one-handed touch interaction beyond the touchscreen.png"
      },
      {
        "id": 90,
        "title": "Expanding Side Touch Input on Mobile Phones",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "MediaControl",
          "Navigation",
          "TextInput"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "FatFingerProblem",
          "HighAccuracy",
          "OcclusionAvoidance",
          "OneHandUse",
          "PortableDesign"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Expanding side touch input on mobile phones finger reachability and two-dimensional taps and flicks using the index and.png"
      },
      {
        "id": 91,
        "title": "MagTouch robust finger identification for a smartwatch using a magnet ring and a built-in magnetometer",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartRing",
          "SmartWatch",
          "Wearables"
        ],
        "sensingTechnology": [
          "IMU",
          "Magnetometer",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - MagTouch robust finger identification for a smartwatch using a magnet ring and a built-in magnetometer.png"
      },
      {
        "id": 92,
        "title": "PenSight enhanced interaction with a pen-top camera",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "Tablet"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "DepthSensing",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction",
          "NonContactBased",
          "PenInput",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DualHand",
          "Grasp"
        ],
        "applicationScenarios": [
          "DigitalArt",
          "Education",
          "Navigation",
          "ObjectManipulation",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EncumberedInteraction",
          "HighAccuracy",
          "LowLatency",
          "OcclusionAvoidance",
          "PortableDesign"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - PenSight enhanced interaction with a pen-top camera.png"
      },
      {
        "id": 93,
        "title": "Shortcut gestures for mobile text editing on fully touch sensitive smartphones",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone",
          "TouchScreen",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "ContactBased",
          "DeviceContactGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Hold",
          "MultiTouch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "OtherScenarios",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "FatFingerProblem",
          "HighAccuracy",
          "OcclusionAvoidance",
          "OneHandUse",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Shortcut gestures for mobile text editing on fully touch sensitive smartphones.png"
      },
      {
        "id": 94,
        "title": "Eliciting tangible and gestural user interactions with and on a cooking pan",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Grasp",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "OtherScenarios",
          "SmartHome"
        ],
        "feedbackOutput": [
          "MultimodalFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EncumberedInteraction"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Eliciting tangible and gestural user interactions with and on a cooking pan.png"
      },
      {
        "id": 95,
        "title": "3D hand pose estimation on conventional capacitive touchscreens",
        "year": "2021",
        "category": "gesture-design",
        "hardwareDevices": [
          "Tablet",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DualHand",
          "Grasp",
          "MultiTouch",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AR",
          "DigitalArt",
          "Gaming",
          "ObjectManipulation",
          "Training",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "FatFingerProblem",
          "HighAccuracy",
          "LowLatency",
          "OcclusionAvoidance",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2021 - 3D hand pose estimation on conventional capacitive touchscreens.png"
      },
      {
        "id": 98,
        "title": "A User-based Mid-air Hand Gesture Set for Spreadsheets",
        "year": "2021",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "Pinch",
          "SingleHand",
          "Swipe"
        ],
        "applicationScenarios": [
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2021-A User-based Mid-air Hand Gesture Set for Spreadsheets.png"
      },
      {
        "id": 101,
        "title": "SoloFinger Robust Microgestures while Grasping Everyday Objects",
        "year": "2021",
        "category": "gesture-design",
        "hardwareDevices": [
          "DataGloves",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Flex",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "ObjectManipulation",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2021 - SoloFinger robust microgestures while grasping everyday objects.png"
      },
      {
        "id": 103,
        "title": "Enabling voice-accompanying hand-to-face gesture recognition with cross-device sensing",
        "year": "2023",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartRing",
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "UltrasonicSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "EarBasedInteraction",
          "MultiModalInteraction",
          "VoiceGestureCombined"
        ],
        "gestureTypes": [
          "SingleHand"
        ],
        "applicationScenarios": [
          "AR",
          "IoTControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "HandsFree",
          "LowLatency",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2023 - Enabling voice-accompanying hand-to-face gesture recognition with cross-device sensing.png"
      },
      {
        "id": 109,
        "title": "The performance and preference of different fingers and chords for pointing, dragging, and object transformation",
        "year": "2016",
        "category": "gesture-design",
        "hardwareDevices": [
          "Tablet",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "Hold",
          "MultiTouch",
          "Pinch",
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "LowLatency",
          "TouchOptimized",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2016 - The performance and preference of different fingers and chords for pointing, dragging, and object transformation.png"
      },
      {
        "id": 112,
        "title": "M[eye]cro eye-gaze+microgestures for multitasking and interruptions",
        "year": "2021",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "OpticalTracking",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "GazeBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "Pinch",
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "InVehicleInteraction",
          "ObjectManipulation",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "MultimodalFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "LowLatency",
          "MidasTouchProblem",
          "OneHandUse"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2021 - M[eye]cro eye-gaze+microgestures for multitasking and interruptions.png"
      },
      {
        "id": 116,
        "title": "Towards the establishment of a framework for intuitive multi-touch interaction design",
        "year": "2012",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone",
          "Tablet",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "HandTracking",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "MultiTouch",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "Navigation",
          "ObjectManipulation",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "HapticFeedback",
          "MultimodalFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "FatFingerProblem",
          "HighAccuracy",
          "OcclusionAvoidance",
          "TouchOptimized",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2012 - Towards the establishment of a framework for intuitive multi-touch interaction design.png"
      },
      {
        "id": 117,
        "title": "Grasping microgestures eliciting single-hand microgestures for handheld objects",
        "year": "2019",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "Smartphone"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "Magnetometer",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "DeviceContactGesture",
          "DirectTouch"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Grasp",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "IoTControl",
          "ObjectManipulation",
          "OtherScenarios",
          "SmartHome"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "ElicitationStudy",
          "EncumberedInteraction",
          "OneHandUse"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2019 - Grasping microgestures eliciting single-hand microgestures for handheld objects.png"
      },
      {
        "id": 118,
        "title": "Rhythmic micro-gestures discreet interaction on-the-go",
        "year": "2017",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Flex",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "MultimodalFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "MidasTouchProblem",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Rhythmic micro-gestures discreet interaction on-the-go.png"
      },
      {
        "id": 119,
        "title": "Studying the visual representation of microgestures",
        "year": "2023",
        "category": "gesture-design",
        "hardwareDevices": [
          "ARGlasses",
          "OtherDevices"
        ],
        "sensingTechnology": [
          "Magnetometer",
          "OtherTechnology"
        ],
        "recognitionClassification": [],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "Flex",
          "Hold",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "Education"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "ElicitationStudy",
          "OneHandUse"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2023 - Studying the visual representation of microgestures.png"
      },
      {
        "id": 120,
        "title": "µGlyph a microgesture notation",
        "year": "2023",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices"
        ],
        "sensingTechnology": [
          "OtherTechnology"
        ],
        "recognitionClassification": [],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "NonContactBased"
        ],
        "gestureTypes": [
          "Flex",
          "Hold",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "Education"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "OneHandUse"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2023 - µGlyph a microgesture notation.png"
      },
      {
        "id": 121,
        "title": "User elicitation on single-hand microgestures",
        "year": "2016",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "ObjectManipulation",
          "TextInput"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EyesFree",
          "OneHandUse",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2016 - User elicitation on single-hand microgestures.png"
      },
      {
        "id": 122,
        "title": "Would you do that understanding social acceptance of gestural interfaces",
        "year": "2010",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "Smartphone"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "OtherScenarios",
          "SmartHome"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2010 - Would you do that understanding social acceptance of gestural interfaces.png"
      },
      {
        "id": 123,
        "title": "Hands as a controller user preferences for hand specific on-skin gestures",
        "year": "2017",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "ComputerVision",
          "IMU",
          "RadarSensing",
          "UltrasonicSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "DualHand",
          "Pinch",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "InVehicleInteraction",
          "IoTControl",
          "MediaControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Hands as a controller user preferences for hand specific on-skin gestures.png"
      },
      {
        "id": 124,
        "title": "Designing More Private and Socially Acceptable Hand-to-Face Gestures for Heads-Up Computing",
        "year": "2024",
        "category": "gesture-design",
        "hardwareDevices": [
          "ARGlasses",
          "SmartGlasses",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "OtherScenarios",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "ProprioceptiveFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2024-Designing More Private and Socially Acceptable Hand-to-Face Gestures for Heads-Up Computing.png"
      },
      {
        "id": 126,
        "title": "Interaction gestures for a wearable device defined by visually impaired children",
        "year": "2016",
        "category": "gesture-design",
        "hardwareDevices": [
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "Hold",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "Healthcare",
          "Training"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "MultimodalFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EyesFree",
          "OneHandUse",
          "PortableDesign",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2016 - Interaction gestures for a wearable device defined by visually impaired children.png"
      },
      {
        "id": 127,
        "title": "Investigating microinteractions for people with visual impairments and the potential role of on-body interaction",
        "year": "2017",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartWatch",
          "Smartphone",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "IMU",
          "MotionSensor",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "MediaControl",
          "Navigation",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Investigating microinteractions for people with visual impairments and the potential role of on-body interaction.png"
      },
      {
        "id": 133,
        "title": "Designing upper-body gesture interaction with and for people with spinal muscular atrophy in VR",
        "year": "2024",
        "category": "gesture-design",
        "hardwareDevices": [
          "VRHeadset",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "ComputerVision"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "GazeBased",
          "InAirGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "VR"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HandsFree",
          "OneHandUse",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2024 - Designing upper-body gesture interaction with and for people with spinal muscular atrophy in VR.png"
      },
      {
        "id": 134,
        "title": "Finger gesture tracking for interactive applications a pilot study with sign languages",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartRing",
          "SmartWatch",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "SignLanguageRelated",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "Education"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "LowLatency",
          "PortableDesign",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Finger gesture tracking for interactive applications a pilot study with sign languages.png"
      },
      {
        "id": 135,
        "title": "A non-linear model of shape  and motion for tracking finger spelt American sign language",
        "year": "2002",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "HandTracking",
          "MotionAnalysis",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "SignLanguageRelated",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "Education"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2002-A non-linear model of shape  and motion for tracking finger spelt American sign language.png"
      },
      {
        "id": 143,
        "title": "DigitSpace Designing Thumb-to-Fingers Touch Interfaces for One-Handed and Eyes-Free Interactions",
        "year": "2016",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "OpticalTracking",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "TextInput"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EyesFree",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2016 - DigitSpace Designing Thumb-to-Fingers Touch Interfaces for One-Handed and Eyes-Free Interactions.png"
      },
      {
        "id": 152,
        "title": "Fingert9- Leveraging  thumb-to-finger interaction for same-side-hand text entry on smartwatches",
        "year": "2018",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartWatch",
          "TouchScreen",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "Hold",
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "TextInput"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EyesFree",
          "OcclusionAvoidance",
          "OneHandUse",
          "SmallScreen",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Fingert9- Leveraging  thumb-to-finger interaction for same-side-hand text entry on smartwatches.png"
      },
      {
        "id": 155,
        "title": "The missing interface- Micro-gestures on augmented objects",
        "year": "2019",
        "category": "gesture-design",
        "hardwareDevices": [
          "ARGlasses",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "RFSensing",
          "RadarSensing"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe"
        ],
        "applicationScenarios": [
          "AR",
          "IndustryApplication",
          "Training"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "OcclusionAvoidance",
          "OneHandUse",
          "PortableDesign"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2019-The missing interface- Micro-gestures on augmented objects.png"
      },
      {
        "id": 162,
        "title": "Design of 3D Microgestures for Commands in Virtual Reality or Augmented Reality",
        "year": "2023",
        "category": "gesture-design",
        "hardwareDevices": [
          "ARGlasses",
          "TouchScreen",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Grasp",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming",
          "MediaControl",
          "Navigation",
          "ObjectManipulation",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2023- Design of 3D Microgestures for Commands in Virtual Reality or Augmented Reality.png"
      },
      {
        "id": 167,
        "title": "User-Defined Game Input for Smart Glasses in Public Space",
        "year": "2015",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartGlasses"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "ElicitationStudy",
          "EyesFree",
          "HandsFree",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2015-User-Defined Game Input for Smart Glasses in Public Space.png"
      },
      {
        "id": 172,
        "title": "A Taxonomy of Microinteractions Defining Microgestures based on Ergonomic and Scenario-dependent Requirements",
        "year": "2011",
        "category": "gesture-design",
        "hardwareDevices": [
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "DepthSensing",
          "EMG",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "Grasp",
          "Pinch",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "InVehicleInteraction",
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "MultimodalFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EncumberedInteraction",
          "EyesFree",
          "OneHandUse"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2011-A Taxonomy of Microinteractions Defining Microgestures based on Ergonomic and Scenario-dependent Requirements.png"
      },
      {
        "id": 183,
        "title": "The intuitive grasp interface design and evaluation of micro-gestures on the steering wheel for driving scenario",
        "year": "2020",
        "category": "gesture-design",
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - The intuitive grasp interface design and evaluation of micro-gestures on the steering wheel for driving scenario.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 184,
        "title": "Transferable Microgestures Across Hand Posture and Location Constraints- Leveraging the Middle, Ring, and Pinky Fingers",
        "year": "2023",
        "category": "gesture-design",
        "image": "Papers/GestureDesign/GestureDesign预览图/2023 - Transferable Microgestures Across Hand Posture and Location Constraints- Leveraging the Middle, Ring, and Pinky Fingers.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 185,
        "title": "Segtouch",
        "year": "2017",
        "category": "gesture-design",
        "image": "Papers/GestureDesign/GestureDesign预览图/2017-Segtouch.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 186,
        "title": "Arpège learning multitouch chord gestures vocabularies",
        "year": "2013",
        "category": "gesture-design",
        "image": "Papers/GestureDesign/GestureDesign预览图/2013 - Arpège learning multitouch chord gestures vocabularies.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 187,
        "title": "PalmType Using Palms as Keyboards for Smart Glasses",
        "year": "2015",
        "category": "gesture-design",
        "image": "Papers/GestureDesign/GestureDesign预览图/2015-PalmType Using Palms as Keyboards for Smart Glasses.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      }
    ]
  },
  "stats": {
    "totalPapers": 165,
    "categories": {
      "hardware": 64,
      "software": 36,
      "gesture-design": 65
    },
    "yearRange": {
      "min": 2002,
      "max": 2025
    }
  }
};