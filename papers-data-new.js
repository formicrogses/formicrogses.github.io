// 自动生成的论文数据文件 V3
// 只包含Papers文件夹中的图片
// 生成时间: 2025-10-23T13:10:07.209069

const PAPERS_DATA = {
  "papers": [
    {
      "id": 1,
      "title": "Towards keyboard independent touch typing in VR",
      "year": "2005",
      "category": "hardware",
      "hardwareDevices": [
        "DataGloves",
        "Keyboard",
        "VRHeadset",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Pinch",
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "DigitalArt",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "OneHandUse",
        "TouchOptimized"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2005 - Towards keyboard independent touch typing in VR.png"
    },
    {
      "id": 2,
      "title": "Demonstrating the feasibility of using forearm electromyography for muscle-computer interfaces",
      "year": "2008",
      "category": "hardware",
      "hardwareDevices": [
        "WearableSensor"
      ],
      "sensingTechnology": [
        "BioSensor",
        "EMG"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "Hold",
        "Pinch",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "InVehicleInteraction",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HandsFree",
        "HighAccuracy",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2008 - Demonstrating the feasibility of using forearm electromyography for muscle-computer interfaces.png"
    },
    {
      "id": 3,
      "title": "Hand gesture recognition and virtual game control based on 3D accelerometer and EMG sensors",
      "year": "2009",
      "category": "hardware",
      "hardwareDevices": [
        "WearableSensor"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "BioSensor",
        "EMG",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand"
      ],
      "applicationScenarios": [
        "Gaming",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "LowLatency",
        "PortableDesign"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2009 - Hand gesture recognition and virtual game control based on 3D accelerometer and EMG sensors.png"
    },
    {
      "id": 4,
      "title": "A prototype of gesture-based interface",
      "year": "2011",
      "category": "hardware",
      "hardwareDevices": [
        "Smartphone",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "BioSensor",
        "EMG"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Flex",
        "SingleHand"
      ],
      "applicationScenarios": [
        "InVehicleInteraction",
        "MediaControl"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2011 - A prototype of gesture-based interface.png"
    },
    {
      "id": 5,
      "title": "Design space for finger gestures with hand-held tablets",
      "year": "2012",
      "category": "gesture-design",
      "hardwareDevices": [
        "Tablet",
        "TouchScreen",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "CapacitiveSensor",
        "Gyroscope",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "DualHand",
        "Grasp",
        "MultiTouch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "MultimodalFeedback",
        "ProprioceptiveFeedback"
      ],
      "userExperienceDesign": [
        "FatFingerProblem",
        "OcclusionAvoidance",
        "SocialAcceptability",
        "TouchOptimized",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2012 - Design space for finger gestures with hand-held tablets.png"
    },
    {
      "id": 6,
      "title": "Augmenting the input space of portable displays using add-on hall-sensor grid",
      "year": "2013",
      "category": "hardware",
      "hardwareDevices": [
        "Smartphone",
        "Tablet",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Magnetometer",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "DirectTouch",
        "NonContactBased",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Pinch",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "Gaming",
        "MediaControl",
        "Navigation",
        "TextInput"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "OcclusionAvoidance",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2013 - Augmenting the input space of portable displays using add-on hall-sensor grid.png"
    },
    {
      "id": 7,
      "title": "EarPut augmenting ear-worn devices for ear-based interaction",
      "year": "2014",
      "category": "hardware",
      "hardwareDevices": [
        "OtherDevices",
        "Smartphone",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "DirectTouch",
        "EarBasedInteraction",
        "InAirGesture"
      ],
      "gestureTypes": [
        "MultiTouch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "Gaming",
        "MediaControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "HapticFeedback",
        "ProprioceptiveFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2014 - EarPut augmenting ear-worn devices for ear-based interaction.png"
    },
    {
      "id": 8,
      "title": "Advancing muscle-computer interfaces with high-density electromyography",
      "year": "2015",
      "category": "hardware",
      "hardwareDevices": [
        "WearableSensor"
      ],
      "sensingTechnology": [
        "BioSensor",
        "EMG"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "NonContactBased"
      ],
      "gestureTypes": [
        "Flex",
        "Pinch",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "IoTControl",
        "MediaControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HandsFree",
        "HighAccuracy",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2015 - Advancing muscle-computer interfaces with high-density electromyography.png"
    },
    {
      "id": 9,
      "title": "eRing multiple finger gesture recognition with one ring using an electric field",
      "year": "2015",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "IoTControl",
        "OtherScenarios",
        "SmartHome"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "OcclusionAvoidance",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2015 - eRing multiple finger gesture recognition with one ring using an electric field.png"
    },
    {
      "id": 10,
      "title": "Finger-writing with smartwatch a case for finger and hand gesture recognition using smartwatch",
      "year": "2015",
      "category": "software",
      "hardwareDevices": [
        "SmartWatch",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "MotionAnalysis",
        "StaticGestureRecognition",
        "TrajectoryAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "IoTControl",
        "MediaControl",
        "SmartHome",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HandsFree",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2015 - Finger-writing with smartwatch a case for finger and hand gesture recognition using smartwatch.png"
    },
    {
      "id": 11,
      "title": "Gunslinger subtle arms-down mid-air interaction",
      "year": "2015",
      "category": "gesture-design",
      "hardwareDevices": [
        "TouchScreen",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "DepthSensing",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "Hold",
        "Pinch",
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HandsFree",
        "LowLatency",
        "MidasTouchProblem",
        "OcclusionAvoidance",
        "OneHandUse",
        "TouchOptimized"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2015 - Gunslinger subtle arms-down mid-air interaction.png"
    },
    {
      "id": 12,
      "title": "Microgesture detection for remote interaction with mobile devices",
      "year": "2016",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "Smartphone",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "DeviceContactGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "InVehicleInteraction",
        "IoTControl",
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EncumberedInteraction",
        "EyesFree",
        "HandsFree",
        "MidasTouchProblem",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2016 - Microgesture detection for remote interaction with mobile devices.png"
    },
    {
      "id": 13,
      "title": "Designing a willing-to-use-in-public hand gestural interaction technique for smart glasses",
      "year": "2016",
      "category": "gesture-design",
      "hardwareDevices": [
        "DataGloves",
        "HapticDevice",
        "SmartGlasses",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "IMU",
        "MotionSensor",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Flex",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "Navigation",
        "ObjectManipulation",
        "TextInput"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "MultimodalFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HandsFree",
        "OcclusionAvoidance",
        "PortableDesign",
        "SocialAcceptability",
        "TouchOptimized"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2016 - Designing a willing-to-use-in-public hand gestural interaction technique for smart glasses.png"
    },
    {
      "id": 15,
      "title": "DeformWear deformation input on tiny wearable devices",
      "year": "2017",
      "category": "hardware",
      "hardwareDevices": [
        "ARGlasses",
        "HapticDevice",
        "SmartGlasses",
        "SmartRing",
        "SmartWatch",
        "VRHeadset",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "OpticalTracking",
        "OtherTechnology",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "MultiModalInteraction",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "Hold",
        "Pinch",
        "SingleHand",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming",
        "MediaControl",
        "Navigation",
        "ObjectManipulation",
        "SmartHome",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "ProprioceptiveFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SmallScreen",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2017 - DeformWear deformation input on tiny wearable devices.png"
    },
    {
      "id": 17,
      "title": "GestAKey touch interaction on individual keycaps",
      "year": "2018",
      "category": "hardware",
      "hardwareDevices": [
        "Keyboard",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "MultiTouch",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "TextInput"
      ],
      "feedbackOutput": [
        "HapticFeedback"
      ],
      "userExperienceDesign": [
        "LowLatency",
        "QWERTYLayout",
        "TouchOptimized",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2018 - GestAKey touch interaction on individual keycaps.png"
    },
    {
      "id": 18,
      "title": "Gestures for smart rings empirical results, insights, and design implications",
      "year": "2018",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartRing",
        "Wearables"
      ],
      "sensingTechnology": [
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "IoTControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "HapticFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Gestures for smart rings empirical results, insights, and design implications.png"
    },
    {
      "id": 19,
      "title": "Thumb-in-motion evaluating thumb-to-ring microgestures for athletic activity",
      "year": "2018",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "SmartWatch",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "Healthcare",
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EncumberedInteraction",
        "LowLatency",
        "OneHandUse",
        "PortableDesign"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2018 - Thumb-in-motion evaluating thumb-to-ring microgestures for athletic activity.png"
    },
    {
      "id": 20,
      "title": "Touch+finger extending touch-based user interface capabilities with idle finger gestures in the air",
      "year": "2018",
      "category": "software",
      "hardwareDevices": [
        "SmartRing",
        "Tablet",
        "TouchScreen",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "Magnetometer"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Hold",
        "MultiTouch",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "DigitalArt",
        "Gaming",
        "MediaControl",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "SmallScreen",
        "TouchOptimized"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2018 - Touch+finger extending touch-based user interface capabilities with idle finger gestures in the air.png"
    },
    {
      "id": 21,
      "title": "FingerInput Capturing Expressive Single-Hand Thumb-to-Finger Microgestures",
      "year": "2018",
      "category": "software",
      "hardwareDevices": [
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "ComputerVision",
        "DepthSensing"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Flex",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "DigitalArt",
        "MediaControl"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "OneHandUse"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2018-FingerInput Capturing Expressive Single-Hand Thumb-to-Finger Microgestures.png"
    },
    {
      "id": 22,
      "title": "AudioTouch minimally invasive sensing of micro-gestures via active bio-acoustic sensing",
      "year": "2019",
      "category": "hardware",
      "hardwareDevices": [
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "BioSensor",
        "PressureSensor",
        "UltrasonicSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "Hold",
        "Pinch",
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "SmartHome",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2019 - AudioTouch minimally invasive sensing of micro-gestures via active bio-acoustic sensing.png"
    },
    {
      "id": 23,
      "title": "TipText eyes-free text entry on a fingertip keyboard",
      "year": "2019",
      "category": "software",
      "hardwareDevices": [
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "ComputerVision",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "QWERTYLayout",
        "SmallScreen",
        "SocialAcceptability"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2019 - TipText eyes-free text entry on a fingertip keyboard.png"
    },
    {
      "id": 24,
      "title": "E-textile microinteractions augmenting twist with flick, slide and grasp gestures for soft electronics",
      "year": "2020",
      "category": "hardware",
      "hardwareDevices": [
        "Etextile",
        "OtherDevices",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "OtherTechnology",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Grasp",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "Gaming",
        "MediaControl",
        "OtherScenarios",
        "SmartHome"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "PortableDesign",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2020 - E-textile microinteractions augmenting twist with flick, slide and grasp gestures for soft electronics.png"
    },
    {
      "id": 25,
      "title": "Exploring user defined gestures for ear-based interactions",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "SmartGlasses",
        "Wearables"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OtherTechnology",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "EarBasedInteraction",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "MediaControl",
        "Navigation",
        "OtherScenarios",
        "SmartHome"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "HapticFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "OneHandUse",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Exploring user defined gestures for ear-based interactions.png"
    },
    {
      "id": 26,
      "title": "Fabriccio touchless gestural input on interactive fabrics",
      "year": "2020",
      "category": "hardware",
      "hardwareDevices": [
        "Etextile",
        "OtherDevices",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "RFSensing",
        "RadarSensing"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "IoTControl",
        "MediaControl",
        "OtherScenarios",
        "SmartHome"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "PortableDesign"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2020 - Fabriccio touchless gestural input on interactive fabrics.png"
    },
    {
      "id": 27,
      "title": "Finger gesture tracking for interactive applications a pilot study with sign languages",
      "year": "2020",
      "category": "software",
      "hardwareDevices": [
        "SmartRing",
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "Magnetometer",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "MotionAnalysis",
        "TrajectoryAnalysis"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "SignLanguageRelated",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "Education",
        "Healthcare",
        "Training"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "MultimodalFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "CommunicationAid",
        "EncumberedInteraction",
        "LowLatency",
        "PortableDesign",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Finger gesture tracking for interactive applications a pilot study with sign languages.png"
    },
    {
      "id": 28,
      "title": "How subtle can it get A trimodal study of ring-sized interfaces for one-handed drone control",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "SmartRing",
        "Smartphone",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "IMU",
        "MotionSensor",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Flex",
        "Hold",
        "SingleHand",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - How subtle can it get A trimodal study of ring-sized interfaces for one-handed drone control.png"
    },
    {
      "id": 29,
      "title": "Nailz sensing hand input with touch sensitive nails",
      "year": "2020",
      "category": "hardware",
      "hardwareDevices": [
        "SmartGlasses",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "IMU"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "MultiTouch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "OneHandUse",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2020 - Nailz sensing hand input with touch sensitive nails.png"
    },
    {
      "id": 30,
      "title": "ThermalRing gesture and tag inputs enabled by a thermal imaging smart ring",
      "year": "2020",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "InAirGesture",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "IoTControl",
        "MediaControl",
        "Navigation",
        "SmartHome"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HighAccuracy",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2020 - ThermalRing gesture and tag inputs enabled by a thermal imaging smart ring.png"
    },
    {
      "id": 32,
      "title": "ElectroRing subtle pinch and touch detection with a ring",
      "year": "2021",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "Pinch",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "DigitalArt",
        "MR",
        "MediaControl",
        "ObjectManipulation",
        "VR"
      ],
      "feedbackOutput": [
        "ProprioceptiveFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "PortableDesign"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2021 - ElectroRing subtle pinch and touch detection with a ring.png"
    },
    {
      "id": 33,
      "title": "SoloFinger robust microgestures while grasping everyday objects",
      "year": "2021",
      "category": "gesture-design",
      "hardwareDevices": [
        "DataGloves",
        "OtherDevices"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "DeviceContactGesture",
        "DirectTouch"
      ],
      "gestureTypes": [
        "Flex",
        "Grasp",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "ObjectManipulation",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "EncumberedInteraction",
        "HighAccuracy"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2021 - SoloFinger robust microgestures while grasping everyday objects.png"
    },
    {
      "id": 34,
      "title": "ThumbTrak recognizing micro-finger poses using a ring with proximity sensing",
      "year": "2021",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "DeviceContactGesture",
        "DirectTouch"
      ],
      "gestureTypes": [
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming",
        "MediaControl",
        "Navigation",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2021 - ThumbTrak recognizing micro-finger poses using a ring with proximity sensing.png"
    },
    {
      "id": 36,
      "title": "DualRing Enabling Subtle and Expressive Hand Interaction with Dual IMU Rings",
      "year": "2021",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "Magnetometer",
        "RFSensing"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "MotionAnalysis",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Grasp",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "IoTControl",
        "MediaControl",
        "ObjectManipulation",
        "SmartHome",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2021-DualRing Enabling Subtle and Expressive Hand Interaction with Dual IMU Rings.png"
    },
    {
      "id": 37,
      "title": "MicroPress detecting pressure and hover distance in thumb-to-finger interactions",
      "year": "2022",
      "category": "hardware",
      "hardwareDevices": [
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "DepthSensing",
        "Gyroscope",
        "IMU",
        "Magnetometer",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "DirectTouch",
        "NonContactBased"
      ],
      "gestureTypes": [
        "Hold",
        "Pinch",
        "SingleHand",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming",
        "MediaControl",
        "Navigation",
        "VR"
      ],
      "feedbackOutput": [
        "ProprioceptiveFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2022 - MicroPress detecting pressure and hover distance in thumb-to-finger interactions.png"
    },
    {
      "id": 39,
      "title": "DRG-Keyboard Enabling Subtle Gesture Typing on the Fingertip with Dual IMU Rings",
      "year": "2023",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "Magnetometer"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "TrajectoryAnalysis"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "SmartHome",
        "TextInput"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "PortableDesign",
        "QWERTYLayout",
        "SmallScreen"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2023-DRG-Keyboard Enabling Subtle Gesture Typing on the Fingertip with Dual IMU Rings.png"
    },
    {
      "id": 40,
      "title": "EFRing Enabling Thumb-to-Index-Finger Microgesture Interaction through Electric Field Sensing Using Single Smart Ring",
      "year": "2023",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "DigitalArt",
        "IoTControl",
        "MediaControl",
        "SmartHome",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2023-EFRing Enabling Thumb-to-Index-Finger Microgesture Interaction through Electric Field Sensing Using Single Smart Ring.png"
    },
    {
      "id": 41,
      "title": "SparseIMU Computational Design of Sparse IMU Layouts for Sensing Fine-grained Finger Microgestures",
      "year": "2023",
      "category": "hardware",
      "hardwareDevices": [
        "DataGloves",
        "SmartRing",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "Magnetometer",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "NonContactBased",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Flex",
        "Grasp",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "Gaming",
        "InVehicleInteraction",
        "IoTControl",
        "SmartHome",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EncumberedInteraction",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "PortableDesign"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2023-SparseIMU Computational Design of Sparse IMU Layouts for Sensing Fine-grained Finger Microgestures.png"
    },
    {
      "id": 42,
      "title": "VibAware Context-Aware Tap and Swipe Gestures Using Bio-Acoustic Sensing",
      "year": "2023",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "SmartWatch",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "BioSensor",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction",
        "NonContactBased",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Grasp",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "IoTControl",
        "MediaControl",
        "SmartHome",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EncumberedInteraction",
        "EyesFree",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2023-VibAware Context-Aware Tap and Swipe Gestures Using Bio-Acoustic Sensing.png"
    },
    {
      "id": 43,
      "title": "MAF exploring mobile acoustic field for hand-to-face gesture interactions",
      "year": "2024",
      "category": "hardware",
      "hardwareDevices": [
        "OtherDevices",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "OtherTechnology",
        "UltrasonicSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "HandToFaceGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Hold",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming",
        "Healthcare",
        "MediaControl",
        "SmartHome",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2024 - MAF exploring mobile acoustic field for hand-to-face gesture interactions.png"
    },
    {
      "id": 44,
      "title": "RadarHand a wrist-worn radar for on-skin touch-based proprioceptive gestures",
      "year": "2024",
      "category": "hardware",
      "hardwareDevices": [
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "RFSensing",
        "RadarSensing"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "Gaming",
        "InVehicleInteraction",
        "MediaControl",
        "Navigation",
        "SmartHome"
      ],
      "feedbackOutput": [
        "ProprioceptiveFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SmallScreen",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2024 - RadarHand a wrist-worn radar for on-skin touch-based proprioceptive gestures.png"
    },
    {
      "id": 45,
      "title": "Ring-a-pose a ring for continuous hand pose tracking",
      "year": "2024",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "OtherTechnology",
        "UltrasonicSensor"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "AccessibilitySupport",
        "Gaming",
        "MediaControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2024 - Ring-a-pose a ring for continuous hand pose tracking.png"
    },
    {
      "id": 46,
      "title": "Studying the simultaneous visual representation of microgestures",
      "year": "2024",
      "category": "software",
      "hardwareDevices": [
        "SmartWatch",
        "Smartphone",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "Hold",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HandsFree",
        "OneHandUse",
        "SmallScreen",
        "SocialAcceptability"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2024 - Studying the simultaneous visual representation of microgestures.png"
    },
    {
      "id": 47,
      "title": "HCMG Human-Capacitance based Micro Gesture for VR AR",
      "year": "2024",
      "category": "hardware",
      "hardwareDevices": [
        "ARGlasses",
        "VRHeadset",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "BioSensor",
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture"
      ],
      "gestureTypes": [
        "Grasp",
        "Pinch",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "AccessibilitySupport",
        "Education",
        "Gaming",
        "Training",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2024-HCMG Human-Capacitance based Micro Gesture for VR AR.png"
    },
    {
      "id": 48,
      "title": "BudsID mobile-ready and expressive finger identification input for earbuds",
      "year": "2025",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "IMU",
        "Magnetometer"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "DirectTouch",
        "EarBasedInteraction"
      ],
      "gestureTypes": [
        "MultiTouch",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "InVehicleInteraction",
        "MediaControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2025 - BudsID mobile-ready and expressive finger identification input for earbuds.png"
    },
    {
      "id": 49,
      "title": "Gesture and audio-haptic guidance techniques to direct conversations with intelligent voice interfaces",
      "year": "2025",
      "category": "software",
      "hardwareDevices": [
        "HapticDevice",
        "SmartGlasses",
        "SmartRing",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "IMU",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction",
        "VoiceGestureCombined"
      ],
      "gestureTypes": [
        "Hold",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "HapticFeedback",
        "MultimodalFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "LowLatency",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2025 - Gesture and audio-haptic guidance techniques to direct conversations with intelligent voice interfaces.png"
    },
    {
      "id": 50,
      "title": "LeakyFeeder In-air gesture control through leaky acoustic waves",
      "year": "2025",
      "category": "software",
      "hardwareDevices": [
        "OtherDevices",
        "Wearables"
      ],
      "sensingTechnology": [
        "OtherTechnology",
        "UltrasonicSensor"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "EarBasedInteraction",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "Hold",
        "Pinch",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl",
        "OtherScenarios",
        "SmartHome",
        "VR"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "PortableDesign"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2025 - LeakyFeeder In-air gesture control through leaky acoustic waves.png"
    },
    {
      "id": 51,
      "title": "DCSNN An Efficient and High-speed sEMG-based Transient-state Micro-gesture Recognition Method on Wearable Devices",
      "year": "2025",
      "category": "hardware",
      "hardwareDevices": [
        "OtherDevices",
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "BioSensor",
        "EMG",
        "IMU"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming",
        "IoTControl",
        "MediaControl",
        "Navigation",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "PortableDesign",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2025-DCSNN An Efficient and High-speed sEMG-based Transient-state Micro-gesture Recognition Method on Wearable Devices.png"
    },
    {
      "id": 52,
      "title": "VibRing A Wearable Vibroacoustic Sensor for Single-Handed Gesture Recognition",
      "year": "2025",
      "category": "hardware",
      "hardwareDevices": [
        "OtherDevices",
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming",
        "IoTControl",
        "MediaControl",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "LowLatency",
        "PortableDesign",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2025-VibRing A Wearable Vibroacoustic Sensor for Single-Handed Gesture Recognition.png"
    },
    {
      "id": 53,
      "title": "Exploring mixed-scale gesture interaction",
      "year": "2017",
      "category": "gesture-design",
      "hardwareDevices": [
        "ARGlasses",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "OpticalTracking",
        "RadarSensing"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "Grasp",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Exploring mixed-scale gesture interaction.png"
    },
    {
      "id": 54,
      "title": "Depth aware finger tapping on virtual displays",
      "year": "2018",
      "category": "software",
      "hardwareDevices": [
        "ARGlasses",
        "Smartphone",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "DepthSensing",
        "UltrasonicSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "MultimodalFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "LowLatency"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2018 - Depth aware finger tapping on virtual displays.png"
    },
    {
      "id": 55,
      "title": "Experimental analysis of barehand mid-air mode-switching techniques in virtual reality",
      "year": "2019",
      "category": "gesture-design",
      "hardwareDevices": [
        "VRHeadset",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "OpticalTracking",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "Grasp",
        "Pinch",
        "SingleHand"
      ],
      "applicationScenarios": [
        "ObjectManipulation",
        "VR"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2019 - Experimental analysis of barehand mid-air mode-switching techniques in virtual reality.png"
    },
    {
      "id": 56,
      "title": "Characterizing in-air eyes-free typing movements in VR",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "MotionAnalysis",
        "TrajectoryAnalysis"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DualHand",
        "Flex",
        "Tap"
      ],
      "applicationScenarios": [
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "QWERTYLayout"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Characterizing in-air eyes-free typing movements in VR.png"
    },
    {
      "id": 57,
      "title": "User gesture elicitation of common smartphone tasks for hand proximate user interfaces",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "ARGlasses",
        "SmartGlasses",
        "Smartphone"
      ],
      "sensingTechnology": [
        "ComputerVision"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "DirectTouch",
        "InAirGesture"
      ],
      "gestureTypes": [
        "Flex",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "MR",
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "OneHandUse",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020-User gesture elicitation of common smartphone tasks for hand proximate user interfaces.png"
    },
    {
      "id": 58,
      "title": "AtaTouch robust finger pinch detection for a VR controller using RF return loss",
      "year": "2021",
      "category": "hardware",
      "hardwareDevices": [
        "VRHeadset",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "RFSensing"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture"
      ],
      "gestureTypes": [
        "Grasp",
        "Pinch",
        "SingleHand",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "Gaming",
        "ObjectManipulation",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "LowLatency",
        "OcclusionAvoidance",
        "OneHandUse"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2021 - AtaTouch robust finger pinch detection for a VR controller using RF return loss.png"
    },
    {
      "id": 60,
      "title": "GraV grasp volume data for the design of one-handed XR interfaces",
      "year": "2024",
      "category": "software",
      "hardwareDevices": [
        "ARGlasses",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "ComputerVision"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Grasp",
        "SingleHand",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "ObjectManipulation",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "OneHandUse",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2024 - GraV grasp volume data for the design of one-handed XR interfaces.png"
    },
    {
      "id": 61,
      "title": "HapticPilot authoring in-situ hand posture-adaptive vibrotactile feedback for virtual reality",
      "year": "2024",
      "category": "software",
      "hardwareDevices": [
        "DataGloves",
        "HapticDevice",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand"
      ],
      "applicationScenarios": [
        "DigitalArt",
        "Gaming",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "LowLatency",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2024 - HapticPilot authoring in-situ hand posture-adaptive vibrotactile feedback for virtual reality.png"
    },
    {
      "id": 62,
      "title": "TriPad touch input in AR on ordinary surfaces with hand tracking only",
      "year": "2024",
      "category": "software",
      "hardwareDevices": [
        "ARGlasses",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "DepthSensing",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "InAirGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "MultiTouch",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "Navigation",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HandsFree",
        "LowLatency",
        "SocialAcceptability",
        "TouchOptimized"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2024 - TriPad touch input in AR on ordinary surfaces with hand tracking only.png"
    },
    {
      "id": 63,
      "title": "GraspUI Seamlessly Integrating Object-Centric Gestures within the Seven Phases of Grasping",
      "year": "2024",
      "category": "software",
      "hardwareDevices": [
        "ARGlasses",
        "SmartGlasses",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "InAirGesture",
        "MultiModalInteraction",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Grasp",
        "Hold",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl",
        "ObjectManipulation",
        "SmartHome"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2024-GraspUI Seamlessly Integrating Object-Centric Gestures within the Seven Phases of Grasping.png"
    },
    {
      "id": 64,
      "title": "Stick-To-XR Understanding Stick-Based User Interface Design for Extended Reality",
      "year": "2024",
      "category": "hardware",
      "hardwareDevices": [
        "HapticDevice",
        "OtherDevices",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OpticalTracking",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DualHand",
        "Grasp",
        "Hold",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AR",
        "Education",
        "Gaming",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "MultimodalFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "OneHandUse",
        "PortableDesign",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2024-Stick-To-XR Understanding Stick-Based User Interface Design for Extended Reality.png"
    },
    {
      "id": 65,
      "title": "STMG A Machine Learning Microgesture Recognition System for Supporting Thumb-Based VR AR Input",
      "year": "2024",
      "category": "software",
      "hardwareDevices": [
        "ARGlasses",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl",
        "Navigation",
        "ObjectManipulation",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2024-STMG A Machine Learning Microgesture Recognition System for Supporting Thumb-Based VR AR Input.png"
    },
    {
      "id": 66,
      "title": "Understanding Gesture and Microgesture Inputs for Augmented Reality Maps",
      "year": "2024",
      "category": "gesture-design",
      "hardwareDevices": [
        "ARGlasses",
        "SmartGlasses",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "CapacitiveSensor",
        "ComputerVision",
        "IMU",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "Navigation"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "ProprioceptiveFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "OneHandUse",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2024-Understanding Gesture and Microgesture Inputs for Augmented Reality Maps.png"
    },
    {
      "id": 67,
      "title": "T2IRay Design of Thumb-to-Index based Indirect Pointing for Continuous and Robust AR VR Input",
      "year": "2025",
      "category": "gesture-design",
      "hardwareDevices": [
        "ARGlasses",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "ObjectManipulation",
        "VR"
      ],
      "feedbackOutput": [
        "ProprioceptiveFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "OneHandUse",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2025-T2IRay Design of Thumb-to-Index based Indirect Pointing for Continuous and Robust AR VR Input.png"
    },
    {
      "id": 68,
      "title": "Key-press gestures recognition and interaction based on SEMG signals",
      "year": "2010",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "BioSensor",
        "EMG"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "Flex",
        "Hold",
        "SingleHand"
      ],
      "applicationScenarios": [
        "MediaControl",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EncumberedInteraction",
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2010 - Key-press gestures recognition and interaction based on SEMG signals.png"
    },
    {
      "id": 69,
      "title": "A study of on-device gestures",
      "year": "2012",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone"
      ],
      "sensingTechnology": [
        "PressureSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "ContactBased",
        "DeviceContactGesture"
      ],
      "gestureTypes": [
        "Grasp",
        "SingleHand",
        "Swipe"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "ProprioceptiveFeedback"
      ],
      "userExperienceDesign": [
        "EncumberedInteraction",
        "OcclusionAvoidance",
        "OneHandUse"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2012 - A study of on-device gestures.png"
    },
    {
      "id": 70,
      "title": "PinchPad performance of touch-based gestures while grasping devices",
      "year": "2012",
      "category": "gesture-design",
      "hardwareDevices": [
        "Tablet"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "ContactBased",
        "DeviceContactGesture",
        "DirectTouch"
      ],
      "gestureTypes": [
        "Grasp",
        "Pinch",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "ProprioceptiveFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "OcclusionAvoidance",
        "OneHandUse"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2012 - PinchPad performance of touch-based gestures while grasping devices.png"
    },
    {
      "id": 71,
      "title": "The fat thumb using the thumb's contact size for single-handed mobile interaction",
      "year": "2012",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "SingleHand",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "FatFingerProblem",
        "OneHandUse",
        "SmallScreen",
        "TouchOptimized"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2012 - The fat thumb using the thumb's contact size for single-handed mobile interaction.png"
    },
    {
      "id": 72,
      "title": "Exploring pinch and spread gestures on mobile devices",
      "year": "2013",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone",
        "Tablet"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "DirectTouch",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DualHand",
        "MultiTouch",
        "Pinch",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "SmallScreen",
        "TouchOptimized"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2013 - Exploring pinch and spread gestures on mobile devices.png"
    },
    {
      "id": 74,
      "title": "Leap gestures for TV insights from an elicitation study",
      "year": "2014",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "Flex",
        "Hold",
        "SingleHand"
      ],
      "applicationScenarios": [
        "MediaControl"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "HandsFree",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2014 - Leap gestures for TV insights from an elicitation study.png"
    },
    {
      "id": 75,
      "title": "Tactile feedback for above-device gesture interfaces adding touch to touchless interactions",
      "year": "2014",
      "category": "software",
      "hardwareDevices": [
        "HapticDevice",
        "SmartRing",
        "SmartWatch",
        "Smartphone",
        "Wearables"
      ],
      "sensingTechnology": [
        "OpticalTracking",
        "UltrasonicSensor"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "SingleHand"
      ],
      "applicationScenarios": [
        "MediaControl"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "MultimodalFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "SmallScreen",
        "TouchOptimized"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2014 - Tactile feedback for above-device gesture interfaces adding touch to touchless interactions.png"
    },
    {
      "id": 76,
      "title": "Interaction proxemics combining physical spaces for seamless gesture interaction",
      "year": "2015",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "DepthSensing",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "DirectTouch",
        "InAirGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "Navigation",
        "ObjectManipulation",
        "TextInput"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2015 - Interaction proxemics combining physical spaces for seamless gesture interaction.png"
    },
    {
      "id": 77,
      "title": "Exploring non-touchscreen gestures for smartwatches",
      "year": "2016",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartWatch",
        "Wearables"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "DeviceContactGesture",
        "InAirGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "ElicitationStudy",
        "FatFingerProblem",
        "OcclusionAvoidance",
        "SmallScreen",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2016 - Exploring non-touchscreen gestures for smartwatches.png"
    },
    {
      "id": 78,
      "title": " Finger-aware shortcuts",
      "year": "2016",
      "category": "software",
      "hardwareDevices": [
        "Keyboard"
      ],
      "sensingTechnology": [
        "ComputerVision"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "DeviceContactGesture"
      ],
      "gestureTypes": [
        "DualHand",
        "Hold",
        "SingleHand"
      ],
      "applicationScenarios": [
        "TextInput"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "QWERTYLayout",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2016 - Finger-aware shortcuts.png"
    },
    {
      "id": 79,
      "title": "Interacting with soli exploring fine-grained dynamic gesture recognition in the radio-frequency spectrum",
      "year": "2016",
      "category": "hardware",
      "hardwareDevices": [
        "OtherDevices",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "RFSensing",
        "RadarSensing"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "ObjectManipulation",
        "SmartHome"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "OcclusionAvoidance",
        "PortableDesign"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2016 - Interacting with soli exploring fine-grained dynamic gesture recognition in the radio-frequency spectrum.png"
    },
    {
      "id": 80,
      "title": "Investigating how the hand interacts with different mobile phones",
      "year": "2016",
      "category": "gesture-design",
      "hardwareDevices": [
        "Keyboard",
        "Smartphone",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "ComputerVision"
      ],
      "recognitionClassification": [
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "DirectTouch"
      ],
      "gestureTypes": [
        "DualHand",
        "Grasp",
        "Hold",
        "SingleHand"
      ],
      "applicationScenarios": [
        "MediaControl",
        "TextInput"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "OneHandUse",
        "TouchOptimized"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2016 - Investigating how the hand interacts with different mobile phones.png"
    },
    {
      "id": 81,
      "title": "WiFinger talk to your smart devices with finger-grained gesture",
      "year": "2016",
      "category": "software",
      "hardwareDevices": [
        "OtherDevices",
        "Smartphone"
      ],
      "sensingTechnology": [
        "RFSensing"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "SignLanguageRelated",
        "SingleHand"
      ],
      "applicationScenarios": [
        "SmartHome",
        "TextInput"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HandsFree",
        "HighAccuracy"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2016 - WiFinger talk to your smart devices with finger-grained gesture.png"
    },
    {
      "id": 82,
      "title": "Understanding grip shifts how form factors impact hand movements on mobile phones",
      "year": "2017",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "DualHand",
        "Hold",
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "Navigation",
        "TextInput"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "OneHandUse",
        "PortableDesign",
        "SmallScreen",
        "TouchOptimized"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Understanding grip shifts how form factors impact hand movements on mobile phones.png"
    },
    {
      "id": 83,
      "title": "Characterizing finger pitch and roll orientation during atomic touch actions",
      "year": "2018",
      "category": "gesture-design",
      "hardwareDevices": [
        "Tablet",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "Magnetometer"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "DualHand",
        "Hold",
        "MultiTouch",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "TouchOptimized"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Characterizing finger pitch and roll orientation during atomic touch actions.png"
    },
    {
      "id": 84,
      "title": "Fingers' range and comfortable area for one-handed smartphone interaction beyond the touchscreen",
      "year": "2018",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "FatFingerProblem",
        "OcclusionAvoidance",
        "OneHandUse",
        "PortableDesign",
        "TouchOptimized"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Fingers' range and comfortable area for one-handed smartphone interaction beyond the touchscreen.png"
    },
    {
      "id": 85,
      "title": "InfiniTouch finger-aware interaction on fully touch sensitive smartphones",
      "year": "2018",
      "category": "hardware",
      "hardwareDevices": [
        "Smartphone",
        "TouchScreen",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "Flex",
        "Pinch",
        "SingleHand",
        "Swipe",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "MediaControl",
        "ObjectManipulation",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "FatFingerProblem",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2018 - InfiniTouch finger-aware interaction on fully touch sensitive smartphones.png"
    },
    {
      "id": 86,
      "title": "Pen + mid-air gestures eliciting contextual gestures",
      "year": "2018",
      "category": "gesture-design",
      "hardwareDevices": [
        "Tablet",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased",
        "PenInput"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "Grasp",
        "Pinch",
        "Swipe"
      ],
      "applicationScenarios": [
        "DigitalArt",
        "Education",
        "MediaControl",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EncumberedInteraction",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Pen + mid-air gestures eliciting contextual gestures.png"
    },
    {
      "id": 87,
      "title": "Unimanual Pen Touch Input Using Variations of Precision Grip Postures",
      "year": "2018",
      "category": "gesture-design",
      "hardwareDevices": [
        "Tablet",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction",
        "PenInput"
      ],
      "gestureTypes": [
        "Grasp",
        "MultiTouch",
        "SingleHand"
      ],
      "applicationScenarios": [
        "DigitalArt",
        "Education",
        "ObjectManipulation",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "HighAccuracy",
        "OneHandUse",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2018-Unimanual Pen Touch Input Using Variations of Precision Grip Postures.png"
    },
    {
      "id": 88,
      "title": "Gaze-assisted typing for smart glasses",
      "year": "2019",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartGlasses",
        "VRHeadset",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "GazeBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "TextInput"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EyesFree",
        "LowLatency",
        "MidasTouchProblem",
        "OneHandUse",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2019 - Gaze-assisted typing for smart glasses.png"
    },
    {
      "id": 89,
      "title": "Investigating unintended inputs for one-handed touch interaction beyond the touchscreen",
      "year": "2019",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "MotionAnalysis",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "ContactBased",
        "DeviceContactGesture"
      ],
      "gestureTypes": [
        "Grasp",
        "SingleHand"
      ],
      "applicationScenarios": [
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EncumberedInteraction",
        "FatFingerProblem",
        "OcclusionAvoidance",
        "OneHandUse",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2019 - Investigating unintended inputs for one-handed touch interaction beyond the touchscreen.png"
    },
    {
      "id": 90,
      "title": "Expanding Side Touch Input on Mobile Phones",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "MediaControl",
        "Navigation",
        "TextInput"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "FatFingerProblem",
        "HighAccuracy",
        "OcclusionAvoidance",
        "OneHandUse",
        "PortableDesign"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Expanding side touch input on mobile phones finger reachability and two-dimensional taps and flicks using the index and.png"
    },
    {
      "id": 91,
      "title": "MagTouch robust finger identification for a smartwatch using a magnet ring and a built-in magnetometer",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartRing",
        "SmartWatch",
        "Wearables"
      ],
      "sensingTechnology": [
        "IMU",
        "Magnetometer",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - MagTouch robust finger identification for a smartwatch using a magnet ring and a built-in magnetometer.png"
    },
    {
      "id": 92,
      "title": "PenSight enhanced interaction with a pen-top camera",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "Tablet"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "DepthSensing",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction",
        "NonContactBased",
        "PenInput",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DualHand",
        "Grasp"
      ],
      "applicationScenarios": [
        "DigitalArt",
        "Education",
        "Navigation",
        "ObjectManipulation",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EncumberedInteraction",
        "HighAccuracy",
        "LowLatency",
        "OcclusionAvoidance",
        "PortableDesign"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - PenSight enhanced interaction with a pen-top camera.png"
    },
    {
      "id": 93,
      "title": "Shortcut gestures for mobile text editing on fully touch sensitive smartphones",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone",
        "TouchScreen",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "ContactBased",
        "DeviceContactGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Hold",
        "MultiTouch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "OtherScenarios",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "FatFingerProblem",
        "HighAccuracy",
        "OcclusionAvoidance",
        "OneHandUse",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Shortcut gestures for mobile text editing on fully touch sensitive smartphones.png"
    },
    {
      "id": 94,
      "title": "Eliciting tangible and gestural user interactions with and on a cooking pan",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Grasp",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "OtherScenarios",
        "SmartHome"
      ],
      "feedbackOutput": [
        "MultimodalFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EncumberedInteraction"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Eliciting tangible and gestural user interactions with and on a cooking pan.png"
    },
    {
      "id": 95,
      "title": "3D hand pose estimation on conventional capacitive touchscreens",
      "year": "2021",
      "category": "gesture-design",
      "hardwareDevices": [
        "Tablet",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DualHand",
        "Grasp",
        "MultiTouch",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AR",
        "DigitalArt",
        "Gaming",
        "ObjectManipulation",
        "Training",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "FatFingerProblem",
        "HighAccuracy",
        "LowLatency",
        "OcclusionAvoidance",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2021 - 3D hand pose estimation on conventional capacitive touchscreens.png"
    },
    {
      "id": 96,
      "title": "TouchPose hand pose prediction, depth estimation, and touch classification from capacitive images",
      "year": "2021",
      "category": "software",
      "hardwareDevices": [
        "Smartphone",
        "Tablet",
        "TouchScreen",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "ComputerVision",
        "DepthSensing",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Grasp",
        "MultiTouch",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AR",
        "DigitalArt",
        "ObjectManipulation",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "LowLatency",
        "OcclusionAvoidance",
        "TouchOptimized",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2021 - TouchPose hand pose prediction, depth estimation, and touch classification from capacitive images.png"
    },
    {
      "id": 97,
      "title": "Watching your phone's back gesture recognition by sensing acoustical structure-borne propagation",
      "year": "2021",
      "category": "software",
      "hardwareDevices": [
        "OtherDevices",
        "Smartphone",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OtherTechnology",
        "UltrasonicSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "DeviceContactGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "IoTControl",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "MultimodalFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "LowLatency",
        "OcclusionAvoidance",
        "PortableDesign",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2021 - Watching your phone's back gesture recognition by sensing acoustical structure-borne propagation.png"
    },
    {
      "id": 98,
      "title": "A User-based Mid-air Hand Gesture Set for Spreadsheets",
      "year": "2021",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "Pinch",
        "SingleHand",
        "Swipe"
      ],
      "applicationScenarios": [
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2021-A User-based Mid-air Hand Gesture Set for Spreadsheets.png"
    },
    {
      "id": 99,
      "title": "Leveraging the properties of mmWave signals for 3D finger motion tracking for interactive IoT applications",
      "year": "2022",
      "category": "software",
      "hardwareDevices": [
        "OtherDevices",
        "Smartphone",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "RFSensing",
        "RadarSensing"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "ContinuousRecognition",
        "FingerTracking",
        "HandTracking"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "Flex",
        "SignLanguageRelated",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AR",
        "AccessibilitySupport",
        "Healthcare",
        "IoTControl",
        "SmartHome",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2022 - Leveraging the properties of mmWave signals for 3D finger motion tracking for interactive IoT applications.png"
    },
    {
      "id": 100,
      "title": "IndexPen Two Finger Text Input with Millimeter Wave Radar",
      "year": "2022",
      "category": "software",
      "hardwareDevices": [
        "OtherDevices",
        "Smartphone",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "RFSensing",
        "RadarSensing"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "AccessibilitySupport",
        "IoTControl",
        "SmartHome",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2022-IndexPen Two Finger Text Input with Millimeter Wave Radar.png"
    },
    {
      "id": 101,
      "title": "SoloFinger Robust Microgestures while Grasping Everyday Objects",
      "year": "2021",
      "category": "gesture-design",
      "hardwareDevices": [
        "DataGloves",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Flex",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "ObjectManipulation",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2021 - SoloFinger robust microgestures while grasping everyday objects.png"
    },
    {
      "id": 102,
      "title": "ARO Exploring the Design of Smart-Ring Interactions for Encumbered Hands",
      "year": "2021",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "CapacitiveSensor",
        "Gyroscope",
        "IMU"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "InAirGesture"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Grasp",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "ElicitationStudy",
        "EncumberedInteraction",
        "HandsFree",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2021-ARO Exploring the Design of Smart-Ring Interactions for Encumbered Hands.png"
    },
    {
      "id": 103,
      "title": "Enabling voice-accompanying hand-to-face gesture recognition with cross-device sensing",
      "year": "2023",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartRing",
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "UltrasonicSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "EarBasedInteraction",
        "MultiModalInteraction",
        "VoiceGestureCombined"
      ],
      "gestureTypes": [
        "SingleHand"
      ],
      "applicationScenarios": [
        "AR",
        "IoTControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "HandsFree",
        "LowLatency",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2023 - Enabling voice-accompanying hand-to-face gesture recognition with cross-device sensing.png"
    },
    {
      "id": 104,
      "title": "iFAD Gestures Understanding Users’ Gesture Input Performance with Index-Finger Augmentation Devices",
      "year": "2023",
      "category": "software",
      "hardwareDevices": [
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "DeviceContactGesture",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "SmartHome",
        "TextInput"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HandsFree",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2023-iFAD Gestures Understanding Users’ Gesture Input Performance with Index-Finger Augmentation Devices.png"
    },
    {
      "id": 105,
      "title": "Persistent assistant seamless everyday AI interactions via intent grounding and multimodal feedback",
      "year": "2025",
      "category": "software",
      "hardwareDevices": [
        "ARGlasses",
        "HapticDevice",
        "SmartGlasses",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "GazeBased",
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased",
        "VoiceGestureCombined"
      ],
      "gestureTypes": [
        "Pinch",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AR",
        "Navigation",
        "SmartHome"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "HapticFeedback",
        "MultimodalFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "OneHandUse",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2025 - Persistent assistant seamless everyday AI interactions via intent grounding and multimodal feedback.png"
    },
    {
      "id": 106,
      "title": "Grasp Interaction with Tablets",
      "year": "2011",
      "category": "software",
      "hardwareDevices": [
        "Tablet",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "CapacitiveSensor",
        "Gyroscope",
        "IMU",
        "Magnetometer"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DualHand",
        "Grasp",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "FatFingerProblem",
        "MidasTouchProblem",
        "OcclusionAvoidance",
        "OneHandUse",
        "SmallScreen",
        "TouchOptimized"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2011-Grasp Interaction with Tablets.png"
    },
    {
      "id": 107,
      "title": "Opportunistic synergy a classifier fusion engine for micro-gesture recognition",
      "year": "2013",
      "category": "software",
      "hardwareDevices": [
        "DrivingSimulator",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "BioSensor",
        "EMG",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "MultiModalInteraction",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Grasp",
        "Hold",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "InVehicleInteraction"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2013 - Opportunistic synergy a classifier fusion engine for micro-gesture recognition.png"
    },
    {
      "id": 109,
      "title": "The performance and preference of different fingers and chords for pointing, dragging, and object transformation",
      "year": "2016",
      "category": "gesture-design",
      "hardwareDevices": [
        "Tablet",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "Hold",
        "MultiTouch",
        "Pinch",
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "LowLatency",
        "TouchOptimized",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2016 - The performance and preference of different fingers and chords for pointing, dragging, and object transformation.png"
    },
    {
      "id": 110,
      "title": "BikeGesture user elicitation and performance of micro hand gesture as input for cycling",
      "year": "2017",
      "category": "hardware",
      "hardwareDevices": [
        "DataGloves",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "BioSensor",
        "IMU",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "Flex",
        "Grasp",
        "Pinch",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "AthleticActivity",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2017 - BikeGesture user elicitation and performance of micro hand gesture as input for cycling.png"
    },
    {
      "id": 112,
      "title": "M[eye]cro eye-gaze+microgestures for multitasking and interruptions",
      "year": "2021",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "OpticalTracking",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "GazeBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "Pinch",
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "InVehicleInteraction",
        "ObjectManipulation",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "MultimodalFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "LowLatency",
        "MidasTouchProblem",
        "OneHandUse"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2021 - M[eye]cro eye-gaze+microgestures for multitasking and interruptions.png"
    },
    {
      "id": 115,
      "title": "AnyButton unpowered, modeless and highly available mobile input using unmodified clothing buttons",
      "year": "2014",
      "category": "hardware",
      "hardwareDevices": [
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "GestureRecognition",
        "HandTracking",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "HapticFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HandsFree",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2014 - AnyButton unpowered, modeless and highly available mobile input using unmodified clothing buttons.png"
    },
    {
      "id": 116,
      "title": "Towards the establishment of a framework for intuitive multi-touch interaction design",
      "year": "2012",
      "category": "gesture-design",
      "hardwareDevices": [
        "Smartphone",
        "Tablet",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "CapacitiveSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "HandTracking",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "MultiTouch",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "Navigation",
        "ObjectManipulation",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "HapticFeedback",
        "MultimodalFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "FatFingerProblem",
        "HighAccuracy",
        "OcclusionAvoidance",
        "TouchOptimized",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2012 - Towards the establishment of a framework for intuitive multi-touch interaction design.png"
    },
    {
      "id": 117,
      "title": "Grasping microgestures eliciting single-hand microgestures for handheld objects",
      "year": "2019",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "Smartphone"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "Magnetometer",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "DeviceContactGesture",
        "DirectTouch"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Grasp",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "IoTControl",
        "ObjectManipulation",
        "OtherScenarios",
        "SmartHome"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "ElicitationStudy",
        "EncumberedInteraction",
        "OneHandUse"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2019 - Grasping microgestures eliciting single-hand microgestures for handheld objects.png"
    },
    {
      "id": 118,
      "title": "Rhythmic micro-gestures discreet interaction on-the-go",
      "year": "2017",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Flex",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "MultimodalFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "MidasTouchProblem",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Rhythmic micro-gestures discreet interaction on-the-go.png"
    },
    {
      "id": 119,
      "title": "Studying the visual representation of microgestures",
      "year": "2023",
      "category": "gesture-design",
      "hardwareDevices": [
        "ARGlasses",
        "OtherDevices"
      ],
      "sensingTechnology": [
        "Magnetometer",
        "OtherTechnology"
      ],
      "recognitionClassification": [],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "Flex",
        "Hold",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "Education"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "ElicitationStudy",
        "OneHandUse"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2023 - Studying the visual representation of microgestures.png"
    },
    {
      "id": 120,
      "title": "µGlyph a microgesture notation",
      "year": "2023",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices"
      ],
      "sensingTechnology": [
        "OtherTechnology"
      ],
      "recognitionClassification": [],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "NonContactBased"
      ],
      "gestureTypes": [
        "Flex",
        "Hold",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "Education"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "OneHandUse"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2023 - µGlyph a microgesture notation.png"
    },
    {
      "id": 121,
      "title": "User elicitation on single-hand microgestures",
      "year": "2016",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "ObjectManipulation",
        "TextInput"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EyesFree",
        "OneHandUse",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2016 - User elicitation on single-hand microgestures.png"
    },
    {
      "id": 122,
      "title": "Would you do that understanding social acceptance of gestural interfaces",
      "year": "2010",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices",
        "Smartphone"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "OtherScenarios",
        "SmartHome"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2010 - Would you do that understanding social acceptance of gestural interfaces.png"
    },
    {
      "id": 123,
      "title": "Hands as a controller user preferences for hand specific on-skin gestures",
      "year": "2017",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "ComputerVision",
        "IMU",
        "RadarSensing",
        "UltrasonicSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "DualHand",
        "Pinch",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "InVehicleInteraction",
        "IoTControl",
        "MediaControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Hands as a controller user preferences for hand specific on-skin gestures.png"
    },
    {
      "id": 124,
      "title": "Designing More Private and Socially Acceptable Hand-to-Face Gestures for Heads-Up Computing",
      "year": "2024",
      "category": "gesture-design",
      "hardwareDevices": [
        "ARGlasses",
        "SmartGlasses",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "OtherScenarios",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "ProprioceptiveFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2024-Designing More Private and Socially Acceptable Hand-to-Face Gestures for Heads-Up Computing.png"
    },
    {
      "id": 125,
      "title": "Blind people and mobile touch-based text-entry acknowledging the need for different flavors",
      "year": "2011",
      "category": "software",
      "hardwareDevices": [
        "Smartphone",
        "TouchScreen"
      ],
      "sensingTechnology": [
        "PressureSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "MultiTouch",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "TextInput"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "MultimodalFeedback"
      ],
      "userExperienceDesign": [
        "FatFingerProblem",
        "QWERTYLayout",
        "TouchOptimized",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2011 - Blind people and mobile touch-based text-entry acknowledging the need for different flavors.png"
    },
    {
      "id": 126,
      "title": "Interaction gestures for a wearable device defined by visually impaired children",
      "year": "2016",
      "category": "gesture-design",
      "hardwareDevices": [
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "Hold",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "Healthcare",
        "Training"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "MultimodalFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EyesFree",
        "OneHandUse",
        "PortableDesign",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2016 - Interaction gestures for a wearable device defined by visually impaired children.png"
    },
    {
      "id": 127,
      "title": "Investigating microinteractions for people with visual impairments and the potential role of on-body interaction",
      "year": "2017",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartWatch",
        "Smartphone",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "IMU",
        "MotionSensor",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "MediaControl",
        "Navigation",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Investigating microinteractions for people with visual impairments and the potential role of on-body interaction.png"
    },
    {
      "id": 128,
      "title": "Static fingerspelling recognition based on boundary tracing algorithm and chain code",
      "year": "2018",
      "category": "software",
      "hardwareDevices": [
        "OtherDevices"
      ],
      "sensingTechnology": [
        "ComputerVision"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "NonContactBased"
      ],
      "gestureTypes": [
        "SignLanguageRelated",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AccessibilitySupport"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2018 - Static fingerspelling recognition based on boundary tracing algorithm and chain code.png"
    },
    {
      "id": 129,
      "title": "Keep the phone in your pocket enabling smartphone operation with an IMU ring for visually impaired people",
      "year": "2020",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "Smartphone",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport"
      ],
      "feedbackOutput": [
        "AudioFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2020 - Keep the phone in your pocket enabling smartphone operation with an IMU ring for visually impaired people.png"
    },
    {
      "id": 130,
      "title": "Performance evaluation of pattern recognition networks using electromyography signal and time-domain features for the classification of hand gestures",
      "year": "2020",
      "category": "software",
      "hardwareDevices": [
        "WearableSensor"
      ],
      "sensingTechnology": [
        "BioSensor",
        "EMG"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased"
      ],
      "gestureTypes": [
        "Flex",
        "Grasp",
        "SingleHand",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "Healthcare"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "CommunicationAid",
        "HighAccuracy"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2020 - Performance evaluation of pattern recognition networks using electromyography signal and time-domain features for the cl.png"
    },
    {
      "id": 131,
      "title": "Keep in touch combining touch interaction with thumb-to-finger µGestures for people with visual impairment",
      "year": "2022",
      "category": "software",
      "hardwareDevices": [
        "Tablet",
        "TouchScreen",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "Education",
        "Navigation"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "MultimodalFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "CommunicationAid",
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "OneHandUse",
        "TouchOptimized"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2022 - Keep in touch combining touch interaction with thumb-to-finger µGestures for people with visual impairment.png"
    },
    {
      "id": 132,
      "title": "µGeT multimodal eyes-free text selection technique combining touch interaction and microgestures",
      "year": "2023",
      "category": "software",
      "hardwareDevices": [
        "Tablet",
        "TouchScreen",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "ComputerVision"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "Hold",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "TextInput"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "OneHandUse",
        "TouchOptimized"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2023 - µGeT multimodal eyes-free text selection technique combining touch interaction and microgestures.png"
    },
    {
      "id": 133,
      "title": "Designing upper-body gesture interaction with and for people with spinal muscular atrophy in VR",
      "year": "2024",
      "category": "gesture-design",
      "hardwareDevices": [
        "VRHeadset",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "ComputerVision"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "GazeBased",
        "InAirGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "VR"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HandsFree",
        "OneHandUse",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2024 - Designing upper-body gesture interaction with and for people with spinal muscular atrophy in VR.png"
    },
    {
      "id": 134,
      "title": "Finger gesture tracking for interactive applications a pilot study with sign languages",
      "year": "2020",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartRing",
        "SmartWatch",
        "WearableSensor"
      ],
      "sensingTechnology": [
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "DualHand",
        "SignLanguageRelated",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "Education"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HighAccuracy",
        "LowLatency",
        "PortableDesign",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Finger gesture tracking for interactive applications a pilot study with sign languages.png"
    },
    {
      "id": 135,
      "title": "A non-linear model of shape  and motion for tracking finger spelt American sign language",
      "year": "2002",
      "category": "gesture-design",
      "hardwareDevices": [
        "OtherDevices"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "HandTracking",
        "MotionAnalysis",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "SignLanguageRelated",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "Education"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2002-A non-linear model of shape  and motion for tracking finger spelt American sign language.png"
    },
    {
      "id": 140,
      "title": "WristFlex- low-power gesture input with wrist-worn pressure sensors",
      "year": "2014",
      "category": "hardware",
      "hardwareDevices": [
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "Pinch",
        "SingleHand",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AthleticActivity",
        "IoTControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2014 - WristFlex- low-power gesture input with wrist-worn pressure sensors.png"
    },
    {
      "id": 141,
      "title": "CyclopsRing- Enabling Whole-Hand and  Context-Aware Interactions Through a Fisheye Ring",
      "year": "2015",
      "category": "hardware",
      "hardwareDevices": [
        "OtherDevices",
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "HandTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming",
        "IoTControl",
        "SmartHome",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HandsFree",
        "OneHandUse",
        "PortableDesign",
        "QWERTYLayout"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2015 - CyclopsRing- Enabling Whole-Hand and  Context-Aware Interactions Through a Fisheye Ring.png"
    },
    {
      "id": 142,
      "title": "Combining Ring Input with Hand  Tracking for Precise, Natural Interaction with Spatial Analytic Interfaces",
      "year": "2016",
      "category": "software",
      "hardwareDevices": [
        "ARGlasses",
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "ComputerVision",
        "DepthSensing",
        "IMU",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "ContinuousRecognition",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Grasp",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "Navigation",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "PortableDesign"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2016 - Combining Ring Input with Hand  Tracking for Precise, Natural Interaction with Spatial Analytic Interfaces..png"
    },
    {
      "id": 143,
      "title": "DigitSpace Designing Thumb-to-Fingers Touch Interfaces for One-Handed and Eyes-Free Interactions",
      "year": "2016",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "OpticalTracking",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "TextInput"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EyesFree",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2016 - DigitSpace Designing Thumb-to-Fingers Touch Interfaces for One-Handed and Eyes-Free Interactions.png"
    },
    {
      "id": 144,
      "title": "ThumbRing- private interactions using one-handed thumb motion input on  finger segments",
      "year": "2016",
      "category": "hardware",
      "hardwareDevices": [
        "ARGlasses",
        "SmartGlasses",
        "SmartRing",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "Magnetometer",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "GestureRecognition",
        "MotionAnalysis",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2016 - ThumbRing- private interactions using one-handed thumb motion input on  finger segments.png"
    },
    {
      "id": 145,
      "title": "Interacting with Soli- Exploring Fine-Grained Dynamic  Gesture Recognition in the Radio-Frequency Spectrum",
      "year": "2016",
      "category": "software",
      "hardwareDevices": [
        "OtherDevices",
        "Wearables"
      ],
      "sensingTechnology": [
        "RFSensing",
        "RadarSensing"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "IoTControl",
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "OcclusionAvoidance"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2016-Interacting with Soli- Exploring Fine-Grained Dynamic  Gesture Recognition in the Radio-Frequency Spectrum.png"
    },
    {
      "id": 146,
      "title": "Soli- Ubiquitous Gesture Sensing with Millimeter Wave Radar",
      "year": "2016",
      "category": "hardware",
      "hardwareDevices": [
        "OtherDevices",
        "SmartWatch",
        "VRHeadset",
        "Wearables"
      ],
      "sensingTechnology": [
        "MotionSensor",
        "RFSensing",
        "RadarSensing"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "Gaming",
        "IoTControl",
        "MediaControl",
        "Navigation",
        "SmartHome",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "OcclusionAvoidance",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2016-Soli- Ubiquitous Gesture Sensing with Millimeter Wave Radar..png"
    },
    {
      "id": 147,
      "title": "TouchRing- Subtle and  Always-Available Input Using a Multi-Touch Ring",
      "year": "2016",
      "category": "hardware",
      "hardwareDevices": [
        "SmartGlasses",
        "SmartRing",
        "TouchScreen",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "MultiTouch",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability",
        "TouchOptimized"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2016-TouchRing- Subtle and  Always-Available Input Using a Multi-Touch Ring.png"
    },
    {
      "id": 148,
      "title": "DigiTouch- Reconfigurable Thumb-to-Finger Input and Text Entry on Head-mounted Displays",
      "year": "2017",
      "category": "hardware",
      "hardwareDevices": [
        "ARGlasses",
        "DataGloves",
        "VRHeadset",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture"
      ],
      "gestureTypes": [
        "Hold",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "ProprioceptiveFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "OcclusionAvoidance",
        "PortableDesign",
        "QWERTYLayout",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2017 - DigiTouch- Reconfigurable Thumb-to-Finger Input and Text Entry on Head-mounted Displays.png"
    },
    {
      "id": 149,
      "title": "FingerSound- Recognizing unistroke thumb gestures using a ring",
      "year": "2017",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Gyroscope",
        "MotionSensor",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl",
        "SmartHome",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "HapticFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HighAccuracy",
        "MidasTouchProblem",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2017 - FingerSound- Recognizing unistroke thumb gestures using a ring..png"
    },
    {
      "id": 152,
      "title": "Fingert9- Leveraging  thumb-to-finger interaction for same-side-hand text entry on smartwatches",
      "year": "2018",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartWatch",
        "TouchScreen",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "Hold",
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "TextInput"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EyesFree",
        "OcclusionAvoidance",
        "OneHandUse",
        "SmallScreen",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Fingert9- Leveraging  thumb-to-finger interaction for same-side-hand text entry on smartwatches.png"
    },
    {
      "id": 153,
      "title": "ThumbText- Text Entry for Wearable Devices Using a Miniature Ring",
      "year": "2018",
      "category": "hardware",
      "hardwareDevices": [
        "SmartGlasses",
        "SmartRing",
        "SmartWatch",
        "TouchScreen",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "Hold",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "TextInput"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "OcclusionAvoidance",
        "OneHandUse",
        "PortableDesign",
        "SmallScreen",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2018 - ThumbText- Text Entry for Wearable Devices Using a Miniature Ring.png"
    },
    {
      "id": 154,
      "title": "Tip-tap- battery-free discrete 2D fingertip input",
      "year": "2019",
      "category": "hardware",
      "hardwareDevices": [
        "DataGloves",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "RFSensing"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased"
      ],
      "gestureTypes": [
        "SingleHand",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "Healthcare",
        "IndustryApplication",
        "MediaControl"
      ],
      "feedbackOutput": [
        "HapticFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HandsFree",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2019- Tip-tap- battery-free discrete 2D fingertip input..png"
    },
    {
      "id": 155,
      "title": "The missing interface- Micro-gestures on augmented objects",
      "year": "2019",
      "category": "gesture-design",
      "hardwareDevices": [
        "ARGlasses",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "RFSensing",
        "RadarSensing"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe"
      ],
      "applicationScenarios": [
        "AR",
        "IndustryApplication",
        "Training"
      ],
      "feedbackOutput": [
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "OcclusionAvoidance",
        "OneHandUse",
        "PortableDesign"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2019-The missing interface- Micro-gestures on augmented objects.png"
    },
    {
      "id": 156,
      "title": "QwertyRing- Text Entry on Physical Surfaces  Using a Ring",
      "year": "2020",
      "category": "hardware",
      "hardwareDevices": [
        "ARGlasses",
        "SmartRing",
        "VRHeadset",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture"
      ],
      "gestureTypes": [
        "Hold",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "SmartHome",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "OneHandUse",
        "PortableDesign",
        "QWERTYLayout",
        "TouchOptimized",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2020 - . QwertyRing- Text Entry on Physical Surfaces  Using a Ring..png"
    },
    {
      "id": 157,
      "title": "BiTipText- Bimanual Eyes-Free Text Entry on a Fingertip Keyboard ",
      "year": "2020",
      "category": "hardware",
      "hardwareDevices": [
        "SmartGlasses",
        "SmartWatch",
        "TouchScreen",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "CapacitiveSensor",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "MotionAnalysis",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DirectTouch"
      ],
      "gestureTypes": [
        "DualHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "PortableDesign",
        "QWERTYLayout",
        "TouchOptimized",
        "UserAdaptation"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2020-BiTipText- Bimanual Eyes-Free Text Entry on a Fingertip Keyboard.png"
    },
    {
      "id": 158,
      "title": "EarBuddy- Enabling On-Face Interaction via Wireless Earbuds",
      "year": "2020",
      "category": "software",
      "hardwareDevices": [
        "Smartphone",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "BioSensor",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "EarBasedInteraction"
      ],
      "gestureTypes": [
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AccessibilitySupport",
        "MediaControl",
        "SmartHome"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2020-EarBuddy- Enabling On-Face Interaction via Wireless Earbuds.png"
    },
    {
      "id": 159,
      "title": "Ready, Steady, Touch! Sensing  Physical Contact with a Finger-Mounted IMU",
      "year": "2020",
      "category": "hardware",
      "hardwareDevices": [
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "Gyroscope",
        "IMU",
        "Magnetometer"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking"
      ],
      "interactionModalities": [
        "BackOfDeviceInteraction",
        "ContactBased",
        "DeviceContactGesture",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "AR",
        "MediaControl",
        "Navigation",
        "SmartHome",
        "TextInput",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "PortableDesign",
        "SocialAcceptability",
        "TouchOptimized"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2020-Ready, Steady, Touch! Sensing  Physical Contact with a Finger-Mounted IMU.png"
    },
    {
      "id": 162,
      "title": "Design of 3D Microgestures for Commands in Virtual Reality or Augmented Reality",
      "year": "2023",
      "category": "gesture-design",
      "hardwareDevices": [
        "ARGlasses",
        "TouchScreen",
        "VRHeadset"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Grasp",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming",
        "MediaControl",
        "Navigation",
        "ObjectManipulation",
        "VR"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2023- Design of 3D Microgestures for Commands in Virtual Reality or Augmented Reality.png"
    },
    {
      "id": 164,
      "title": "Abracadabra Wireless, High-Precision, and Unpowered Finger Input for Very Small Mobile Devices",
      "year": "2009",
      "category": "hardware",
      "hardwareDevices": [
        "SmartRing",
        "SmartWatch",
        "Wearables"
      ],
      "sensingTechnology": [
        "Magnetometer",
        "MotionSensor"
      ],
      "recognitionClassification": [
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased",
        "TangibleInteraction"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Flex",
        "Hold",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation",
        "ObjectManipulation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "HandsFree",
        "HighAccuracy",
        "PortableDesign",
        "SmallScreen"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2009-Abracadabra Wireless, High-Precision, and Unpowered Finger Input for Very Small Mobile Devices.png"
    },
    {
      "id": 165,
      "title": "Digits Freehand 3D Interactions Anywhere Using a Wrist-Worn Gloveless Sensor",
      "year": "2012",
      "category": "hardware",
      "hardwareDevices": [
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "IMU",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "3DPoseEstimation",
        "ContinuousRecognition",
        "FingerTracking",
        "HandTracking"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "Flex",
        "Grasp",
        "Pinch",
        "SingleHand"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming",
        "MR",
        "ObjectManipulation",
        "VR"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "PortableDesign"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2012-Digits Freehand 3D Interactions Anywhere Using a Wrist-Worn Gloveless Sensor.png"
    },
    {
      "id": 166,
      "title": "TIMMi Finger-worn Textile Input Device with Multimodal Sensing in Mobile Interaction",
      "year": "2015",
      "category": "hardware",
      "hardwareDevices": [
        "Etextile",
        "SmartRing",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "OtherTechnology",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "DeviceContactGesture",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "Flex",
        "SingleHand",
        "Swipe",
        "Tap",
        "ThumbIndex"
      ],
      "applicationScenarios": [
        "MediaControl",
        "OtherScenarios"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "OneHandUse",
        "PortableDesign",
        "SocialAcceptability"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2015-TIMMi Finger-worn Textile Input Device with Multimodal Sensing in Mobile Interaction.png"
    },
    {
      "id": 167,
      "title": "User-Defined Game Input for Smart Glasses in Public Space",
      "year": "2015",
      "category": "gesture-design",
      "hardwareDevices": [
        "SmartGlasses"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "MotionSensor",
        "OpticalTracking"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "HandTracking"
      ],
      "interactionModalities": [
        "BodyContactGesture",
        "ContactBased",
        "InAirGesture",
        "MultiModalInteraction",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "AR",
        "Gaming"
      ],
      "feedbackOutput": [
        "AudioFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "ElicitationStudy",
        "EyesFree",
        "HandsFree",
        "SocialAcceptability"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2015-User-Defined Game Input for Smart Glasses in Public Space.png"
    },
    {
      "id": 168,
      "title": "zSense Enabling Shallow Depth Gesture Recognition for Greater Input Expressivity on Smart Wearables",
      "year": "2015",
      "category": "hardware",
      "hardwareDevices": [
        "SmartGlasses",
        "SmartRing",
        "SmartWatch",
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "DepthSensing",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "ContinuousRecognition",
        "DynamicGestureRecognition",
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "InAirGesture",
        "NonContactBased"
      ],
      "gestureTypes": [
        "DirectionalGesture",
        "Pinch",
        "SingleHand",
        "Swipe",
        "Tap"
      ],
      "applicationScenarios": [
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "RealTimeFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "EyesFree",
        "HandsFree",
        "HighAccuracy",
        "LowLatency",
        "OneHandUse",
        "PortableDesign",
        "SmallScreen"
      ],
      "image": "Papers/HARDWARE/Hardware预览图/2015-zSense Enabling Shallow Depth Gesture Recognition for Greater Input Expressivity on Smart Wearables.png"
    },
    {
      "id": 171,
      "title": "A Usability User Study Concerning Free-Hand Microgesture and Wrist-Worn Sensors",
      "year": "2014",
      "category": "software",
      "hardwareDevices": [
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "ComputerVision",
        "DepthSensing",
        "OtherTechnology"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition",
        "StaticGestureRecognition"
      ],
      "interactionModalities": [
        "NonContactBased"
      ],
      "gestureTypes": [
        "DualHand",
        "Flex",
        "Pinch",
        "SingleHand"
      ],
      "applicationScenarios": [
        "IndustryApplication",
        "MediaControl",
        "Navigation",
        "TextInput"
      ],
      "feedbackOutput": [
        "RealTimeFeedback",
        "VisualFeedback"
      ],
      "userExperienceDesign": [
        "DiscreetInput",
        "HighAccuracy",
        "OneHandUse",
        "SocialAcceptability",
        "UserAdaptation"
      ],
      "image": "Papers/SOFTWARE/Software预览图/2014-A Usability User Study Concerning Free-Hand Microgesture and Wrist-Worn Sensors.png"
    },
    {
      "id": 172,
      "title": "A Taxonomy of Microinteractions Defining Microgestures based on Ergonomic and Scenario-dependent Requirements",
      "year": "2011",
      "category": "gesture-design",
      "hardwareDevices": [
        "WearableSensor",
        "Wearables"
      ],
      "sensingTechnology": [
        "Accelerometer",
        "DepthSensing",
        "EMG",
        "PressureSensor"
      ],
      "recognitionClassification": [
        "FingerTracking",
        "GestureRecognition"
      ],
      "interactionModalities": [
        "ContactBased",
        "MultiModalInteraction"
      ],
      "gestureTypes": [
        "Grasp",
        "Pinch",
        "SingleHand",
        "Tap"
      ],
      "applicationScenarios": [
        "InVehicleInteraction",
        "MediaControl",
        "Navigation"
      ],
      "feedbackOutput": [
        "HapticFeedback",
        "MultimodalFeedback"
      ],
      "userExperienceDesign": [
        "ElicitationStudy",
        "EncumberedInteraction",
        "EyesFree",
        "OneHandUse"
      ],
      "image": "Papers/GestureDesign/GestureDesign预览图/2011-A Taxonomy of Microinteractions Defining Microgestures based on Ergonomic and Scenario-dependent Requirements.png"
    },
    {
      "id": 173,
      "title": "DigiTap- an eyes-free VR:AR symbolic input device.",
      "year": "2014",
      "category": "hardware",
      "image": "Papers/HARDWARE/Hardware预览图/2014 - DigiTap- an eyes-free VR:AR symbolic input device..png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": []
    },
    {
      "id": 174,
      "title": "LightRing- Always-Available 2D Input on Any Surface.",
      "year": "2014",
      "category": "hardware",
      "image": "Papers/HARDWARE/Hardware预览图/2014 - LightRing- Always-Available 2D Input on Any Surface..png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": []
    },
    {
      "id": 175,
      "title": "OptiRing Low-Resolution Optical Sensing for Subtle Thumb-to-Index Input",
      "year": "2023",
      "category": "hardware",
      "image": "Papers/HARDWARE/Hardware预览图/2023 -  OptiRing Low-Resolution Optical Sensing for Subtle Thumb-to-Index Input.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": []
    },
    {
      "id": 176,
      "title": "PinchWatch  A Wearable Device for One-Handed Microinteractions",
      "year": "2010",
      "category": "hardware",
      "image": "Papers/HARDWARE/Hardware预览图/2010-PinchWatch  A Wearable Device for One-Handed Microinteractions.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": []
    },
    {
      "id": 177,
      "title": "iSkin Flexible, Stretchable and Visually Customizable On-Body Touch Sensors for Mobile Computing",
      "year": "2015",
      "category": "hardware",
      "image": "Papers/HARDWARE/Hardware预览图/2015-iSkin Flexible, Stretchable and Visually Customizable On-Body Touch Sensors for Mobile Computing.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": []
    },
    {
      "id": 178,
      "title": "Pyro thumb-tip gesture recognition using pyroelectric infrared sensing",
      "year": "2017",
      "category": "hardware",
      "image": "Papers/HARDWARE/Hardware预览图/2017 - Pyro thumb-tip gesture recognition using pyroelectric infrared sensing.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": []
    },
    {
      "id": 179,
      "title": "FingerPad-  private and subtle interaction using fingertips",
      "year": "2013",
      "category": "hardware",
      "image": "Papers/HARDWARE/Hardware预览图/2013 - FingerPad-  private and subtle interaction using fingertips.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": []
    },
    {
      "id": 180,
      "title": "Skinmarks Enabling interactions on body landmarks using conformal skin electronics",
      "year": "2017",
      "category": "hardware",
      "image": "Papers/HARDWARE/Hardware预览图/2017-Skinmarks Enabling interactions on body landmarks using conformal skin electronics.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": []
    },
    {
      "id": 181,
      "title": "Press-n-paste copy-and-paste operations with pressure-sensitive caret navigation for miniaturized surface in mobile aug",
      "year": "2021",
      "category": "software",
      "image": "Papers/SOFTWARE/Software预览图/2021 - Press-n-paste copy-and-paste operations with pressure-sensitive caret navigation for miniaturized surface in mobile aug.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": []
    },
    {
      "id": 182,
      "title": "Vulture- A Mid-Air Word-Gesture Keyboard",
      "year": "2014",
      "category": "software",
      "image": "Papers/SOFTWARE/Software预览图/2014 - Vulture- A Mid-Air Word-Gesture Keyboard.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": []
    },
    {
      "id": 183,
      "title": "The intuitive grasp interface design and evaluation of micro-gestures on the steering wheel for driving scenario",
      "year": "2020",
      "category": "gesture-design",
      "image": "Papers/GestureDesign/GestureDesign预览图/2020 - The intuitive grasp interface design and evaluation of micro-gestures on the steering wheel for driving scenario.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": []
    },
    {
      "id": 184,
      "title": "Transferable Microgestures Across Hand Posture and Location Constraints- Leveraging the Middle, Ring, and Pinky Fingers",
      "year": "2023",
      "category": "gesture-design",
      "image": "Papers/GestureDesign/GestureDesign预览图/2023 - Transferable Microgestures Across Hand Posture and Location Constraints- Leveraging the Middle, Ring, and Pinky Fingers.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": []
    },
    {
      "id": 185,
      "title": "Segtouch",
      "year": "2017",
      "category": "gesture-design",
      "image": "Papers/GestureDesign/GestureDesign预览图/2017-Segtouch.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": []
    },
    {
      "id": 186,
      "title": "Arpège learning multitouch chord gestures vocabularies",
      "year": "2013",
      "category": "gesture-design",
      "image": "Papers/GestureDesign/GestureDesign预览图/2013 - Arpège learning multitouch chord gestures vocabularies.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": []
    },
    {
      "id": 187,
      "title": "PalmType Using Palms as Keyboards for Smart Glasses",
      "year": "2015",
      "category": "gesture-design",
      "image": "Papers/GestureDesign/GestureDesign预览图/2015-PalmType Using Palms as Keyboards for Smart Glasses.png",
      "hardwareDevices": [],
      "sensingTechnology": [],
      "recognitionClassification": [],
      "interactionModalities": [],
      "gestureTypes": [],
      "applicationScenarios": [],
      "feedbackOutput": [],
      "userExperienceDesign": []
    }
  ],
  "categories": {
    "hardware": [
      {
        "id": 1,
        "title": "Towards keyboard independent touch typing in VR",
        "year": "2005",
        "category": "hardware",
        "hardwareDevices": [
          "DataGloves",
          "Keyboard",
          "VRHeadset",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Pinch",
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "DigitalArt",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "OneHandUse",
          "TouchOptimized"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2005 - Towards keyboard independent touch typing in VR.png"
      },
      {
        "id": 2,
        "title": "Demonstrating the feasibility of using forearm electromyography for muscle-computer interfaces",
        "year": "2008",
        "category": "hardware",
        "hardwareDevices": [
          "WearableSensor"
        ],
        "sensingTechnology": [
          "BioSensor",
          "EMG"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "Hold",
          "Pinch",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "InVehicleInteraction",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HandsFree",
          "HighAccuracy",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2008 - Demonstrating the feasibility of using forearm electromyography for muscle-computer interfaces.png"
      },
      {
        "id": 3,
        "title": "Hand gesture recognition and virtual game control based on 3D accelerometer and EMG sensors",
        "year": "2009",
        "category": "hardware",
        "hardwareDevices": [
          "WearableSensor"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "BioSensor",
          "EMG",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand"
        ],
        "applicationScenarios": [
          "Gaming",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "LowLatency",
          "PortableDesign"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2009 - Hand gesture recognition and virtual game control based on 3D accelerometer and EMG sensors.png"
      },
      {
        "id": 4,
        "title": "A prototype of gesture-based interface",
        "year": "2011",
        "category": "hardware",
        "hardwareDevices": [
          "Smartphone",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "BioSensor",
          "EMG"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Flex",
          "SingleHand"
        ],
        "applicationScenarios": [
          "InVehicleInteraction",
          "MediaControl"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2011 - A prototype of gesture-based interface.png"
      },
      {
        "id": 6,
        "title": "Augmenting the input space of portable displays using add-on hall-sensor grid",
        "year": "2013",
        "category": "hardware",
        "hardwareDevices": [
          "Smartphone",
          "Tablet",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Magnetometer",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "DirectTouch",
          "NonContactBased",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Pinch",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "Gaming",
          "MediaControl",
          "Navigation",
          "TextInput"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "OcclusionAvoidance",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2013 - Augmenting the input space of portable displays using add-on hall-sensor grid.png"
      },
      {
        "id": 7,
        "title": "EarPut augmenting ear-worn devices for ear-based interaction",
        "year": "2014",
        "category": "hardware",
        "hardwareDevices": [
          "OtherDevices",
          "Smartphone",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "DirectTouch",
          "EarBasedInteraction",
          "InAirGesture"
        ],
        "gestureTypes": [
          "MultiTouch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "Gaming",
          "MediaControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "HapticFeedback",
          "ProprioceptiveFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2014 - EarPut augmenting ear-worn devices for ear-based interaction.png"
      },
      {
        "id": 8,
        "title": "Advancing muscle-computer interfaces with high-density electromyography",
        "year": "2015",
        "category": "hardware",
        "hardwareDevices": [
          "WearableSensor"
        ],
        "sensingTechnology": [
          "BioSensor",
          "EMG"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "NonContactBased"
        ],
        "gestureTypes": [
          "Flex",
          "Pinch",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "IoTControl",
          "MediaControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HandsFree",
          "HighAccuracy",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2015 - Advancing muscle-computer interfaces with high-density electromyography.png"
      },
      {
        "id": 9,
        "title": "eRing multiple finger gesture recognition with one ring using an electric field",
        "year": "2015",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "IoTControl",
          "OtherScenarios",
          "SmartHome"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "OcclusionAvoidance",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2015 - eRing multiple finger gesture recognition with one ring using an electric field.png"
      },
      {
        "id": 12,
        "title": "Microgesture detection for remote interaction with mobile devices",
        "year": "2016",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "Smartphone",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "DeviceContactGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "InVehicleInteraction",
          "IoTControl",
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EncumberedInteraction",
          "EyesFree",
          "HandsFree",
          "MidasTouchProblem",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2016 - Microgesture detection for remote interaction with mobile devices.png"
      },
      {
        "id": 15,
        "title": "DeformWear deformation input on tiny wearable devices",
        "year": "2017",
        "category": "hardware",
        "hardwareDevices": [
          "ARGlasses",
          "HapticDevice",
          "SmartGlasses",
          "SmartRing",
          "SmartWatch",
          "VRHeadset",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "OpticalTracking",
          "OtherTechnology",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "MultiModalInteraction",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "Hold",
          "Pinch",
          "SingleHand",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming",
          "MediaControl",
          "Navigation",
          "ObjectManipulation",
          "SmartHome",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "ProprioceptiveFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SmallScreen",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2017 - DeformWear deformation input on tiny wearable devices.png"
      },
      {
        "id": 17,
        "title": "GestAKey touch interaction on individual keycaps",
        "year": "2018",
        "category": "hardware",
        "hardwareDevices": [
          "Keyboard",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "MultiTouch",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "TextInput"
        ],
        "feedbackOutput": [
          "HapticFeedback"
        ],
        "userExperienceDesign": [
          "LowLatency",
          "QWERTYLayout",
          "TouchOptimized",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2018 - GestAKey touch interaction on individual keycaps.png"
      },
      {
        "id": 19,
        "title": "Thumb-in-motion evaluating thumb-to-ring microgestures for athletic activity",
        "year": "2018",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "SmartWatch",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "Healthcare",
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EncumberedInteraction",
          "LowLatency",
          "OneHandUse",
          "PortableDesign"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2018 - Thumb-in-motion evaluating thumb-to-ring microgestures for athletic activity.png"
      },
      {
        "id": 22,
        "title": "AudioTouch minimally invasive sensing of micro-gestures via active bio-acoustic sensing",
        "year": "2019",
        "category": "hardware",
        "hardwareDevices": [
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "BioSensor",
          "PressureSensor",
          "UltrasonicSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "Hold",
          "Pinch",
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "SmartHome",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2019 - AudioTouch minimally invasive sensing of micro-gestures via active bio-acoustic sensing.png"
      },
      {
        "id": 24,
        "title": "E-textile microinteractions augmenting twist with flick, slide and grasp gestures for soft electronics",
        "year": "2020",
        "category": "hardware",
        "hardwareDevices": [
          "Etextile",
          "OtherDevices",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "OtherTechnology",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Grasp",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "Gaming",
          "MediaControl",
          "OtherScenarios",
          "SmartHome"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "PortableDesign",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2020 - E-textile microinteractions augmenting twist with flick, slide and grasp gestures for soft electronics.png"
      },
      {
        "id": 26,
        "title": "Fabriccio touchless gestural input on interactive fabrics",
        "year": "2020",
        "category": "hardware",
        "hardwareDevices": [
          "Etextile",
          "OtherDevices",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "RFSensing",
          "RadarSensing"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "IoTControl",
          "MediaControl",
          "OtherScenarios",
          "SmartHome"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "PortableDesign"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2020 - Fabriccio touchless gestural input on interactive fabrics.png"
      },
      {
        "id": 29,
        "title": "Nailz sensing hand input with touch sensitive nails",
        "year": "2020",
        "category": "hardware",
        "hardwareDevices": [
          "SmartGlasses",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "IMU"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "MultiTouch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "OneHandUse",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2020 - Nailz sensing hand input with touch sensitive nails.png"
      },
      {
        "id": 30,
        "title": "ThermalRing gesture and tag inputs enabled by a thermal imaging smart ring",
        "year": "2020",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "InAirGesture",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "IoTControl",
          "MediaControl",
          "Navigation",
          "SmartHome"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HighAccuracy",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2020 - ThermalRing gesture and tag inputs enabled by a thermal imaging smart ring.png"
      },
      {
        "id": 32,
        "title": "ElectroRing subtle pinch and touch detection with a ring",
        "year": "2021",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "Pinch",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "DigitalArt",
          "MR",
          "MediaControl",
          "ObjectManipulation",
          "VR"
        ],
        "feedbackOutput": [
          "ProprioceptiveFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "PortableDesign"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2021 - ElectroRing subtle pinch and touch detection with a ring.png"
      },
      {
        "id": 34,
        "title": "ThumbTrak recognizing micro-finger poses using a ring with proximity sensing",
        "year": "2021",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "DeviceContactGesture",
          "DirectTouch"
        ],
        "gestureTypes": [
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming",
          "MediaControl",
          "Navigation",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2021 - ThumbTrak recognizing micro-finger poses using a ring with proximity sensing.png"
      },
      {
        "id": 36,
        "title": "DualRing Enabling Subtle and Expressive Hand Interaction with Dual IMU Rings",
        "year": "2021",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "Magnetometer",
          "RFSensing"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "MotionAnalysis",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Grasp",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "IoTControl",
          "MediaControl",
          "ObjectManipulation",
          "SmartHome",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2021-DualRing Enabling Subtle and Expressive Hand Interaction with Dual IMU Rings.png"
      },
      {
        "id": 37,
        "title": "MicroPress detecting pressure and hover distance in thumb-to-finger interactions",
        "year": "2022",
        "category": "hardware",
        "hardwareDevices": [
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "DepthSensing",
          "Gyroscope",
          "IMU",
          "Magnetometer",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "DirectTouch",
          "NonContactBased"
        ],
        "gestureTypes": [
          "Hold",
          "Pinch",
          "SingleHand",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming",
          "MediaControl",
          "Navigation",
          "VR"
        ],
        "feedbackOutput": [
          "ProprioceptiveFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2022 - MicroPress detecting pressure and hover distance in thumb-to-finger interactions.png"
      },
      {
        "id": 39,
        "title": "DRG-Keyboard Enabling Subtle Gesture Typing on the Fingertip with Dual IMU Rings",
        "year": "2023",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "Magnetometer"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "TrajectoryAnalysis"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "SmartHome",
          "TextInput"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "PortableDesign",
          "QWERTYLayout",
          "SmallScreen"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2023-DRG-Keyboard Enabling Subtle Gesture Typing on the Fingertip with Dual IMU Rings.png"
      },
      {
        "id": 40,
        "title": "EFRing Enabling Thumb-to-Index-Finger Microgesture Interaction through Electric Field Sensing Using Single Smart Ring",
        "year": "2023",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "DigitalArt",
          "IoTControl",
          "MediaControl",
          "SmartHome",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2023-EFRing Enabling Thumb-to-Index-Finger Microgesture Interaction through Electric Field Sensing Using Single Smart Ring.png"
      },
      {
        "id": 41,
        "title": "SparseIMU Computational Design of Sparse IMU Layouts for Sensing Fine-grained Finger Microgestures",
        "year": "2023",
        "category": "hardware",
        "hardwareDevices": [
          "DataGloves",
          "SmartRing",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "Magnetometer",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "NonContactBased",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Flex",
          "Grasp",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "Gaming",
          "InVehicleInteraction",
          "IoTControl",
          "SmartHome",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EncumberedInteraction",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "PortableDesign"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2023-SparseIMU Computational Design of Sparse IMU Layouts for Sensing Fine-grained Finger Microgestures.png"
      },
      {
        "id": 42,
        "title": "VibAware Context-Aware Tap and Swipe Gestures Using Bio-Acoustic Sensing",
        "year": "2023",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "SmartWatch",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "BioSensor",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction",
          "NonContactBased",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Grasp",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "IoTControl",
          "MediaControl",
          "SmartHome",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EncumberedInteraction",
          "EyesFree",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2023-VibAware Context-Aware Tap and Swipe Gestures Using Bio-Acoustic Sensing.png"
      },
      {
        "id": 43,
        "title": "MAF exploring mobile acoustic field for hand-to-face gesture interactions",
        "year": "2024",
        "category": "hardware",
        "hardwareDevices": [
          "OtherDevices",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "OtherTechnology",
          "UltrasonicSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "HandToFaceGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Hold",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming",
          "Healthcare",
          "MediaControl",
          "SmartHome",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2024 - MAF exploring mobile acoustic field for hand-to-face gesture interactions.png"
      },
      {
        "id": 44,
        "title": "RadarHand a wrist-worn radar for on-skin touch-based proprioceptive gestures",
        "year": "2024",
        "category": "hardware",
        "hardwareDevices": [
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "RFSensing",
          "RadarSensing"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "Gaming",
          "InVehicleInteraction",
          "MediaControl",
          "Navigation",
          "SmartHome"
        ],
        "feedbackOutput": [
          "ProprioceptiveFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SmallScreen",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2024 - RadarHand a wrist-worn radar for on-skin touch-based proprioceptive gestures.png"
      },
      {
        "id": 45,
        "title": "Ring-a-pose a ring for continuous hand pose tracking",
        "year": "2024",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "OtherTechnology",
          "UltrasonicSensor"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "AccessibilitySupport",
          "Gaming",
          "MediaControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2024 - Ring-a-pose a ring for continuous hand pose tracking.png"
      },
      {
        "id": 47,
        "title": "HCMG Human-Capacitance based Micro Gesture for VR AR",
        "year": "2024",
        "category": "hardware",
        "hardwareDevices": [
          "ARGlasses",
          "VRHeadset",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "BioSensor",
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture"
        ],
        "gestureTypes": [
          "Grasp",
          "Pinch",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "AccessibilitySupport",
          "Education",
          "Gaming",
          "Training",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2024-HCMG Human-Capacitance based Micro Gesture for VR AR.png"
      },
      {
        "id": 48,
        "title": "BudsID mobile-ready and expressive finger identification input for earbuds",
        "year": "2025",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "IMU",
          "Magnetometer"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "DirectTouch",
          "EarBasedInteraction"
        ],
        "gestureTypes": [
          "MultiTouch",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "InVehicleInteraction",
          "MediaControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2025 - BudsID mobile-ready and expressive finger identification input for earbuds.png"
      },
      {
        "id": 51,
        "title": "DCSNN An Efficient and High-speed sEMG-based Transient-state Micro-gesture Recognition Method on Wearable Devices",
        "year": "2025",
        "category": "hardware",
        "hardwareDevices": [
          "OtherDevices",
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "BioSensor",
          "EMG",
          "IMU"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming",
          "IoTControl",
          "MediaControl",
          "Navigation",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "PortableDesign",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2025-DCSNN An Efficient and High-speed sEMG-based Transient-state Micro-gesture Recognition Method on Wearable Devices.png"
      },
      {
        "id": 52,
        "title": "VibRing A Wearable Vibroacoustic Sensor for Single-Handed Gesture Recognition",
        "year": "2025",
        "category": "hardware",
        "hardwareDevices": [
          "OtherDevices",
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming",
          "IoTControl",
          "MediaControl",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "LowLatency",
          "PortableDesign",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2025-VibRing A Wearable Vibroacoustic Sensor for Single-Handed Gesture Recognition.png"
      },
      {
        "id": 58,
        "title": "AtaTouch robust finger pinch detection for a VR controller using RF return loss",
        "year": "2021",
        "category": "hardware",
        "hardwareDevices": [
          "VRHeadset",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "RFSensing"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture"
        ],
        "gestureTypes": [
          "Grasp",
          "Pinch",
          "SingleHand",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "Gaming",
          "ObjectManipulation",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "LowLatency",
          "OcclusionAvoidance",
          "OneHandUse"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2021 - AtaTouch robust finger pinch detection for a VR controller using RF return loss.png"
      },
      {
        "id": 64,
        "title": "Stick-To-XR Understanding Stick-Based User Interface Design for Extended Reality",
        "year": "2024",
        "category": "hardware",
        "hardwareDevices": [
          "HapticDevice",
          "OtherDevices",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OpticalTracking",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DualHand",
          "Grasp",
          "Hold",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AR",
          "Education",
          "Gaming",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "MultimodalFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "OneHandUse",
          "PortableDesign",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2024-Stick-To-XR Understanding Stick-Based User Interface Design for Extended Reality.png"
      },
      {
        "id": 79,
        "title": "Interacting with soli exploring fine-grained dynamic gesture recognition in the radio-frequency spectrum",
        "year": "2016",
        "category": "hardware",
        "hardwareDevices": [
          "OtherDevices",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "RFSensing",
          "RadarSensing"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "ObjectManipulation",
          "SmartHome"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "OcclusionAvoidance",
          "PortableDesign"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2016 - Interacting with soli exploring fine-grained dynamic gesture recognition in the radio-frequency spectrum.png"
      },
      {
        "id": 85,
        "title": "InfiniTouch finger-aware interaction on fully touch sensitive smartphones",
        "year": "2018",
        "category": "hardware",
        "hardwareDevices": [
          "Smartphone",
          "TouchScreen",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "Flex",
          "Pinch",
          "SingleHand",
          "Swipe",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "MediaControl",
          "ObjectManipulation",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "FatFingerProblem",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2018 - InfiniTouch finger-aware interaction on fully touch sensitive smartphones.png"
      },
      {
        "id": 102,
        "title": "ARO Exploring the Design of Smart-Ring Interactions for Encumbered Hands",
        "year": "2021",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "CapacitiveSensor",
          "Gyroscope",
          "IMU"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "InAirGesture"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Grasp",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "ElicitationStudy",
          "EncumberedInteraction",
          "HandsFree",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2021-ARO Exploring the Design of Smart-Ring Interactions for Encumbered Hands.png"
      },
      {
        "id": 110,
        "title": "BikeGesture user elicitation and performance of micro hand gesture as input for cycling",
        "year": "2017",
        "category": "hardware",
        "hardwareDevices": [
          "DataGloves",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "BioSensor",
          "IMU",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "Flex",
          "Grasp",
          "Pinch",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "AthleticActivity",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2017 - BikeGesture user elicitation and performance of micro hand gesture as input for cycling.png"
      },
      {
        "id": 115,
        "title": "AnyButton unpowered, modeless and highly available mobile input using unmodified clothing buttons",
        "year": "2014",
        "category": "hardware",
        "hardwareDevices": [
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "GestureRecognition",
          "HandTracking",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "HapticFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HandsFree",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2014 - AnyButton unpowered, modeless and highly available mobile input using unmodified clothing buttons.png"
      },
      {
        "id": 129,
        "title": "Keep the phone in your pocket enabling smartphone operation with an IMU ring for visually impaired people",
        "year": "2020",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "Smartphone",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport"
        ],
        "feedbackOutput": [
          "AudioFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2020 - Keep the phone in your pocket enabling smartphone operation with an IMU ring for visually impaired people.png"
      },
      {
        "id": 140,
        "title": "WristFlex- low-power gesture input with wrist-worn pressure sensors",
        "year": "2014",
        "category": "hardware",
        "hardwareDevices": [
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "Pinch",
          "SingleHand",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AthleticActivity",
          "IoTControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2014 - WristFlex- low-power gesture input with wrist-worn pressure sensors.png"
      },
      {
        "id": 141,
        "title": "CyclopsRing- Enabling Whole-Hand and  Context-Aware Interactions Through a Fisheye Ring",
        "year": "2015",
        "category": "hardware",
        "hardwareDevices": [
          "OtherDevices",
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming",
          "IoTControl",
          "SmartHome",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HandsFree",
          "OneHandUse",
          "PortableDesign",
          "QWERTYLayout"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2015 - CyclopsRing- Enabling Whole-Hand and  Context-Aware Interactions Through a Fisheye Ring.png"
      },
      {
        "id": 144,
        "title": "ThumbRing- private interactions using one-handed thumb motion input on  finger segments",
        "year": "2016",
        "category": "hardware",
        "hardwareDevices": [
          "ARGlasses",
          "SmartGlasses",
          "SmartRing",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "Magnetometer",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "GestureRecognition",
          "MotionAnalysis",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2016 - ThumbRing- private interactions using one-handed thumb motion input on  finger segments.png"
      },
      {
        "id": 146,
        "title": "Soli- Ubiquitous Gesture Sensing with Millimeter Wave Radar",
        "year": "2016",
        "category": "hardware",
        "hardwareDevices": [
          "OtherDevices",
          "SmartWatch",
          "VRHeadset",
          "Wearables"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "RFSensing",
          "RadarSensing"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "Gaming",
          "IoTControl",
          "MediaControl",
          "Navigation",
          "SmartHome",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "OcclusionAvoidance",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2016-Soli- Ubiquitous Gesture Sensing with Millimeter Wave Radar..png"
      },
      {
        "id": 147,
        "title": "TouchRing- Subtle and  Always-Available Input Using a Multi-Touch Ring",
        "year": "2016",
        "category": "hardware",
        "hardwareDevices": [
          "SmartGlasses",
          "SmartRing",
          "TouchScreen",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "MultiTouch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability",
          "TouchOptimized"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2016-TouchRing- Subtle and  Always-Available Input Using a Multi-Touch Ring.png"
      },
      {
        "id": 148,
        "title": "DigiTouch- Reconfigurable Thumb-to-Finger Input and Text Entry on Head-mounted Displays",
        "year": "2017",
        "category": "hardware",
        "hardwareDevices": [
          "ARGlasses",
          "DataGloves",
          "VRHeadset",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture"
        ],
        "gestureTypes": [
          "Hold",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "ProprioceptiveFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "OcclusionAvoidance",
          "PortableDesign",
          "QWERTYLayout",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2017 - DigiTouch- Reconfigurable Thumb-to-Finger Input and Text Entry on Head-mounted Displays.png"
      },
      {
        "id": 149,
        "title": "FingerSound- Recognizing unistroke thumb gestures using a ring",
        "year": "2017",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Gyroscope",
          "MotionSensor",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl",
          "SmartHome",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "HapticFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "MidasTouchProblem",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2017 - FingerSound- Recognizing unistroke thumb gestures using a ring..png"
      },
      {
        "id": 153,
        "title": "ThumbText- Text Entry for Wearable Devices Using a Miniature Ring",
        "year": "2018",
        "category": "hardware",
        "hardwareDevices": [
          "SmartGlasses",
          "SmartRing",
          "SmartWatch",
          "TouchScreen",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Hold",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "TextInput"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "OcclusionAvoidance",
          "OneHandUse",
          "PortableDesign",
          "SmallScreen",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2018 - ThumbText- Text Entry for Wearable Devices Using a Miniature Ring.png"
      },
      {
        "id": 154,
        "title": "Tip-tap- battery-free discrete 2D fingertip input",
        "year": "2019",
        "category": "hardware",
        "hardwareDevices": [
          "DataGloves",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "RFSensing"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "Healthcare",
          "IndustryApplication",
          "MediaControl"
        ],
        "feedbackOutput": [
          "HapticFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HandsFree",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2019- Tip-tap- battery-free discrete 2D fingertip input..png"
      },
      {
        "id": 156,
        "title": "QwertyRing- Text Entry on Physical Surfaces  Using a Ring",
        "year": "2020",
        "category": "hardware",
        "hardwareDevices": [
          "ARGlasses",
          "SmartRing",
          "VRHeadset",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture"
        ],
        "gestureTypes": [
          "Hold",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "SmartHome",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "OneHandUse",
          "PortableDesign",
          "QWERTYLayout",
          "TouchOptimized",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2020 - . QwertyRing- Text Entry on Physical Surfaces  Using a Ring..png"
      },
      {
        "id": 157,
        "title": "BiTipText- Bimanual Eyes-Free Text Entry on a Fingertip Keyboard ",
        "year": "2020",
        "category": "hardware",
        "hardwareDevices": [
          "SmartGlasses",
          "SmartWatch",
          "TouchScreen",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "DualHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "PortableDesign",
          "QWERTYLayout",
          "TouchOptimized",
          "UserAdaptation"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2020-BiTipText- Bimanual Eyes-Free Text Entry on a Fingertip Keyboard.png"
      },
      {
        "id": 159,
        "title": "Ready, Steady, Touch! Sensing  Physical Contact with a Finger-Mounted IMU",
        "year": "2020",
        "category": "hardware",
        "hardwareDevices": [
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "Magnetometer"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "ContactBased",
          "DeviceContactGesture",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl",
          "Navigation",
          "SmartHome",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "PortableDesign",
          "SocialAcceptability",
          "TouchOptimized"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2020-Ready, Steady, Touch! Sensing  Physical Contact with a Finger-Mounted IMU.png"
      },
      {
        "id": 164,
        "title": "Abracadabra Wireless, High-Precision, and Unpowered Finger Input for Very Small Mobile Devices",
        "year": "2009",
        "category": "hardware",
        "hardwareDevices": [
          "SmartRing",
          "SmartWatch",
          "Wearables"
        ],
        "sensingTechnology": [
          "Magnetometer",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Flex",
          "Hold",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "PortableDesign",
          "SmallScreen"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2009-Abracadabra Wireless, High-Precision, and Unpowered Finger Input for Very Small Mobile Devices.png"
      },
      {
        "id": 165,
        "title": "Digits Freehand 3D Interactions Anywhere Using a Wrist-Worn Gloveless Sensor",
        "year": "2012",
        "category": "hardware",
        "hardwareDevices": [
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "IMU",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "ContinuousRecognition",
          "FingerTracking",
          "HandTracking"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "Flex",
          "Grasp",
          "Pinch",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming",
          "MR",
          "ObjectManipulation",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "PortableDesign"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2012-Digits Freehand 3D Interactions Anywhere Using a Wrist-Worn Gloveless Sensor.png"
      },
      {
        "id": 166,
        "title": "TIMMi Finger-worn Textile Input Device with Multimodal Sensing in Mobile Interaction",
        "year": "2015",
        "category": "hardware",
        "hardwareDevices": [
          "Etextile",
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "OtherTechnology",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "Flex",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2015-TIMMi Finger-worn Textile Input Device with Multimodal Sensing in Mobile Interaction.png"
      },
      {
        "id": 168,
        "title": "zSense Enabling Shallow Depth Gesture Recognition for Greater Input Expressivity on Smart Wearables",
        "year": "2015",
        "category": "hardware",
        "hardwareDevices": [
          "SmartGlasses",
          "SmartRing",
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "DepthSensing",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "PortableDesign",
          "SmallScreen"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2015-zSense Enabling Shallow Depth Gesture Recognition for Greater Input Expressivity on Smart Wearables.png"
      },
      {
        "id": 173,
        "title": "DigiTap- an eyes-free VR:AR symbolic input device.",
        "year": "2014",
        "category": "hardware",
        "image": "Papers/HARDWARE/Hardware预览图/2014 - DigiTap- an eyes-free VR:AR symbolic input device..png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 174,
        "title": "LightRing- Always-Available 2D Input on Any Surface.",
        "year": "2014",
        "category": "hardware",
        "image": "Papers/HARDWARE/Hardware预览图/2014 - LightRing- Always-Available 2D Input on Any Surface..png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 175,
        "title": "OptiRing Low-Resolution Optical Sensing for Subtle Thumb-to-Index Input",
        "year": "2023",
        "category": "hardware",
        "image": "Papers/HARDWARE/Hardware预览图/2023 -  OptiRing Low-Resolution Optical Sensing for Subtle Thumb-to-Index Input.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 176,
        "title": "PinchWatch  A Wearable Device for One-Handed Microinteractions",
        "year": "2010",
        "category": "hardware",
        "image": "Papers/HARDWARE/Hardware预览图/2010-PinchWatch  A Wearable Device for One-Handed Microinteractions.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 177,
        "title": "iSkin Flexible, Stretchable and Visually Customizable On-Body Touch Sensors for Mobile Computing",
        "year": "2015",
        "category": "hardware",
        "image": "Papers/HARDWARE/Hardware预览图/2015-iSkin Flexible, Stretchable and Visually Customizable On-Body Touch Sensors for Mobile Computing.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 178,
        "title": "Pyro thumb-tip gesture recognition using pyroelectric infrared sensing",
        "year": "2017",
        "category": "hardware",
        "image": "Papers/HARDWARE/Hardware预览图/2017 - Pyro thumb-tip gesture recognition using pyroelectric infrared sensing.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 179,
        "title": "FingerPad-  private and subtle interaction using fingertips",
        "year": "2013",
        "category": "hardware",
        "image": "Papers/HARDWARE/Hardware预览图/2013 - FingerPad-  private and subtle interaction using fingertips.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 180,
        "title": "Skinmarks Enabling interactions on body landmarks using conformal skin electronics",
        "year": "2017",
        "category": "hardware",
        "image": "Papers/HARDWARE/Hardware预览图/2017-Skinmarks Enabling interactions on body landmarks using conformal skin electronics.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      }
    ],
    "software": [
      {
        "id": 10,
        "title": "Finger-writing with smartwatch a case for finger and hand gesture recognition using smartwatch",
        "year": "2015",
        "category": "software",
        "hardwareDevices": [
          "SmartWatch",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "MotionAnalysis",
          "StaticGestureRecognition",
          "TrajectoryAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "IoTControl",
          "MediaControl",
          "SmartHome",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HandsFree",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2015 - Finger-writing with smartwatch a case for finger and hand gesture recognition using smartwatch.png"
      },
      {
        "id": 20,
        "title": "Touch+finger extending touch-based user interface capabilities with idle finger gestures in the air",
        "year": "2018",
        "category": "software",
        "hardwareDevices": [
          "SmartRing",
          "Tablet",
          "TouchScreen",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "Magnetometer"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Hold",
          "MultiTouch",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "DigitalArt",
          "Gaming",
          "MediaControl",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "SmallScreen",
          "TouchOptimized"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2018 - Touch+finger extending touch-based user interface capabilities with idle finger gestures in the air.png"
      },
      {
        "id": 21,
        "title": "FingerInput Capturing Expressive Single-Hand Thumb-to-Finger Microgestures",
        "year": "2018",
        "category": "software",
        "hardwareDevices": [
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "ComputerVision",
          "DepthSensing"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Flex",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "DigitalArt",
          "MediaControl"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "OneHandUse"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2018-FingerInput Capturing Expressive Single-Hand Thumb-to-Finger Microgestures.png"
      },
      {
        "id": 23,
        "title": "TipText eyes-free text entry on a fingertip keyboard",
        "year": "2019",
        "category": "software",
        "hardwareDevices": [
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "ComputerVision",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "QWERTYLayout",
          "SmallScreen",
          "SocialAcceptability"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2019 - TipText eyes-free text entry on a fingertip keyboard.png"
      },
      {
        "id": 27,
        "title": "Finger gesture tracking for interactive applications a pilot study with sign languages",
        "year": "2020",
        "category": "software",
        "hardwareDevices": [
          "SmartRing",
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "Magnetometer",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "MotionAnalysis",
          "TrajectoryAnalysis"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "SignLanguageRelated",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "Education",
          "Healthcare",
          "Training"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "MultimodalFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "CommunicationAid",
          "EncumberedInteraction",
          "LowLatency",
          "PortableDesign",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Finger gesture tracking for interactive applications a pilot study with sign languages.png"
      },
      {
        "id": 46,
        "title": "Studying the simultaneous visual representation of microgestures",
        "year": "2024",
        "category": "software",
        "hardwareDevices": [
          "SmartWatch",
          "Smartphone",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "Hold",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HandsFree",
          "OneHandUse",
          "SmallScreen",
          "SocialAcceptability"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2024 - Studying the simultaneous visual representation of microgestures.png"
      },
      {
        "id": 49,
        "title": "Gesture and audio-haptic guidance techniques to direct conversations with intelligent voice interfaces",
        "year": "2025",
        "category": "software",
        "hardwareDevices": [
          "HapticDevice",
          "SmartGlasses",
          "SmartRing",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "IMU",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction",
          "VoiceGestureCombined"
        ],
        "gestureTypes": [
          "Hold",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "HapticFeedback",
          "MultimodalFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "LowLatency",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2025 - Gesture and audio-haptic guidance techniques to direct conversations with intelligent voice interfaces.png"
      },
      {
        "id": 50,
        "title": "LeakyFeeder In-air gesture control through leaky acoustic waves",
        "year": "2025",
        "category": "software",
        "hardwareDevices": [
          "OtherDevices",
          "Wearables"
        ],
        "sensingTechnology": [
          "OtherTechnology",
          "UltrasonicSensor"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "EarBasedInteraction",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "Hold",
          "Pinch",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl",
          "OtherScenarios",
          "SmartHome",
          "VR"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "PortableDesign"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2025 - LeakyFeeder In-air gesture control through leaky acoustic waves.png"
      },
      {
        "id": 54,
        "title": "Depth aware finger tapping on virtual displays",
        "year": "2018",
        "category": "software",
        "hardwareDevices": [
          "ARGlasses",
          "Smartphone",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "DepthSensing",
          "UltrasonicSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "MultimodalFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "LowLatency"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2018 - Depth aware finger tapping on virtual displays.png"
      },
      {
        "id": 60,
        "title": "GraV grasp volume data for the design of one-handed XR interfaces",
        "year": "2024",
        "category": "software",
        "hardwareDevices": [
          "ARGlasses",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "ComputerVision"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Grasp",
          "SingleHand",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "ObjectManipulation",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "OneHandUse",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2024 - GraV grasp volume data for the design of one-handed XR interfaces.png"
      },
      {
        "id": 61,
        "title": "HapticPilot authoring in-situ hand posture-adaptive vibrotactile feedback for virtual reality",
        "year": "2024",
        "category": "software",
        "hardwareDevices": [
          "DataGloves",
          "HapticDevice",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand"
        ],
        "applicationScenarios": [
          "DigitalArt",
          "Gaming",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "LowLatency",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2024 - HapticPilot authoring in-situ hand posture-adaptive vibrotactile feedback for virtual reality.png"
      },
      {
        "id": 62,
        "title": "TriPad touch input in AR on ordinary surfaces with hand tracking only",
        "year": "2024",
        "category": "software",
        "hardwareDevices": [
          "ARGlasses",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "DepthSensing",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "InAirGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "MultiTouch",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "Navigation",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HandsFree",
          "LowLatency",
          "SocialAcceptability",
          "TouchOptimized"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2024 - TriPad touch input in AR on ordinary surfaces with hand tracking only.png"
      },
      {
        "id": 63,
        "title": "GraspUI Seamlessly Integrating Object-Centric Gestures within the Seven Phases of Grasping",
        "year": "2024",
        "category": "software",
        "hardwareDevices": [
          "ARGlasses",
          "SmartGlasses",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "InAirGesture",
          "MultiModalInteraction",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Grasp",
          "Hold",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl",
          "ObjectManipulation",
          "SmartHome"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2024-GraspUI Seamlessly Integrating Object-Centric Gestures within the Seven Phases of Grasping.png"
      },
      {
        "id": 65,
        "title": "STMG A Machine Learning Microgesture Recognition System for Supporting Thumb-Based VR AR Input",
        "year": "2024",
        "category": "software",
        "hardwareDevices": [
          "ARGlasses",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl",
          "Navigation",
          "ObjectManipulation",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2024-STMG A Machine Learning Microgesture Recognition System for Supporting Thumb-Based VR AR Input.png"
      },
      {
        "id": 75,
        "title": "Tactile feedback for above-device gesture interfaces adding touch to touchless interactions",
        "year": "2014",
        "category": "software",
        "hardwareDevices": [
          "HapticDevice",
          "SmartRing",
          "SmartWatch",
          "Smartphone",
          "Wearables"
        ],
        "sensingTechnology": [
          "OpticalTracking",
          "UltrasonicSensor"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "SingleHand"
        ],
        "applicationScenarios": [
          "MediaControl"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "MultimodalFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "SmallScreen",
          "TouchOptimized"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2014 - Tactile feedback for above-device gesture interfaces adding touch to touchless interactions.png"
      },
      {
        "id": 78,
        "title": " Finger-aware shortcuts",
        "year": "2016",
        "category": "software",
        "hardwareDevices": [
          "Keyboard"
        ],
        "sensingTechnology": [
          "ComputerVision"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "DeviceContactGesture"
        ],
        "gestureTypes": [
          "DualHand",
          "Hold",
          "SingleHand"
        ],
        "applicationScenarios": [
          "TextInput"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "QWERTYLayout",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2016 - Finger-aware shortcuts.png"
      },
      {
        "id": 81,
        "title": "WiFinger talk to your smart devices with finger-grained gesture",
        "year": "2016",
        "category": "software",
        "hardwareDevices": [
          "OtherDevices",
          "Smartphone"
        ],
        "sensingTechnology": [
          "RFSensing"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "SignLanguageRelated",
          "SingleHand"
        ],
        "applicationScenarios": [
          "SmartHome",
          "TextInput"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HandsFree",
          "HighAccuracy"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2016 - WiFinger talk to your smart devices with finger-grained gesture.png"
      },
      {
        "id": 96,
        "title": "TouchPose hand pose prediction, depth estimation, and touch classification from capacitive images",
        "year": "2021",
        "category": "software",
        "hardwareDevices": [
          "Smartphone",
          "Tablet",
          "TouchScreen",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "ComputerVision",
          "DepthSensing",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Grasp",
          "MultiTouch",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AR",
          "DigitalArt",
          "ObjectManipulation",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "LowLatency",
          "OcclusionAvoidance",
          "TouchOptimized",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2021 - TouchPose hand pose prediction, depth estimation, and touch classification from capacitive images.png"
      },
      {
        "id": 97,
        "title": "Watching your phone's back gesture recognition by sensing acoustical structure-borne propagation",
        "year": "2021",
        "category": "software",
        "hardwareDevices": [
          "OtherDevices",
          "Smartphone",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OtherTechnology",
          "UltrasonicSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "DeviceContactGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "IoTControl",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "MultimodalFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "LowLatency",
          "OcclusionAvoidance",
          "PortableDesign",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2021 - Watching your phone's back gesture recognition by sensing acoustical structure-borne propagation.png"
      },
      {
        "id": 99,
        "title": "Leveraging the properties of mmWave signals for 3D finger motion tracking for interactive IoT applications",
        "year": "2022",
        "category": "software",
        "hardwareDevices": [
          "OtherDevices",
          "Smartphone",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "RFSensing",
          "RadarSensing"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "ContinuousRecognition",
          "FingerTracking",
          "HandTracking"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "Flex",
          "SignLanguageRelated",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AR",
          "AccessibilitySupport",
          "Healthcare",
          "IoTControl",
          "SmartHome",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2022 - Leveraging the properties of mmWave signals for 3D finger motion tracking for interactive IoT applications.png"
      },
      {
        "id": 100,
        "title": "IndexPen Two Finger Text Input with Millimeter Wave Radar",
        "year": "2022",
        "category": "software",
        "hardwareDevices": [
          "OtherDevices",
          "Smartphone",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "RFSensing",
          "RadarSensing"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "AccessibilitySupport",
          "IoTControl",
          "SmartHome",
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2022-IndexPen Two Finger Text Input with Millimeter Wave Radar.png"
      },
      {
        "id": 104,
        "title": "iFAD Gestures Understanding Users’ Gesture Input Performance with Index-Finger Augmentation Devices",
        "year": "2023",
        "category": "software",
        "hardwareDevices": [
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "DeviceContactGesture",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "SmartHome",
          "TextInput"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HandsFree",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2023-iFAD Gestures Understanding Users’ Gesture Input Performance with Index-Finger Augmentation Devices.png"
      },
      {
        "id": 105,
        "title": "Persistent assistant seamless everyday AI interactions via intent grounding and multimodal feedback",
        "year": "2025",
        "category": "software",
        "hardwareDevices": [
          "ARGlasses",
          "HapticDevice",
          "SmartGlasses",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "GazeBased",
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased",
          "VoiceGestureCombined"
        ],
        "gestureTypes": [
          "Pinch",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AR",
          "Navigation",
          "SmartHome"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "HapticFeedback",
          "MultimodalFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "OneHandUse",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2025 - Persistent assistant seamless everyday AI interactions via intent grounding and multimodal feedback.png"
      },
      {
        "id": 106,
        "title": "Grasp Interaction with Tablets",
        "year": "2011",
        "category": "software",
        "hardwareDevices": [
          "Tablet",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "CapacitiveSensor",
          "Gyroscope",
          "IMU",
          "Magnetometer"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DualHand",
          "Grasp",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "FatFingerProblem",
          "MidasTouchProblem",
          "OcclusionAvoidance",
          "OneHandUse",
          "SmallScreen",
          "TouchOptimized"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2011-Grasp Interaction with Tablets.png"
      },
      {
        "id": 107,
        "title": "Opportunistic synergy a classifier fusion engine for micro-gesture recognition",
        "year": "2013",
        "category": "software",
        "hardwareDevices": [
          "DrivingSimulator",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "BioSensor",
          "EMG",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "MultiModalInteraction",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Grasp",
          "Hold",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "InVehicleInteraction"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2013 - Opportunistic synergy a classifier fusion engine for micro-gesture recognition.png"
      },
      {
        "id": 125,
        "title": "Blind people and mobile touch-based text-entry acknowledging the need for different flavors",
        "year": "2011",
        "category": "software",
        "hardwareDevices": [
          "Smartphone",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "PressureSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "MultiTouch",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "TextInput"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "MultimodalFeedback"
        ],
        "userExperienceDesign": [
          "FatFingerProblem",
          "QWERTYLayout",
          "TouchOptimized",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2011 - Blind people and mobile touch-based text-entry acknowledging the need for different flavors.png"
      },
      {
        "id": 128,
        "title": "Static fingerspelling recognition based on boundary tracing algorithm and chain code",
        "year": "2018",
        "category": "software",
        "hardwareDevices": [
          "OtherDevices"
        ],
        "sensingTechnology": [
          "ComputerVision"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "NonContactBased"
        ],
        "gestureTypes": [
          "SignLanguageRelated",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AccessibilitySupport"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2018 - Static fingerspelling recognition based on boundary tracing algorithm and chain code.png"
      },
      {
        "id": 130,
        "title": "Performance evaluation of pattern recognition networks using electromyography signal and time-domain features for the classification of hand gestures",
        "year": "2020",
        "category": "software",
        "hardwareDevices": [
          "WearableSensor"
        ],
        "sensingTechnology": [
          "BioSensor",
          "EMG"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased"
        ],
        "gestureTypes": [
          "Flex",
          "Grasp",
          "SingleHand",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "Healthcare"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "CommunicationAid",
          "HighAccuracy"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2020 - Performance evaluation of pattern recognition networks using electromyography signal and time-domain features for the cl.png"
      },
      {
        "id": 131,
        "title": "Keep in touch combining touch interaction with thumb-to-finger µGestures for people with visual impairment",
        "year": "2022",
        "category": "software",
        "hardwareDevices": [
          "Tablet",
          "TouchScreen",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "Education",
          "Navigation"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "MultimodalFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "CommunicationAid",
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "OneHandUse",
          "TouchOptimized"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2022 - Keep in touch combining touch interaction with thumb-to-finger µGestures for people with visual impairment.png"
      },
      {
        "id": 132,
        "title": "µGeT multimodal eyes-free text selection technique combining touch interaction and microgestures",
        "year": "2023",
        "category": "software",
        "hardwareDevices": [
          "Tablet",
          "TouchScreen",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "ComputerVision"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "Hold",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "TextInput"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "OneHandUse",
          "TouchOptimized"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2023 - µGeT multimodal eyes-free text selection technique combining touch interaction and microgestures.png"
      },
      {
        "id": 142,
        "title": "Combining Ring Input with Hand  Tracking for Precise, Natural Interaction with Spatial Analytic Interfaces",
        "year": "2016",
        "category": "software",
        "hardwareDevices": [
          "ARGlasses",
          "SmartRing",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "ComputerVision",
          "DepthSensing",
          "IMU",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "ContinuousRecognition",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Grasp",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "Navigation",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "PortableDesign"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2016 - Combining Ring Input with Hand  Tracking for Precise, Natural Interaction with Spatial Analytic Interfaces..png"
      },
      {
        "id": 145,
        "title": "Interacting with Soli- Exploring Fine-Grained Dynamic  Gesture Recognition in the Radio-Frequency Spectrum",
        "year": "2016",
        "category": "software",
        "hardwareDevices": [
          "OtherDevices",
          "Wearables"
        ],
        "sensingTechnology": [
          "RFSensing",
          "RadarSensing"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "IoTControl",
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "OcclusionAvoidance"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2016-Interacting with Soli- Exploring Fine-Grained Dynamic  Gesture Recognition in the Radio-Frequency Spectrum.png"
      },
      {
        "id": 158,
        "title": "EarBuddy- Enabling On-Face Interaction via Wireless Earbuds",
        "year": "2020",
        "category": "software",
        "hardwareDevices": [
          "Smartphone",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "BioSensor",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "EarBasedInteraction"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "MediaControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2020-EarBuddy- Enabling On-Face Interaction via Wireless Earbuds.png"
      },
      {
        "id": 171,
        "title": "A Usability User Study Concerning Free-Hand Microgesture and Wrist-Worn Sensors",
        "year": "2014",
        "category": "software",
        "hardwareDevices": [
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "DepthSensing",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "NonContactBased"
        ],
        "gestureTypes": [
          "DualHand",
          "Flex",
          "Pinch",
          "SingleHand"
        ],
        "applicationScenarios": [
          "IndustryApplication",
          "MediaControl",
          "Navigation",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "OneHandUse",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/SOFTWARE/Software预览图/2014-A Usability User Study Concerning Free-Hand Microgesture and Wrist-Worn Sensors.png"
      },
      {
        "id": 181,
        "title": "Press-n-paste copy-and-paste operations with pressure-sensitive caret navigation for miniaturized surface in mobile aug",
        "year": "2021",
        "category": "software",
        "image": "Papers/SOFTWARE/Software预览图/2021 - Press-n-paste copy-and-paste operations with pressure-sensitive caret navigation for miniaturized surface in mobile aug.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 182,
        "title": "Vulture- A Mid-Air Word-Gesture Keyboard",
        "year": "2014",
        "category": "software",
        "image": "Papers/SOFTWARE/Software预览图/2014 - Vulture- A Mid-Air Word-Gesture Keyboard.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      }
    ],
    "gesture-design": [
      {
        "id": 5,
        "title": "Design space for finger gestures with hand-held tablets",
        "year": "2012",
        "category": "gesture-design",
        "hardwareDevices": [
          "Tablet",
          "TouchScreen",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "CapacitiveSensor",
          "Gyroscope",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "DualHand",
          "Grasp",
          "MultiTouch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "MultimodalFeedback",
          "ProprioceptiveFeedback"
        ],
        "userExperienceDesign": [
          "FatFingerProblem",
          "OcclusionAvoidance",
          "SocialAcceptability",
          "TouchOptimized",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2012 - Design space for finger gestures with hand-held tablets.png"
      },
      {
        "id": 11,
        "title": "Gunslinger subtle arms-down mid-air interaction",
        "year": "2015",
        "category": "gesture-design",
        "hardwareDevices": [
          "TouchScreen",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "DepthSensing",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "Hold",
          "Pinch",
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HandsFree",
          "LowLatency",
          "MidasTouchProblem",
          "OcclusionAvoidance",
          "OneHandUse",
          "TouchOptimized"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2015 - Gunslinger subtle arms-down mid-air interaction.png"
      },
      {
        "id": 13,
        "title": "Designing a willing-to-use-in-public hand gestural interaction technique for smart glasses",
        "year": "2016",
        "category": "gesture-design",
        "hardwareDevices": [
          "DataGloves",
          "HapticDevice",
          "SmartGlasses",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "IMU",
          "MotionSensor",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Flex",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "Navigation",
          "ObjectManipulation",
          "TextInput"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "MultimodalFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HandsFree",
          "OcclusionAvoidance",
          "PortableDesign",
          "SocialAcceptability",
          "TouchOptimized"
        ],
        "image": "Papers/HARDWARE/Hardware预览图/2016 - Designing a willing-to-use-in-public hand gestural interaction technique for smart glasses.png"
      },
      {
        "id": 18,
        "title": "Gestures for smart rings empirical results, insights, and design implications",
        "year": "2018",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartRing",
          "Wearables"
        ],
        "sensingTechnology": [
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "IoTControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "HapticFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Gestures for smart rings empirical results, insights, and design implications.png"
      },
      {
        "id": 25,
        "title": "Exploring user defined gestures for ear-based interactions",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "SmartGlasses",
          "Wearables"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OtherTechnology",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "EarBasedInteraction",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "MediaControl",
          "Navigation",
          "OtherScenarios",
          "SmartHome"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "HapticFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "OneHandUse",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Exploring user defined gestures for ear-based interactions.png"
      },
      {
        "id": 28,
        "title": "How subtle can it get A trimodal study of ring-sized interfaces for one-handed drone control",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "SmartRing",
          "Smartphone",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "IMU",
          "MotionSensor",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Flex",
          "Hold",
          "SingleHand",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - How subtle can it get A trimodal study of ring-sized interfaces for one-handed drone control.png"
      },
      {
        "id": 33,
        "title": "SoloFinger robust microgestures while grasping everyday objects",
        "year": "2021",
        "category": "gesture-design",
        "hardwareDevices": [
          "DataGloves",
          "OtherDevices"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "DeviceContactGesture",
          "DirectTouch"
        ],
        "gestureTypes": [
          "Flex",
          "Grasp",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "ObjectManipulation",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "EncumberedInteraction",
          "HighAccuracy"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2021 - SoloFinger robust microgestures while grasping everyday objects.png"
      },
      {
        "id": 53,
        "title": "Exploring mixed-scale gesture interaction",
        "year": "2017",
        "category": "gesture-design",
        "hardwareDevices": [
          "ARGlasses",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "OpticalTracking",
          "RadarSensing"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "Grasp",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AR",
          "MediaControl",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Exploring mixed-scale gesture interaction.png"
      },
      {
        "id": 55,
        "title": "Experimental analysis of barehand mid-air mode-switching techniques in virtual reality",
        "year": "2019",
        "category": "gesture-design",
        "hardwareDevices": [
          "VRHeadset",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "OpticalTracking",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "Grasp",
          "Pinch",
          "SingleHand"
        ],
        "applicationScenarios": [
          "ObjectManipulation",
          "VR"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2019 - Experimental analysis of barehand mid-air mode-switching techniques in virtual reality.png"
      },
      {
        "id": 56,
        "title": "Characterizing in-air eyes-free typing movements in VR",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "MotionAnalysis",
          "TrajectoryAnalysis"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DualHand",
          "Flex",
          "Tap"
        ],
        "applicationScenarios": [
          "TextInput",
          "VR"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "QWERTYLayout"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Characterizing in-air eyes-free typing movements in VR.png"
      },
      {
        "id": 57,
        "title": "User gesture elicitation of common smartphone tasks for hand proximate user interfaces",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "ARGlasses",
          "SmartGlasses",
          "Smartphone"
        ],
        "sensingTechnology": [
          "ComputerVision"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "DirectTouch",
          "InAirGesture"
        ],
        "gestureTypes": [
          "Flex",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "MR",
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "OneHandUse",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020-User gesture elicitation of common smartphone tasks for hand proximate user interfaces.png"
      },
      {
        "id": 66,
        "title": "Understanding Gesture and Microgesture Inputs for Augmented Reality Maps",
        "year": "2024",
        "category": "gesture-design",
        "hardwareDevices": [
          "ARGlasses",
          "SmartGlasses",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "CapacitiveSensor",
          "ComputerVision",
          "IMU",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "Navigation"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "ProprioceptiveFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "OneHandUse",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2024-Understanding Gesture and Microgesture Inputs for Augmented Reality Maps.png"
      },
      {
        "id": 67,
        "title": "T2IRay Design of Thumb-to-Index based Indirect Pointing for Continuous and Robust AR VR Input",
        "year": "2025",
        "category": "gesture-design",
        "hardwareDevices": [
          "ARGlasses",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "ObjectManipulation",
          "VR"
        ],
        "feedbackOutput": [
          "ProprioceptiveFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "OneHandUse",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2025-T2IRay Design of Thumb-to-Index based Indirect Pointing for Continuous and Robust AR VR Input.png"
      },
      {
        "id": 68,
        "title": "Key-press gestures recognition and interaction based on SEMG signals",
        "year": "2010",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "BioSensor",
          "EMG"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "Flex",
          "Hold",
          "SingleHand"
        ],
        "applicationScenarios": [
          "MediaControl",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EncumberedInteraction",
          "EyesFree",
          "HandsFree",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2010 - Key-press gestures recognition and interaction based on SEMG signals.png"
      },
      {
        "id": 69,
        "title": "A study of on-device gestures",
        "year": "2012",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone"
        ],
        "sensingTechnology": [
          "PressureSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "ContactBased",
          "DeviceContactGesture"
        ],
        "gestureTypes": [
          "Grasp",
          "SingleHand",
          "Swipe"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "ProprioceptiveFeedback"
        ],
        "userExperienceDesign": [
          "EncumberedInteraction",
          "OcclusionAvoidance",
          "OneHandUse"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2012 - A study of on-device gestures.png"
      },
      {
        "id": 70,
        "title": "PinchPad performance of touch-based gestures while grasping devices",
        "year": "2012",
        "category": "gesture-design",
        "hardwareDevices": [
          "Tablet"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "ContactBased",
          "DeviceContactGesture",
          "DirectTouch"
        ],
        "gestureTypes": [
          "Grasp",
          "Pinch",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "ProprioceptiveFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "OcclusionAvoidance",
          "OneHandUse"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2012 - PinchPad performance of touch-based gestures while grasping devices.png"
      },
      {
        "id": 71,
        "title": "The fat thumb using the thumb's contact size for single-handed mobile interaction",
        "year": "2012",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "SingleHand",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "FatFingerProblem",
          "OneHandUse",
          "SmallScreen",
          "TouchOptimized"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2012 - The fat thumb using the thumb's contact size for single-handed mobile interaction.png"
      },
      {
        "id": 72,
        "title": "Exploring pinch and spread gestures on mobile devices",
        "year": "2013",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone",
          "Tablet"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "DirectTouch",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DualHand",
          "MultiTouch",
          "Pinch",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "SmallScreen",
          "TouchOptimized"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2013 - Exploring pinch and spread gestures on mobile devices.png"
      },
      {
        "id": 74,
        "title": "Leap gestures for TV insights from an elicitation study",
        "year": "2014",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "Flex",
          "Hold",
          "SingleHand"
        ],
        "applicationScenarios": [
          "MediaControl"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "HandsFree",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2014 - Leap gestures for TV insights from an elicitation study.png"
      },
      {
        "id": 76,
        "title": "Interaction proxemics combining physical spaces for seamless gesture interaction",
        "year": "2015",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "DepthSensing",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "DirectTouch",
          "InAirGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "Navigation",
          "ObjectManipulation",
          "TextInput"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2015 - Interaction proxemics combining physical spaces for seamless gesture interaction.png"
      },
      {
        "id": 77,
        "title": "Exploring non-touchscreen gestures for smartwatches",
        "year": "2016",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartWatch",
          "Wearables"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "DeviceContactGesture",
          "InAirGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "ElicitationStudy",
          "FatFingerProblem",
          "OcclusionAvoidance",
          "SmallScreen",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2016 - Exploring non-touchscreen gestures for smartwatches.png"
      },
      {
        "id": 80,
        "title": "Investigating how the hand interacts with different mobile phones",
        "year": "2016",
        "category": "gesture-design",
        "hardwareDevices": [
          "Keyboard",
          "Smartphone",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "ComputerVision"
        ],
        "recognitionClassification": [
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "DirectTouch"
        ],
        "gestureTypes": [
          "DualHand",
          "Grasp",
          "Hold",
          "SingleHand"
        ],
        "applicationScenarios": [
          "MediaControl",
          "TextInput"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "OneHandUse",
          "TouchOptimized"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2016 - Investigating how the hand interacts with different mobile phones.png"
      },
      {
        "id": 82,
        "title": "Understanding grip shifts how form factors impact hand movements on mobile phones",
        "year": "2017",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "DualHand",
          "Hold",
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "Navigation",
          "TextInput"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "OneHandUse",
          "PortableDesign",
          "SmallScreen",
          "TouchOptimized"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Understanding grip shifts how form factors impact hand movements on mobile phones.png"
      },
      {
        "id": 83,
        "title": "Characterizing finger pitch and roll orientation during atomic touch actions",
        "year": "2018",
        "category": "gesture-design",
        "hardwareDevices": [
          "Tablet",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "Magnetometer"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "DualHand",
          "Hold",
          "MultiTouch",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "TouchOptimized"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Characterizing finger pitch and roll orientation during atomic touch actions.png"
      },
      {
        "id": 84,
        "title": "Fingers' range and comfortable area for one-handed smartphone interaction beyond the touchscreen",
        "year": "2018",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "FatFingerProblem",
          "OcclusionAvoidance",
          "OneHandUse",
          "PortableDesign",
          "TouchOptimized"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Fingers' range and comfortable area for one-handed smartphone interaction beyond the touchscreen.png"
      },
      {
        "id": 86,
        "title": "Pen + mid-air gestures eliciting contextual gestures",
        "year": "2018",
        "category": "gesture-design",
        "hardwareDevices": [
          "Tablet",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased",
          "PenInput"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "Grasp",
          "Pinch",
          "Swipe"
        ],
        "applicationScenarios": [
          "DigitalArt",
          "Education",
          "MediaControl",
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EncumberedInteraction",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Pen + mid-air gestures eliciting contextual gestures.png"
      },
      {
        "id": 87,
        "title": "Unimanual Pen Touch Input Using Variations of Precision Grip Postures",
        "year": "2018",
        "category": "gesture-design",
        "hardwareDevices": [
          "Tablet",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction",
          "PenInput"
        ],
        "gestureTypes": [
          "Grasp",
          "MultiTouch",
          "SingleHand"
        ],
        "applicationScenarios": [
          "DigitalArt",
          "Education",
          "ObjectManipulation",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "HighAccuracy",
          "OneHandUse",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2018-Unimanual Pen Touch Input Using Variations of Precision Grip Postures.png"
      },
      {
        "id": 88,
        "title": "Gaze-assisted typing for smart glasses",
        "year": "2019",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartGlasses",
          "VRHeadset",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "GazeBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "TextInput"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EyesFree",
          "LowLatency",
          "MidasTouchProblem",
          "OneHandUse",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2019 - Gaze-assisted typing for smart glasses.png"
      },
      {
        "id": 89,
        "title": "Investigating unintended inputs for one-handed touch interaction beyond the touchscreen",
        "year": "2019",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "MotionAnalysis",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "ContactBased",
          "DeviceContactGesture"
        ],
        "gestureTypes": [
          "Grasp",
          "SingleHand"
        ],
        "applicationScenarios": [
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EncumberedInteraction",
          "FatFingerProblem",
          "OcclusionAvoidance",
          "OneHandUse",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2019 - Investigating unintended inputs for one-handed touch interaction beyond the touchscreen.png"
      },
      {
        "id": 90,
        "title": "Expanding Side Touch Input on Mobile Phones",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "MediaControl",
          "Navigation",
          "TextInput"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "FatFingerProblem",
          "HighAccuracy",
          "OcclusionAvoidance",
          "OneHandUse",
          "PortableDesign"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Expanding side touch input on mobile phones finger reachability and two-dimensional taps and flicks using the index and.png"
      },
      {
        "id": 91,
        "title": "MagTouch robust finger identification for a smartwatch using a magnet ring and a built-in magnetometer",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartRing",
          "SmartWatch",
          "Wearables"
        ],
        "sensingTechnology": [
          "IMU",
          "Magnetometer",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "LowLatency",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - MagTouch robust finger identification for a smartwatch using a magnet ring and a built-in magnetometer.png"
      },
      {
        "id": 92,
        "title": "PenSight enhanced interaction with a pen-top camera",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "Tablet"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "DepthSensing",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction",
          "NonContactBased",
          "PenInput",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "DualHand",
          "Grasp"
        ],
        "applicationScenarios": [
          "DigitalArt",
          "Education",
          "Navigation",
          "ObjectManipulation",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EncumberedInteraction",
          "HighAccuracy",
          "LowLatency",
          "OcclusionAvoidance",
          "PortableDesign"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - PenSight enhanced interaction with a pen-top camera.png"
      },
      {
        "id": 93,
        "title": "Shortcut gestures for mobile text editing on fully touch sensitive smartphones",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone",
          "TouchScreen",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "BackOfDeviceInteraction",
          "ContactBased",
          "DeviceContactGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Hold",
          "MultiTouch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "OtherScenarios",
          "TextInput"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "FatFingerProblem",
          "HighAccuracy",
          "OcclusionAvoidance",
          "OneHandUse",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Shortcut gestures for mobile text editing on fully touch sensitive smartphones.png"
      },
      {
        "id": 94,
        "title": "Eliciting tangible and gestural user interactions with and on a cooking pan",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "TangibleInteraction"
        ],
        "gestureTypes": [
          "Grasp",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "OtherScenarios",
          "SmartHome"
        ],
        "feedbackOutput": [
          "MultimodalFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EncumberedInteraction"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Eliciting tangible and gestural user interactions with and on a cooking pan.png"
      },
      {
        "id": 95,
        "title": "3D hand pose estimation on conventional capacitive touchscreens",
        "year": "2021",
        "category": "gesture-design",
        "hardwareDevices": [
          "Tablet",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DualHand",
          "Grasp",
          "MultiTouch",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AR",
          "DigitalArt",
          "Gaming",
          "ObjectManipulation",
          "Training",
          "VR"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "FatFingerProblem",
          "HighAccuracy",
          "LowLatency",
          "OcclusionAvoidance",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2021 - 3D hand pose estimation on conventional capacitive touchscreens.png"
      },
      {
        "id": 98,
        "title": "A User-based Mid-air Hand Gesture Set for Spreadsheets",
        "year": "2021",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "Pinch",
          "SingleHand",
          "Swipe"
        ],
        "applicationScenarios": [
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2021-A User-based Mid-air Hand Gesture Set for Spreadsheets.png"
      },
      {
        "id": 101,
        "title": "SoloFinger Robust Microgestures while Grasping Everyday Objects",
        "year": "2021",
        "category": "gesture-design",
        "hardwareDevices": [
          "DataGloves",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Flex",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "ObjectManipulation",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "HighAccuracy",
          "LowLatency",
          "OneHandUse"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2021 - SoloFinger robust microgestures while grasping everyday objects.png"
      },
      {
        "id": 103,
        "title": "Enabling voice-accompanying hand-to-face gesture recognition with cross-device sensing",
        "year": "2023",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartRing",
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "Gyroscope",
          "IMU",
          "UltrasonicSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "EarBasedInteraction",
          "MultiModalInteraction",
          "VoiceGestureCombined"
        ],
        "gestureTypes": [
          "SingleHand"
        ],
        "applicationScenarios": [
          "AR",
          "IoTControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "HandsFree",
          "LowLatency",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2023 - Enabling voice-accompanying hand-to-face gesture recognition with cross-device sensing.png"
      },
      {
        "id": 109,
        "title": "The performance and preference of different fingers and chords for pointing, dragging, and object transformation",
        "year": "2016",
        "category": "gesture-design",
        "hardwareDevices": [
          "Tablet",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "Hold",
          "MultiTouch",
          "Pinch",
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "ObjectManipulation"
        ],
        "feedbackOutput": [
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "LowLatency",
          "TouchOptimized",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2016 - The performance and preference of different fingers and chords for pointing, dragging, and object transformation.png"
      },
      {
        "id": 112,
        "title": "M[eye]cro eye-gaze+microgestures for multitasking and interruptions",
        "year": "2021",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "OpticalTracking",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "GazeBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "Pinch",
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "InVehicleInteraction",
          "ObjectManipulation",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "MultimodalFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "HighAccuracy",
          "LowLatency",
          "MidasTouchProblem",
          "OneHandUse"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2021 - M[eye]cro eye-gaze+microgestures for multitasking and interruptions.png"
      },
      {
        "id": 116,
        "title": "Towards the establishment of a framework for intuitive multi-touch interaction design",
        "year": "2012",
        "category": "gesture-design",
        "hardwareDevices": [
          "Smartphone",
          "Tablet",
          "TouchScreen"
        ],
        "sensingTechnology": [
          "CapacitiveSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "HandTracking",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DirectTouch",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "MultiTouch",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "Navigation",
          "ObjectManipulation",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "HapticFeedback",
          "MultimodalFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "FatFingerProblem",
          "HighAccuracy",
          "OcclusionAvoidance",
          "TouchOptimized",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2012 - Towards the establishment of a framework for intuitive multi-touch interaction design.png"
      },
      {
        "id": 117,
        "title": "Grasping microgestures eliciting single-hand microgestures for handheld objects",
        "year": "2019",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "Smartphone"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "Magnetometer",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "DeviceContactGesture",
          "DirectTouch"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Grasp",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "IoTControl",
          "ObjectManipulation",
          "OtherScenarios",
          "SmartHome"
        ],
        "feedbackOutput": [
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "ElicitationStudy",
          "EncumberedInteraction",
          "OneHandUse"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2019 - Grasping microgestures eliciting single-hand microgestures for handheld objects.png"
      },
      {
        "id": 118,
        "title": "Rhythmic micro-gestures discreet interaction on-the-go",
        "year": "2017",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices"
        ],
        "sensingTechnology": [
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Flex",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "Navigation",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "MultimodalFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "EyesFree",
          "MidasTouchProblem",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Rhythmic micro-gestures discreet interaction on-the-go.png"
      },
      {
        "id": 119,
        "title": "Studying the visual representation of microgestures",
        "year": "2023",
        "category": "gesture-design",
        "hardwareDevices": [
          "ARGlasses",
          "OtherDevices"
        ],
        "sensingTechnology": [
          "Magnetometer",
          "OtherTechnology"
        ],
        "recognitionClassification": [],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "Flex",
          "Hold",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AR",
          "Education"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "ElicitationStudy",
          "OneHandUse"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2023 - Studying the visual representation of microgestures.png"
      },
      {
        "id": 120,
        "title": "µGlyph a microgesture notation",
        "year": "2023",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices"
        ],
        "sensingTechnology": [
          "OtherTechnology"
        ],
        "recognitionClassification": [],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "NonContactBased"
        ],
        "gestureTypes": [
          "Flex",
          "Hold",
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "Education"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "OneHandUse"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2023 - µGlyph a microgesture notation.png"
      },
      {
        "id": 121,
        "title": "User elicitation on single-hand microgestures",
        "year": "2016",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "ObjectManipulation",
          "TextInput"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EyesFree",
          "OneHandUse",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2016 - User elicitation on single-hand microgestures.png"
      },
      {
        "id": 122,
        "title": "Would you do that understanding social acceptance of gestural interfaces",
        "year": "2010",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices",
          "Smartphone"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "MediaControl",
          "OtherScenarios",
          "SmartHome"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2010 - Would you do that understanding social acceptance of gestural interfaces.png"
      },
      {
        "id": 123,
        "title": "Hands as a controller user preferences for hand specific on-skin gestures",
        "year": "2017",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "ComputerVision",
          "IMU",
          "RadarSensing",
          "UltrasonicSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "DualHand",
          "Pinch",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "InVehicleInteraction",
          "IoTControl",
          "MediaControl",
          "SmartHome"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Hands as a controller user preferences for hand specific on-skin gestures.png"
      },
      {
        "id": 124,
        "title": "Designing More Private and Socially Acceptable Hand-to-Face Gestures for Heads-Up Computing",
        "year": "2024",
        "category": "gesture-design",
        "hardwareDevices": [
          "ARGlasses",
          "SmartGlasses",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "OtherScenarios",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "ProprioceptiveFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2024-Designing More Private and Socially Acceptable Hand-to-Face Gestures for Heads-Up Computing.png"
      },
      {
        "id": 126,
        "title": "Interaction gestures for a wearable device defined by visually impaired children",
        "year": "2016",
        "category": "gesture-design",
        "hardwareDevices": [
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "Hold",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "Healthcare",
          "Training"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "MultimodalFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EyesFree",
          "OneHandUse",
          "PortableDesign",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2016 - Interaction gestures for a wearable device defined by visually impaired children.png"
      },
      {
        "id": 127,
        "title": "Investigating microinteractions for people with visual impairments and the potential role of on-body interaction",
        "year": "2017",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartWatch",
          "Smartphone",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "IMU",
          "MotionSensor",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "MotionAnalysis"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "MediaControl",
          "Navigation",
          "OtherScenarios"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "OneHandUse",
          "PortableDesign",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2017 - Investigating microinteractions for people with visual impairments and the potential role of on-body interaction.png"
      },
      {
        "id": 133,
        "title": "Designing upper-body gesture interaction with and for people with spinal muscular atrophy in VR",
        "year": "2024",
        "category": "gesture-design",
        "hardwareDevices": [
          "VRHeadset",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "ComputerVision"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "GazeBased",
          "InAirGesture",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Pinch",
          "SingleHand",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "VR"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback"
        ],
        "userExperienceDesign": [
          "EyesFree",
          "HandsFree",
          "OneHandUse",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2024 - Designing upper-body gesture interaction with and for people with spinal muscular atrophy in VR.png"
      },
      {
        "id": 134,
        "title": "Finger gesture tracking for interactive applications a pilot study with sign languages",
        "year": "2020",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartRing",
          "SmartWatch",
          "WearableSensor"
        ],
        "sensingTechnology": [
          "IMU",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "ContinuousRecognition",
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "DualHand",
          "SignLanguageRelated",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "Education"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HighAccuracy",
          "LowLatency",
          "PortableDesign",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - Finger gesture tracking for interactive applications a pilot study with sign languages.png"
      },
      {
        "id": 135,
        "title": "A non-linear model of shape  and motion for tracking finger spelt American sign language",
        "year": "2002",
        "category": "gesture-design",
        "hardwareDevices": [
          "OtherDevices"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "GestureRecognition",
          "HandTracking",
          "MotionAnalysis",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "SignLanguageRelated",
          "SingleHand"
        ],
        "applicationScenarios": [
          "AccessibilitySupport",
          "Education"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2002-A non-linear model of shape  and motion for tracking finger spelt American sign language.png"
      },
      {
        "id": 143,
        "title": "DigitSpace Designing Thumb-to-Fingers Touch Interfaces for One-Handed and Eyes-Free Interactions",
        "year": "2016",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartWatch",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "OpticalTracking",
          "OtherTechnology"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "MediaControl",
          "TextInput"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EyesFree",
          "HighAccuracy",
          "OneHandUse",
          "PortableDesign",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2016 - DigitSpace Designing Thumb-to-Fingers Touch Interfaces for One-Handed and Eyes-Free Interactions.png"
      },
      {
        "id": 152,
        "title": "Fingert9- Leveraging  thumb-to-finger interaction for same-side-hand text entry on smartwatches",
        "year": "2018",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartWatch",
          "TouchScreen",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "CapacitiveSensor",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "DirectTouch"
        ],
        "gestureTypes": [
          "Hold",
          "SingleHand",
          "Tap",
          "ThumbIndex"
        ],
        "applicationScenarios": [
          "TextInput"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "RealTimeFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EyesFree",
          "OcclusionAvoidance",
          "OneHandUse",
          "SmallScreen",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2018 - Fingert9- Leveraging  thumb-to-finger interaction for same-side-hand text entry on smartwatches.png"
      },
      {
        "id": 155,
        "title": "The missing interface- Micro-gestures on augmented objects",
        "year": "2019",
        "category": "gesture-design",
        "hardwareDevices": [
          "ARGlasses",
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "RFSensing",
          "RadarSensing"
        ],
        "recognitionClassification": [
          "DynamicGestureRecognition",
          "FingerTracking",
          "GestureRecognition",
          "StaticGestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "DeviceContactGesture",
          "InAirGesture",
          "NonContactBased"
        ],
        "gestureTypes": [
          "SingleHand",
          "Swipe"
        ],
        "applicationScenarios": [
          "AR",
          "IndustryApplication",
          "Training"
        ],
        "feedbackOutput": [
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "OcclusionAvoidance",
          "OneHandUse",
          "PortableDesign"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2019-The missing interface- Micro-gestures on augmented objects.png"
      },
      {
        "id": 162,
        "title": "Design of 3D Microgestures for Commands in Virtual Reality or Augmented Reality",
        "year": "2023",
        "category": "gesture-design",
        "hardwareDevices": [
          "ARGlasses",
          "TouchScreen",
          "VRHeadset"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "MotionSensor"
        ],
        "recognitionClassification": [
          "3DPoseEstimation",
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "Grasp",
          "Pinch",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming",
          "MediaControl",
          "Navigation",
          "ObjectManipulation",
          "VR"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "HandsFree",
          "HighAccuracy",
          "LowLatency",
          "SocialAcceptability",
          "UserAdaptation"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2023- Design of 3D Microgestures for Commands in Virtual Reality or Augmented Reality.png"
      },
      {
        "id": 167,
        "title": "User-Defined Game Input for Smart Glasses in Public Space",
        "year": "2015",
        "category": "gesture-design",
        "hardwareDevices": [
          "SmartGlasses"
        ],
        "sensingTechnology": [
          "ComputerVision",
          "MotionSensor",
          "OpticalTracking"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition",
          "HandTracking"
        ],
        "interactionModalities": [
          "BodyContactGesture",
          "ContactBased",
          "InAirGesture",
          "MultiModalInteraction",
          "NonContactBased"
        ],
        "gestureTypes": [
          "DirectionalGesture",
          "SingleHand",
          "Swipe",
          "Tap"
        ],
        "applicationScenarios": [
          "AR",
          "Gaming"
        ],
        "feedbackOutput": [
          "AudioFeedback",
          "VisualFeedback"
        ],
        "userExperienceDesign": [
          "DiscreetInput",
          "ElicitationStudy",
          "EyesFree",
          "HandsFree",
          "SocialAcceptability"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2015-User-Defined Game Input for Smart Glasses in Public Space.png"
      },
      {
        "id": 172,
        "title": "A Taxonomy of Microinteractions Defining Microgestures based on Ergonomic and Scenario-dependent Requirements",
        "year": "2011",
        "category": "gesture-design",
        "hardwareDevices": [
          "WearableSensor",
          "Wearables"
        ],
        "sensingTechnology": [
          "Accelerometer",
          "DepthSensing",
          "EMG",
          "PressureSensor"
        ],
        "recognitionClassification": [
          "FingerTracking",
          "GestureRecognition"
        ],
        "interactionModalities": [
          "ContactBased",
          "MultiModalInteraction"
        ],
        "gestureTypes": [
          "Grasp",
          "Pinch",
          "SingleHand",
          "Tap"
        ],
        "applicationScenarios": [
          "InVehicleInteraction",
          "MediaControl",
          "Navigation"
        ],
        "feedbackOutput": [
          "HapticFeedback",
          "MultimodalFeedback"
        ],
        "userExperienceDesign": [
          "ElicitationStudy",
          "EncumberedInteraction",
          "EyesFree",
          "OneHandUse"
        ],
        "image": "Papers/GestureDesign/GestureDesign预览图/2011-A Taxonomy of Microinteractions Defining Microgestures based on Ergonomic and Scenario-dependent Requirements.png"
      },
      {
        "id": 183,
        "title": "The intuitive grasp interface design and evaluation of micro-gestures on the steering wheel for driving scenario",
        "year": "2020",
        "category": "gesture-design",
        "image": "Papers/GestureDesign/GestureDesign预览图/2020 - The intuitive grasp interface design and evaluation of micro-gestures on the steering wheel for driving scenario.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 184,
        "title": "Transferable Microgestures Across Hand Posture and Location Constraints- Leveraging the Middle, Ring, and Pinky Fingers",
        "year": "2023",
        "category": "gesture-design",
        "image": "Papers/GestureDesign/GestureDesign预览图/2023 - Transferable Microgestures Across Hand Posture and Location Constraints- Leveraging the Middle, Ring, and Pinky Fingers.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 185,
        "title": "Segtouch",
        "year": "2017",
        "category": "gesture-design",
        "image": "Papers/GestureDesign/GestureDesign预览图/2017-Segtouch.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 186,
        "title": "Arpège learning multitouch chord gestures vocabularies",
        "year": "2013",
        "category": "gesture-design",
        "image": "Papers/GestureDesign/GestureDesign预览图/2013 - Arpège learning multitouch chord gestures vocabularies.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      },
      {
        "id": 187,
        "title": "PalmType Using Palms as Keyboards for Smart Glasses",
        "year": "2015",
        "category": "gesture-design",
        "image": "Papers/GestureDesign/GestureDesign预览图/2015-PalmType Using Palms as Keyboards for Smart Glasses.png",
        "hardwareDevices": [],
        "sensingTechnology": [],
        "recognitionClassification": [],
        "interactionModalities": [],
        "gestureTypes": [],
        "applicationScenarios": [],
        "feedbackOutput": [],
        "userExperienceDesign": []
      }
    ]
  },
  "stats": {
    "totalPapers": 165,
    "categories": {
      "hardware": 64,
      "software": 36,
      "gesture-design": 65
    },
    "yearRange": {
      "min": 2002,
      "max": 2025
    }
  }
};

// 导出数据
if (typeof module !== 'undefined' && module.exports) {
    module.exports = PAPERS_DATA;
}
